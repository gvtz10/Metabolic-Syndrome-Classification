{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "rEPY3JZfBw26"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "RmREFIAyNahx"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import torch\n",
        "df = pd.read_csv(r'/content/Metabolic Syndrome.csv')\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(len(df))\n",
        "df = df.dropna()\n",
        "print(len(df))\n",
        "df.head()\n",
        "df.reset_index()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 478
        },
        "id": "WtWKHdb5bv1b",
        "outputId": "22ad5d10-c33e-4d09-965c-06623743c6e2"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2401\n",
            "2009\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "      index   seqn  Age     Sex  Marital  Income         Race  WaistCirc  \\\n",
              "0         0  62161   22    Male   Single  8200.0        White       81.0   \n",
              "1         1  62164   44  Female  Married  4500.0        White       80.1   \n",
              "2         2  62169   21    Male   Single   800.0        Asian       69.6   \n",
              "3         3  62172   43  Female   Single  2000.0        Black      120.4   \n",
              "4         5  62178   80    Male  Widowed   300.0        White      112.5   \n",
              "...     ...    ...  ...     ...      ...     ...          ...        ...   \n",
              "2004   2394  71895   31    Male  Married  2500.0        Asian       74.0   \n",
              "2005   2395  71898   65  Female  Married  5400.0  MexAmerican       98.5   \n",
              "2006   2398  71909   28    Male   Single   800.0  MexAmerican      100.8   \n",
              "2007   2399  71911   27    Male  Married  8200.0  MexAmerican      106.6   \n",
              "2008   2400  71915   60    Male   Single  6200.0        White      106.6   \n",
              "\n",
              "       BMI  Albuminuria  UrAlbCr  UricAcid  BloodGlucose  HDL  Triglycerides  \\\n",
              "0     23.3            0     3.88       4.9            92   41             84   \n",
              "1     23.2            0     8.55       4.5            82   28             56   \n",
              "2     20.1            0     5.07       5.4           107   43             78   \n",
              "3     33.3            0     5.22       5.0           104   73            141   \n",
              "4     28.5            0     9.79       4.8           105   47            100   \n",
              "...    ...          ...      ...       ...           ...  ...            ...   \n",
              "2004  20.6            0     2.00       6.7            95   64             81   \n",
              "2005  29.4            0     5.51       6.7           114   49            165   \n",
              "2006  29.4            0     2.78       6.2            99   47             84   \n",
              "2007  31.3            0     4.15       6.2           100   41            124   \n",
              "2008  27.5            0    12.82       5.2            91   36            226   \n",
              "\n",
              "      MetabolicSyndrome  \n",
              "0                     0  \n",
              "1                     0  \n",
              "2                     0  \n",
              "3                     0  \n",
              "4                     0  \n",
              "...                 ...  \n",
              "2004                  0  \n",
              "2005                  1  \n",
              "2006                  0  \n",
              "2007                  1  \n",
              "2008                  1  \n",
              "\n",
              "[2009 rows x 16 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-66471662-94d1-42ed-9b65-81bb6ed91526\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>index</th>\n",
              "      <th>seqn</th>\n",
              "      <th>Age</th>\n",
              "      <th>Sex</th>\n",
              "      <th>Marital</th>\n",
              "      <th>Income</th>\n",
              "      <th>Race</th>\n",
              "      <th>WaistCirc</th>\n",
              "      <th>BMI</th>\n",
              "      <th>Albuminuria</th>\n",
              "      <th>UrAlbCr</th>\n",
              "      <th>UricAcid</th>\n",
              "      <th>BloodGlucose</th>\n",
              "      <th>HDL</th>\n",
              "      <th>Triglycerides</th>\n",
              "      <th>MetabolicSyndrome</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0</td>\n",
              "      <td>62161</td>\n",
              "      <td>22</td>\n",
              "      <td>Male</td>\n",
              "      <td>Single</td>\n",
              "      <td>8200.0</td>\n",
              "      <td>White</td>\n",
              "      <td>81.0</td>\n",
              "      <td>23.3</td>\n",
              "      <td>0</td>\n",
              "      <td>3.88</td>\n",
              "      <td>4.9</td>\n",
              "      <td>92</td>\n",
              "      <td>41</td>\n",
              "      <td>84</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>1</td>\n",
              "      <td>62164</td>\n",
              "      <td>44</td>\n",
              "      <td>Female</td>\n",
              "      <td>Married</td>\n",
              "      <td>4500.0</td>\n",
              "      <td>White</td>\n",
              "      <td>80.1</td>\n",
              "      <td>23.2</td>\n",
              "      <td>0</td>\n",
              "      <td>8.55</td>\n",
              "      <td>4.5</td>\n",
              "      <td>82</td>\n",
              "      <td>28</td>\n",
              "      <td>56</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>2</td>\n",
              "      <td>62169</td>\n",
              "      <td>21</td>\n",
              "      <td>Male</td>\n",
              "      <td>Single</td>\n",
              "      <td>800.0</td>\n",
              "      <td>Asian</td>\n",
              "      <td>69.6</td>\n",
              "      <td>20.1</td>\n",
              "      <td>0</td>\n",
              "      <td>5.07</td>\n",
              "      <td>5.4</td>\n",
              "      <td>107</td>\n",
              "      <td>43</td>\n",
              "      <td>78</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>3</td>\n",
              "      <td>62172</td>\n",
              "      <td>43</td>\n",
              "      <td>Female</td>\n",
              "      <td>Single</td>\n",
              "      <td>2000.0</td>\n",
              "      <td>Black</td>\n",
              "      <td>120.4</td>\n",
              "      <td>33.3</td>\n",
              "      <td>0</td>\n",
              "      <td>5.22</td>\n",
              "      <td>5.0</td>\n",
              "      <td>104</td>\n",
              "      <td>73</td>\n",
              "      <td>141</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>5</td>\n",
              "      <td>62178</td>\n",
              "      <td>80</td>\n",
              "      <td>Male</td>\n",
              "      <td>Widowed</td>\n",
              "      <td>300.0</td>\n",
              "      <td>White</td>\n",
              "      <td>112.5</td>\n",
              "      <td>28.5</td>\n",
              "      <td>0</td>\n",
              "      <td>9.79</td>\n",
              "      <td>4.8</td>\n",
              "      <td>105</td>\n",
              "      <td>47</td>\n",
              "      <td>100</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2004</th>\n",
              "      <td>2394</td>\n",
              "      <td>71895</td>\n",
              "      <td>31</td>\n",
              "      <td>Male</td>\n",
              "      <td>Married</td>\n",
              "      <td>2500.0</td>\n",
              "      <td>Asian</td>\n",
              "      <td>74.0</td>\n",
              "      <td>20.6</td>\n",
              "      <td>0</td>\n",
              "      <td>2.00</td>\n",
              "      <td>6.7</td>\n",
              "      <td>95</td>\n",
              "      <td>64</td>\n",
              "      <td>81</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2005</th>\n",
              "      <td>2395</td>\n",
              "      <td>71898</td>\n",
              "      <td>65</td>\n",
              "      <td>Female</td>\n",
              "      <td>Married</td>\n",
              "      <td>5400.0</td>\n",
              "      <td>MexAmerican</td>\n",
              "      <td>98.5</td>\n",
              "      <td>29.4</td>\n",
              "      <td>0</td>\n",
              "      <td>5.51</td>\n",
              "      <td>6.7</td>\n",
              "      <td>114</td>\n",
              "      <td>49</td>\n",
              "      <td>165</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2006</th>\n",
              "      <td>2398</td>\n",
              "      <td>71909</td>\n",
              "      <td>28</td>\n",
              "      <td>Male</td>\n",
              "      <td>Single</td>\n",
              "      <td>800.0</td>\n",
              "      <td>MexAmerican</td>\n",
              "      <td>100.8</td>\n",
              "      <td>29.4</td>\n",
              "      <td>0</td>\n",
              "      <td>2.78</td>\n",
              "      <td>6.2</td>\n",
              "      <td>99</td>\n",
              "      <td>47</td>\n",
              "      <td>84</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2007</th>\n",
              "      <td>2399</td>\n",
              "      <td>71911</td>\n",
              "      <td>27</td>\n",
              "      <td>Male</td>\n",
              "      <td>Married</td>\n",
              "      <td>8200.0</td>\n",
              "      <td>MexAmerican</td>\n",
              "      <td>106.6</td>\n",
              "      <td>31.3</td>\n",
              "      <td>0</td>\n",
              "      <td>4.15</td>\n",
              "      <td>6.2</td>\n",
              "      <td>100</td>\n",
              "      <td>41</td>\n",
              "      <td>124</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2008</th>\n",
              "      <td>2400</td>\n",
              "      <td>71915</td>\n",
              "      <td>60</td>\n",
              "      <td>Male</td>\n",
              "      <td>Single</td>\n",
              "      <td>6200.0</td>\n",
              "      <td>White</td>\n",
              "      <td>106.6</td>\n",
              "      <td>27.5</td>\n",
              "      <td>0</td>\n",
              "      <td>12.82</td>\n",
              "      <td>5.2</td>\n",
              "      <td>91</td>\n",
              "      <td>36</td>\n",
              "      <td>226</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>2009 rows × 16 columns</p>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-66471662-94d1-42ed-9b65-81bb6ed91526')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-66471662-94d1-42ed-9b65-81bb6ed91526 button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-66471662-94d1-42ed-9b65-81bb6ed91526');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "<div id=\"df-f9942d91-7f21-4d4c-9e32-608a3642f7ba\">\n",
              "  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-f9942d91-7f21-4d4c-9e32-608a3642f7ba')\"\n",
              "            title=\"Suggest charts\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "  </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "  <script>\n",
              "    async function quickchart(key) {\n",
              "      const quickchartButtonEl =\n",
              "        document.querySelector('#' + key + ' button');\n",
              "      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "      quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "      try {\n",
              "        const charts = await google.colab.kernel.invokeFunction(\n",
              "            'suggestCharts', [key], {});\n",
              "      } catch (error) {\n",
              "        console.error('Error during call to suggestCharts:', error);\n",
              "      }\n",
              "      quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "    }\n",
              "    (() => {\n",
              "      let quickchartButtonEl =\n",
              "        document.querySelector('#df-f9942d91-7f21-4d4c-9e32-608a3642f7ba button');\n",
              "      quickchartButtonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "    })();\n",
              "  </script>\n",
              "</div>\n",
              "    </div>\n",
              "  </div>\n"
            ]
          },
          "metadata": {},
          "execution_count": 2
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "normalizing numeric columns"
      ],
      "metadata": {
        "id": "COHQCzGUca1o"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.preprocessing import MinMaxScaler\n",
        "\n",
        "columns_to_normalize = ['Age', 'Income', 'WaistCirc','BMI', 'Albuminuria', 'UrAlbCr', 'UricAcid', 'BloodGlucose', 'HDL' , 'Triglycerides']\n",
        "\n",
        "subset_to_normalize = df[columns_to_normalize]\n",
        "\n",
        "scaler = StandardScaler()\n",
        "\n",
        "normalized_values = scaler.fit_transform(subset_to_normalize)\n",
        "\n",
        "df[columns_to_normalize] = normalized_values\n"
      ],
      "metadata": {
        "id": "lqLzjYHSWZIO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "one hot encoding catageorical variables"
      ],
      "metadata": {
        "id": "YZ2nVnCdcPbN"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "columns_to_encode = ['Sex', 'Marital', 'Race']\n",
        "\n",
        "df_encoded = pd.get_dummies(df, columns=columns_to_encode)\n",
        "\n"
      ],
      "metadata": {
        "id": "nv9hj6ifby1Q"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "print(len(df_encoded.columns))\n",
        "print(df.columns)\n",
        "\n",
        "df_encoded = df_encoded.drop(['seqn'], axis = 1)\n",
        "df_encoded = df_encoded.reset_index(drop=True)\n",
        "\n",
        "df_encoded.head()\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 342
        },
        "id": "PmxgN-WVB7YY",
        "outputId": "426add0f-593f-460b-a3af-2057afa8cbda"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "25\n",
            "Index(['seqn', 'Age', 'Sex', 'Marital', 'Income', 'Race', 'WaistCirc', 'BMI',\n",
            "       'Albuminuria', 'UrAlbCr', 'UricAcid', 'BloodGlucose', 'HDL',\n",
            "       'Triglycerides', 'MetabolicSyndrome'],\n",
            "      dtype='object')\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "        Age    Income  WaistCirc       BMI  Albuminuria   UrAlbCr  UricAcid  \\\n",
              "0 -1.565320  1.358247  -1.074950 -0.825925     -0.35381 -0.158988 -0.414060   \n",
              "1 -0.302216  0.118240  -1.130157 -0.841126     -0.35381 -0.139640 -0.694072   \n",
              "2 -1.622734 -1.121766  -1.774238 -1.312344     -0.35381 -0.154058 -0.064045   \n",
              "3 -0.359630 -0.719602   1.341889  0.694136     -0.35381 -0.153436 -0.344057   \n",
              "4  1.764683 -1.289335   0.857294 -0.035493     -0.35381 -0.134502 -0.484063   \n",
              "\n",
              "   BloodGlucose       HDL  Triglycerides  ...  Marital_Married  \\\n",
              "0     -0.476040 -0.836256      -0.477671  ...                0   \n",
              "1     -0.773408 -1.702426      -0.789488  ...                1   \n",
              "2     -0.029988 -0.702999      -0.544489  ...                0   \n",
              "3     -0.119199  1.295856       0.157101  ...                0   \n",
              "4     -0.089462 -0.436485      -0.299489  ...                0   \n",
              "\n",
              "   Marital_Separated  Marital_Single  Marital_Widowed  Race_Asian  Race_Black  \\\n",
              "0                  0               1                0           0           0   \n",
              "1                  0               0                0           0           0   \n",
              "2                  0               1                0           1           0   \n",
              "3                  0               1                0           0           1   \n",
              "4                  0               0                1           0           0   \n",
              "\n",
              "   Race_Hispanic  Race_MexAmerican  Race_Other  Race_White  \n",
              "0              0                 0           0           1  \n",
              "1              0                 0           0           1  \n",
              "2              0                 0           0           0  \n",
              "3              0                 0           0           0  \n",
              "4              0                 0           0           1  \n",
              "\n",
              "[5 rows x 24 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-890cc457-95db-471f-85fd-676dbb6afdf2\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Age</th>\n",
              "      <th>Income</th>\n",
              "      <th>WaistCirc</th>\n",
              "      <th>BMI</th>\n",
              "      <th>Albuminuria</th>\n",
              "      <th>UrAlbCr</th>\n",
              "      <th>UricAcid</th>\n",
              "      <th>BloodGlucose</th>\n",
              "      <th>HDL</th>\n",
              "      <th>Triglycerides</th>\n",
              "      <th>...</th>\n",
              "      <th>Marital_Married</th>\n",
              "      <th>Marital_Separated</th>\n",
              "      <th>Marital_Single</th>\n",
              "      <th>Marital_Widowed</th>\n",
              "      <th>Race_Asian</th>\n",
              "      <th>Race_Black</th>\n",
              "      <th>Race_Hispanic</th>\n",
              "      <th>Race_MexAmerican</th>\n",
              "      <th>Race_Other</th>\n",
              "      <th>Race_White</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>-1.565320</td>\n",
              "      <td>1.358247</td>\n",
              "      <td>-1.074950</td>\n",
              "      <td>-0.825925</td>\n",
              "      <td>-0.35381</td>\n",
              "      <td>-0.158988</td>\n",
              "      <td>-0.414060</td>\n",
              "      <td>-0.476040</td>\n",
              "      <td>-0.836256</td>\n",
              "      <td>-0.477671</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>-0.302216</td>\n",
              "      <td>0.118240</td>\n",
              "      <td>-1.130157</td>\n",
              "      <td>-0.841126</td>\n",
              "      <td>-0.35381</td>\n",
              "      <td>-0.139640</td>\n",
              "      <td>-0.694072</td>\n",
              "      <td>-0.773408</td>\n",
              "      <td>-1.702426</td>\n",
              "      <td>-0.789488</td>\n",
              "      <td>...</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>-1.622734</td>\n",
              "      <td>-1.121766</td>\n",
              "      <td>-1.774238</td>\n",
              "      <td>-1.312344</td>\n",
              "      <td>-0.35381</td>\n",
              "      <td>-0.154058</td>\n",
              "      <td>-0.064045</td>\n",
              "      <td>-0.029988</td>\n",
              "      <td>-0.702999</td>\n",
              "      <td>-0.544489</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>-0.359630</td>\n",
              "      <td>-0.719602</td>\n",
              "      <td>1.341889</td>\n",
              "      <td>0.694136</td>\n",
              "      <td>-0.35381</td>\n",
              "      <td>-0.153436</td>\n",
              "      <td>-0.344057</td>\n",
              "      <td>-0.119199</td>\n",
              "      <td>1.295856</td>\n",
              "      <td>0.157101</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>1.764683</td>\n",
              "      <td>-1.289335</td>\n",
              "      <td>0.857294</td>\n",
              "      <td>-0.035493</td>\n",
              "      <td>-0.35381</td>\n",
              "      <td>-0.134502</td>\n",
              "      <td>-0.484063</td>\n",
              "      <td>-0.089462</td>\n",
              "      <td>-0.436485</td>\n",
              "      <td>-0.299489</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>5 rows × 24 columns</p>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-890cc457-95db-471f-85fd-676dbb6afdf2')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-890cc457-95db-471f-85fd-676dbb6afdf2 button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-890cc457-95db-471f-85fd-676dbb6afdf2');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "<div id=\"df-4c6a7df5-fcad-4386-ae96-c54c19aeb9e7\">\n",
              "  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-4c6a7df5-fcad-4386-ae96-c54c19aeb9e7')\"\n",
              "            title=\"Suggest charts\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "  </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "  <script>\n",
              "    async function quickchart(key) {\n",
              "      const quickchartButtonEl =\n",
              "        document.querySelector('#' + key + ' button');\n",
              "      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "      quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "      try {\n",
              "        const charts = await google.colab.kernel.invokeFunction(\n",
              "            'suggestCharts', [key], {});\n",
              "      } catch (error) {\n",
              "        console.error('Error during call to suggestCharts:', error);\n",
              "      }\n",
              "      quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "    }\n",
              "    (() => {\n",
              "      let quickchartButtonEl =\n",
              "        document.querySelector('#df-4c6a7df5-fcad-4386-ae96-c54c19aeb9e7 button');\n",
              "      quickchartButtonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "    })();\n",
              "  </script>\n",
              "</div>\n",
              "    </div>\n",
              "  </div>\n"
            ]
          },
          "metadata": {},
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "pytorch dataset defintion"
      ],
      "metadata": {
        "id": "AhZwHYuTe_uE"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from torch.utils.data import Dataset\n",
        "\n",
        "class MetabolicSyndromeData(Dataset):\n",
        "    def __init__(self, dataframe, transform=None):\n",
        "        self.dataframe = dataframe\n",
        "        self.transform = transform\n",
        "        self.targets = self.dataframe['MetabolicSyndrome']\n",
        "        self.features = self.dataframe.drop(columns=['MetabolicSyndrome','index']).values\n",
        "    def __len__(self):\n",
        "        return len(self.dataframe)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        features = torch.tensor(self.features[idx], dtype=torch.float32)\n",
        "        target = torch.tensor(self.targets[idx], dtype=torch.float32)\n",
        "\n",
        "        if self.transform:\n",
        "            features = self.transform(features)\n",
        "\n",
        "        return features, target\n"
      ],
      "metadata": {
        "id": "l1l9B7FFe9An"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Load data into dataloader"
      ],
      "metadata": {
        "id": "9Beq1oyOfkAz"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from torch.utils.data import DataLoader\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "\n",
        "train_df, test_df = train_test_split(df_encoded, test_size=0.2, random_state=42)\n",
        "\n",
        "train_df = train_df.reset_index()\n",
        "test_df = test_df.reset_index()\n",
        "\n",
        "train_dataset = MetabolicSyndromeData(dataframe=train_df)\n",
        "test_dataset = MetabolicSyndromeData(dataframe=test_df)\n",
        "\n",
        "\n",
        "\n",
        "batch_size = 1\n",
        "trainloader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
        "testloader = DataLoader(test_dataset, batch_size=batch_size, shuffle=True)\n"
      ],
      "metadata": {
        "id": "YUDjzTjofll6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "MLP Network definitions"
      ],
      "metadata": {
        "id": "IsRRzdwEXdnV"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch.nn as nn\n",
        "\n",
        "class MLP(nn.Module):\n",
        "    def __init__(self, Hidden_size_one, Hidden_size_two):\n",
        "        super().__init__()\n",
        "        # Define your layers here!!\n",
        "        # YOUR CODE HERE\n",
        "        self.fc = nn.Linear(in_features = 23,out_features= Hidden_size_one, bias = True)\n",
        "        self.fc1 = nn.Linear(in_features= Hidden_size_one ,out_features= Hidden_size_two, bias = True)\n",
        "        self.fc2 = nn.Linear(in_features= Hidden_size_two, out_features= 1, bias = True)\n",
        "        self.selu = nn.SELU(inplace=False)\n",
        "        self.sigmoid = nn.Sigmoid()\n",
        "\n",
        "    def forward(self, x):\n",
        "\n",
        "        x = self.fc(x)\n",
        "        x = self.selu(x)\n",
        "        x = self.fc1(x)\n",
        "        x = self.selu(x)\n",
        "        x = self.fc2(x)\n",
        "        output = self.sigmoid(x)\n",
        "        return output"
      ],
      "metadata": {
        "id": "V82gdQyEWZwu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class ShallowMLP(nn.Module):\n",
        "    def __init__(self, Hidden_size):\n",
        "        super().__init__()\n",
        "        # Define your layers here!!\n",
        "        # YOUR CODE HERE\n",
        "        self.fc = nn.Linear(in_features = 23,out_features= Hidden_size, bias = True)\n",
        "        self.fc2 = nn.Linear( in_features = Hidden_size, out_features= 1, bias = True)\n",
        "        self.sigmoid = nn.Sigmoid()\n",
        "\n",
        "    def forward(self, x):\n",
        "\n",
        "        x = self.fc(x)\n",
        "        x = self.sigmoid(x)\n",
        "        x = self.fc2(x)\n",
        "        output = self.sigmoid(x)\n",
        "        return output"
      ],
      "metadata": {
        "id": "yC8Hx5UPXtmh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Training Logic"
      ],
      "metadata": {
        "id": "pi3XwreJXcIH"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "learning_rate = 1e-4\n",
        "n_epochs = 50\n",
        "\n",
        "# Use BCEWithLogitsLoss for binary classification\n",
        "mlp = ShallowMLP(75)\n",
        "\n",
        "criterion = nn.BCELoss()\n",
        "optimizer = torch.optim.Adam(mlp.parameters(), lr=learning_rate)\n",
        "\n",
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "# Assuming ShallowMLP is a binary classification model\n",
        "\n",
        "def train(model, optimizer, criterion ,learning_rate, n_epochs, trainloader, device, printbool):\n",
        "  for param_group in optimizer.param_groups:\n",
        "        param_group['lr'] = learning_rate\n",
        "\n",
        "  criterion.to(device)\n",
        "  model.to(device)\n",
        "  for epoch in range(n_epochs):\n",
        "      running_loss = 0.0\n",
        "      for i, data in enumerate(trainloader, 0):\n",
        "          inputs, labels = data\n",
        "\n",
        "          # Assuming labels are in the range [0, 1], if not, preprocess accordingly\n",
        "          labels = labels.float().to(device)\n",
        "\n",
        "          output = model(inputs.to(device))\n",
        "\n",
        "          loss = criterion(output, labels.view(-1, 1))  # Ensure labels have shape (batch_size, 1)\n",
        "\n",
        "          optimizer.zero_grad()\n",
        "          loss.backward()\n",
        "          optimizer.step()\n",
        "\n",
        "          running_loss += loss.item()\n",
        "          if i % 10 == 9 and printbool:\n",
        "            print('[Epoch %d, Step %5d] loss: %.3f' %\n",
        "                  (epoch + 1, i + 1, running_loss / 10))\n",
        "            running_loss = 0.0\n",
        "  print('Finished Training')\n",
        "\n",
        "train(model = mlp, optimizer= optimizer, criterion= criterion, learning_rate = learning_rate, n_epochs = n_epochs, trainloader = trainloader, device = device, printbool = True )\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "1TmT2hLWXLOQ",
        "outputId": "6bd67c64-228f-415f-c2b0-172dd7b9764a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[Epoch 1, Step    10] loss: 0.758\n",
            "[Epoch 1, Step    20] loss: 0.696\n",
            "[Epoch 1, Step    30] loss: 0.729\n",
            "[Epoch 1, Step    40] loss: 0.737\n",
            "[Epoch 1, Step    50] loss: 0.698\n",
            "[Epoch 1, Step    60] loss: 0.730\n",
            "[Epoch 1, Step    70] loss: 0.714\n",
            "[Epoch 1, Step    80] loss: 0.744\n",
            "[Epoch 1, Step    90] loss: 0.726\n",
            "[Epoch 1, Step   100] loss: 0.729\n",
            "[Epoch 1, Step   110] loss: 0.665\n",
            "[Epoch 1, Step   120] loss: 0.715\n",
            "[Epoch 1, Step   130] loss: 0.700\n",
            "[Epoch 1, Step   140] loss: 0.685\n",
            "[Epoch 1, Step   150] loss: 0.689\n",
            "[Epoch 1, Step   160] loss: 0.693\n",
            "[Epoch 1, Step   170] loss: 0.687\n",
            "[Epoch 1, Step   180] loss: 0.676\n",
            "[Epoch 1, Step   190] loss: 0.673\n",
            "[Epoch 1, Step   200] loss: 0.679\n",
            "[Epoch 1, Step   210] loss: 0.699\n",
            "[Epoch 1, Step   220] loss: 0.680\n",
            "[Epoch 1, Step   230] loss: 0.648\n",
            "[Epoch 1, Step   240] loss: 0.668\n",
            "[Epoch 1, Step   250] loss: 0.656\n",
            "[Epoch 1, Step   260] loss: 0.659\n",
            "[Epoch 1, Step   270] loss: 0.679\n",
            "[Epoch 1, Step   280] loss: 0.637\n",
            "[Epoch 1, Step   290] loss: 0.691\n",
            "[Epoch 1, Step   300] loss: 0.658\n",
            "[Epoch 1, Step   310] loss: 0.657\n",
            "[Epoch 1, Step   320] loss: 0.665\n",
            "[Epoch 1, Step   330] loss: 0.637\n",
            "[Epoch 1, Step   340] loss: 0.633\n",
            "[Epoch 1, Step   350] loss: 0.659\n",
            "[Epoch 1, Step   360] loss: 0.637\n",
            "[Epoch 1, Step   370] loss: 0.636\n",
            "[Epoch 1, Step   380] loss: 0.602\n",
            "[Epoch 1, Step   390] loss: 0.670\n",
            "[Epoch 1, Step   400] loss: 0.709\n",
            "[Epoch 1, Step   410] loss: 0.687\n",
            "[Epoch 1, Step   420] loss: 0.665\n",
            "[Epoch 1, Step   430] loss: 0.632\n",
            "[Epoch 1, Step   440] loss: 0.640\n",
            "[Epoch 1, Step   450] loss: 0.688\n",
            "[Epoch 1, Step   460] loss: 0.591\n",
            "[Epoch 1, Step   470] loss: 0.586\n",
            "[Epoch 1, Step   480] loss: 0.565\n",
            "[Epoch 1, Step   490] loss: 0.678\n",
            "[Epoch 1, Step   500] loss: 0.659\n",
            "[Epoch 1, Step   510] loss: 0.756\n",
            "[Epoch 1, Step   520] loss: 0.634\n",
            "[Epoch 1, Step   530] loss: 0.629\n",
            "[Epoch 1, Step   540] loss: 0.673\n",
            "[Epoch 1, Step   550] loss: 0.585\n",
            "[Epoch 1, Step   560] loss: 0.574\n",
            "[Epoch 1, Step   570] loss: 0.633\n",
            "[Epoch 1, Step   580] loss: 0.581\n",
            "[Epoch 1, Step   590] loss: 0.606\n",
            "[Epoch 1, Step   600] loss: 0.547\n",
            "[Epoch 1, Step   610] loss: 0.647\n",
            "[Epoch 1, Step   620] loss: 0.636\n",
            "[Epoch 1, Step   630] loss: 0.529\n",
            "[Epoch 1, Step   640] loss: 0.478\n",
            "[Epoch 1, Step   650] loss: 0.546\n",
            "[Epoch 1, Step   660] loss: 0.535\n",
            "[Epoch 1, Step   670] loss: 0.499\n",
            "[Epoch 1, Step   680] loss: 0.603\n",
            "[Epoch 1, Step   690] loss: 0.699\n",
            "[Epoch 1, Step   700] loss: 0.573\n",
            "[Epoch 1, Step   710] loss: 0.677\n",
            "[Epoch 1, Step   720] loss: 0.569\n",
            "[Epoch 1, Step   730] loss: 0.527\n",
            "[Epoch 1, Step   740] loss: 0.680\n",
            "[Epoch 1, Step   750] loss: 0.525\n",
            "[Epoch 1, Step   760] loss: 0.803\n",
            "[Epoch 1, Step   770] loss: 0.639\n",
            "[Epoch 1, Step   780] loss: 0.480\n",
            "[Epoch 1, Step   790] loss: 0.623\n",
            "[Epoch 1, Step   800] loss: 0.559\n",
            "[Epoch 1, Step   810] loss: 0.662\n",
            "[Epoch 1, Step   820] loss: 0.606\n",
            "[Epoch 1, Step   830] loss: 0.619\n",
            "[Epoch 1, Step   840] loss: 0.831\n",
            "[Epoch 1, Step   850] loss: 0.589\n",
            "[Epoch 1, Step   860] loss: 0.681\n",
            "[Epoch 1, Step   870] loss: 0.725\n",
            "[Epoch 1, Step   880] loss: 0.639\n",
            "[Epoch 1, Step   890] loss: 0.669\n",
            "[Epoch 1, Step   900] loss: 0.596\n",
            "[Epoch 1, Step   910] loss: 0.589\n",
            "[Epoch 1, Step   920] loss: 0.591\n",
            "[Epoch 1, Step   930] loss: 0.579\n",
            "[Epoch 1, Step   940] loss: 0.603\n",
            "[Epoch 1, Step   950] loss: 0.736\n",
            "[Epoch 1, Step   960] loss: 0.553\n",
            "[Epoch 1, Step   970] loss: 0.666\n",
            "[Epoch 1, Step   980] loss: 0.734\n",
            "[Epoch 1, Step   990] loss: 0.548\n",
            "[Epoch 1, Step  1000] loss: 0.673\n",
            "[Epoch 1, Step  1010] loss: 0.553\n",
            "[Epoch 1, Step  1020] loss: 0.588\n",
            "[Epoch 1, Step  1030] loss: 0.667\n",
            "[Epoch 1, Step  1040] loss: 0.560\n",
            "[Epoch 1, Step  1050] loss: 0.688\n",
            "[Epoch 1, Step  1060] loss: 0.587\n",
            "[Epoch 1, Step  1070] loss: 0.499\n",
            "[Epoch 1, Step  1080] loss: 0.651\n",
            "[Epoch 1, Step  1090] loss: 0.545\n",
            "[Epoch 1, Step  1100] loss: 0.754\n",
            "[Epoch 1, Step  1110] loss: 0.655\n",
            "[Epoch 1, Step  1120] loss: 0.564\n",
            "[Epoch 1, Step  1130] loss: 0.572\n",
            "[Epoch 1, Step  1140] loss: 0.623\n",
            "[Epoch 1, Step  1150] loss: 0.583\n",
            "[Epoch 1, Step  1160] loss: 0.493\n",
            "[Epoch 1, Step  1170] loss: 0.663\n",
            "[Epoch 1, Step  1180] loss: 0.630\n",
            "[Epoch 1, Step  1190] loss: 0.684\n",
            "[Epoch 1, Step  1200] loss: 0.644\n",
            "[Epoch 1, Step  1210] loss: 0.492\n",
            "[Epoch 1, Step  1220] loss: 0.604\n",
            "[Epoch 1, Step  1230] loss: 0.529\n",
            "[Epoch 1, Step  1240] loss: 0.593\n",
            "[Epoch 1, Step  1250] loss: 0.596\n",
            "[Epoch 1, Step  1260] loss: 0.549\n",
            "[Epoch 1, Step  1270] loss: 0.690\n",
            "[Epoch 1, Step  1280] loss: 0.640\n",
            "[Epoch 1, Step  1290] loss: 0.594\n",
            "[Epoch 1, Step  1300] loss: 0.604\n",
            "[Epoch 1, Step  1310] loss: 0.483\n",
            "[Epoch 1, Step  1320] loss: 0.622\n",
            "[Epoch 1, Step  1330] loss: 0.446\n",
            "[Epoch 1, Step  1340] loss: 0.539\n",
            "[Epoch 1, Step  1350] loss: 0.570\n",
            "[Epoch 1, Step  1360] loss: 0.617\n",
            "[Epoch 1, Step  1370] loss: 0.435\n",
            "[Epoch 1, Step  1380] loss: 0.563\n",
            "[Epoch 1, Step  1390] loss: 0.621\n",
            "[Epoch 1, Step  1400] loss: 0.640\n",
            "[Epoch 1, Step  1410] loss: 0.527\n",
            "[Epoch 1, Step  1420] loss: 0.503\n",
            "[Epoch 1, Step  1430] loss: 0.499\n",
            "[Epoch 1, Step  1440] loss: 0.564\n",
            "[Epoch 1, Step  1450] loss: 0.723\n",
            "[Epoch 1, Step  1460] loss: 0.579\n",
            "[Epoch 1, Step  1470] loss: 0.602\n",
            "[Epoch 1, Step  1480] loss: 0.579\n",
            "[Epoch 1, Step  1490] loss: 0.551\n",
            "[Epoch 1, Step  1500] loss: 0.529\n",
            "[Epoch 1, Step  1510] loss: 0.626\n",
            "[Epoch 1, Step  1520] loss: 0.534\n",
            "[Epoch 1, Step  1530] loss: 0.535\n",
            "[Epoch 1, Step  1540] loss: 0.573\n",
            "[Epoch 1, Step  1550] loss: 0.618\n",
            "[Epoch 1, Step  1560] loss: 0.455\n",
            "[Epoch 1, Step  1570] loss: 0.436\n",
            "[Epoch 1, Step  1580] loss: 0.558\n",
            "[Epoch 1, Step  1590] loss: 0.602\n",
            "[Epoch 1, Step  1600] loss: 0.389\n",
            "[Epoch 2, Step    10] loss: 0.523\n",
            "[Epoch 2, Step    20] loss: 0.706\n",
            "[Epoch 2, Step    30] loss: 0.538\n",
            "[Epoch 2, Step    40] loss: 0.497\n",
            "[Epoch 2, Step    50] loss: 0.567\n",
            "[Epoch 2, Step    60] loss: 0.439\n",
            "[Epoch 2, Step    70] loss: 0.578\n",
            "[Epoch 2, Step    80] loss: 0.377\n",
            "[Epoch 2, Step    90] loss: 0.645\n",
            "[Epoch 2, Step   100] loss: 0.543\n",
            "[Epoch 2, Step   110] loss: 0.514\n",
            "[Epoch 2, Step   120] loss: 0.516\n",
            "[Epoch 2, Step   130] loss: 0.491\n",
            "[Epoch 2, Step   140] loss: 0.546\n",
            "[Epoch 2, Step   150] loss: 0.631\n",
            "[Epoch 2, Step   160] loss: 0.634\n",
            "[Epoch 2, Step   170] loss: 0.743\n",
            "[Epoch 2, Step   180] loss: 0.514\n",
            "[Epoch 2, Step   190] loss: 0.550\n",
            "[Epoch 2, Step   200] loss: 0.472\n",
            "[Epoch 2, Step   210] loss: 0.417\n",
            "[Epoch 2, Step   220] loss: 0.649\n",
            "[Epoch 2, Step   230] loss: 0.712\n",
            "[Epoch 2, Step   240] loss: 0.436\n",
            "[Epoch 2, Step   250] loss: 0.481\n",
            "[Epoch 2, Step   260] loss: 0.648\n",
            "[Epoch 2, Step   270] loss: 0.600\n",
            "[Epoch 2, Step   280] loss: 0.744\n",
            "[Epoch 2, Step   290] loss: 0.449\n",
            "[Epoch 2, Step   300] loss: 0.486\n",
            "[Epoch 2, Step   310] loss: 0.642\n",
            "[Epoch 2, Step   320] loss: 0.424\n",
            "[Epoch 2, Step   330] loss: 0.636\n",
            "[Epoch 2, Step   340] loss: 0.547\n",
            "[Epoch 2, Step   350] loss: 0.494\n",
            "[Epoch 2, Step   360] loss: 0.619\n",
            "[Epoch 2, Step   370] loss: 0.572\n",
            "[Epoch 2, Step   380] loss: 0.616\n",
            "[Epoch 2, Step   390] loss: 0.599\n",
            "[Epoch 2, Step   400] loss: 0.488\n",
            "[Epoch 2, Step   410] loss: 0.514\n",
            "[Epoch 2, Step   420] loss: 0.482\n",
            "[Epoch 2, Step   430] loss: 0.519\n",
            "[Epoch 2, Step   440] loss: 0.445\n",
            "[Epoch 2, Step   450] loss: 0.565\n",
            "[Epoch 2, Step   460] loss: 0.596\n",
            "[Epoch 2, Step   470] loss: 0.467\n",
            "[Epoch 2, Step   480] loss: 0.722\n",
            "[Epoch 2, Step   490] loss: 0.442\n",
            "[Epoch 2, Step   500] loss: 0.591\n",
            "[Epoch 2, Step   510] loss: 0.512\n",
            "[Epoch 2, Step   520] loss: 0.638\n",
            "[Epoch 2, Step   530] loss: 0.525\n",
            "[Epoch 2, Step   540] loss: 0.591\n",
            "[Epoch 2, Step   550] loss: 0.375\n",
            "[Epoch 2, Step   560] loss: 0.552\n",
            "[Epoch 2, Step   570] loss: 0.478\n",
            "[Epoch 2, Step   580] loss: 0.398\n",
            "[Epoch 2, Step   590] loss: 0.409\n",
            "[Epoch 2, Step   600] loss: 0.706\n",
            "[Epoch 2, Step   610] loss: 0.610\n",
            "[Epoch 2, Step   620] loss: 0.485\n",
            "[Epoch 2, Step   630] loss: 0.545\n",
            "[Epoch 2, Step   640] loss: 0.534\n",
            "[Epoch 2, Step   650] loss: 0.616\n",
            "[Epoch 2, Step   660] loss: 0.433\n",
            "[Epoch 2, Step   670] loss: 0.582\n",
            "[Epoch 2, Step   680] loss: 0.673\n",
            "[Epoch 2, Step   690] loss: 0.438\n",
            "[Epoch 2, Step   700] loss: 0.489\n",
            "[Epoch 2, Step   710] loss: 0.443\n",
            "[Epoch 2, Step   720] loss: 0.489\n",
            "[Epoch 2, Step   730] loss: 0.525\n",
            "[Epoch 2, Step   740] loss: 0.554\n",
            "[Epoch 2, Step   750] loss: 0.540\n",
            "[Epoch 2, Step   760] loss: 0.636\n",
            "[Epoch 2, Step   770] loss: 0.437\n",
            "[Epoch 2, Step   780] loss: 0.403\n",
            "[Epoch 2, Step   790] loss: 0.598\n",
            "[Epoch 2, Step   800] loss: 0.588\n",
            "[Epoch 2, Step   810] loss: 0.533\n",
            "[Epoch 2, Step   820] loss: 0.592\n",
            "[Epoch 2, Step   830] loss: 0.488\n",
            "[Epoch 2, Step   840] loss: 0.453\n",
            "[Epoch 2, Step   850] loss: 0.473\n",
            "[Epoch 2, Step   860] loss: 0.591\n",
            "[Epoch 2, Step   870] loss: 0.467\n",
            "[Epoch 2, Step   880] loss: 0.456\n",
            "[Epoch 2, Step   890] loss: 0.409\n",
            "[Epoch 2, Step   900] loss: 0.564\n",
            "[Epoch 2, Step   910] loss: 0.391\n",
            "[Epoch 2, Step   920] loss: 0.569\n",
            "[Epoch 2, Step   930] loss: 0.527\n",
            "[Epoch 2, Step   940] loss: 0.494\n",
            "[Epoch 2, Step   950] loss: 0.458\n",
            "[Epoch 2, Step   960] loss: 0.487\n",
            "[Epoch 2, Step   970] loss: 0.672\n",
            "[Epoch 2, Step   980] loss: 0.624\n",
            "[Epoch 2, Step   990] loss: 0.621\n",
            "[Epoch 2, Step  1000] loss: 0.490\n",
            "[Epoch 2, Step  1010] loss: 0.404\n",
            "[Epoch 2, Step  1020] loss: 0.680\n",
            "[Epoch 2, Step  1030] loss: 0.571\n",
            "[Epoch 2, Step  1040] loss: 0.658\n",
            "[Epoch 2, Step  1050] loss: 0.483\n",
            "[Epoch 2, Step  1060] loss: 0.525\n",
            "[Epoch 2, Step  1070] loss: 0.513\n",
            "[Epoch 2, Step  1080] loss: 0.432\n",
            "[Epoch 2, Step  1090] loss: 0.362\n",
            "[Epoch 2, Step  1100] loss: 0.623\n",
            "[Epoch 2, Step  1110] loss: 0.441\n",
            "[Epoch 2, Step  1120] loss: 0.599\n",
            "[Epoch 2, Step  1130] loss: 0.497\n",
            "[Epoch 2, Step  1140] loss: 0.459\n",
            "[Epoch 2, Step  1150] loss: 0.391\n",
            "[Epoch 2, Step  1160] loss: 0.538\n",
            "[Epoch 2, Step  1170] loss: 0.405\n",
            "[Epoch 2, Step  1180] loss: 0.653\n",
            "[Epoch 2, Step  1190] loss: 0.494\n",
            "[Epoch 2, Step  1200] loss: 0.560\n",
            "[Epoch 2, Step  1210] loss: 0.556\n",
            "[Epoch 2, Step  1220] loss: 0.631\n",
            "[Epoch 2, Step  1230] loss: 0.615\n",
            "[Epoch 2, Step  1240] loss: 0.707\n",
            "[Epoch 2, Step  1250] loss: 0.609\n",
            "[Epoch 2, Step  1260] loss: 0.411\n",
            "[Epoch 2, Step  1270] loss: 0.605\n",
            "[Epoch 2, Step  1280] loss: 0.395\n",
            "[Epoch 2, Step  1290] loss: 0.614\n",
            "[Epoch 2, Step  1300] loss: 0.411\n",
            "[Epoch 2, Step  1310] loss: 0.490\n",
            "[Epoch 2, Step  1320] loss: 0.541\n",
            "[Epoch 2, Step  1330] loss: 0.630\n",
            "[Epoch 2, Step  1340] loss: 0.408\n",
            "[Epoch 2, Step  1350] loss: 0.473\n",
            "[Epoch 2, Step  1360] loss: 0.538\n",
            "[Epoch 2, Step  1370] loss: 0.432\n",
            "[Epoch 2, Step  1380] loss: 0.589\n",
            "[Epoch 2, Step  1390] loss: 0.546\n",
            "[Epoch 2, Step  1400] loss: 0.581\n",
            "[Epoch 2, Step  1410] loss: 0.666\n",
            "[Epoch 2, Step  1420] loss: 0.461\n",
            "[Epoch 2, Step  1430] loss: 0.444\n",
            "[Epoch 2, Step  1440] loss: 0.459\n",
            "[Epoch 2, Step  1450] loss: 0.509\n",
            "[Epoch 2, Step  1460] loss: 0.547\n",
            "[Epoch 2, Step  1470] loss: 0.437\n",
            "[Epoch 2, Step  1480] loss: 0.414\n",
            "[Epoch 2, Step  1490] loss: 0.468\n",
            "[Epoch 2, Step  1500] loss: 0.527\n",
            "[Epoch 2, Step  1510] loss: 0.501\n",
            "[Epoch 2, Step  1520] loss: 0.526\n",
            "[Epoch 2, Step  1530] loss: 0.595\n",
            "[Epoch 2, Step  1540] loss: 0.357\n",
            "[Epoch 2, Step  1550] loss: 0.546\n",
            "[Epoch 2, Step  1560] loss: 0.488\n",
            "[Epoch 2, Step  1570] loss: 0.389\n",
            "[Epoch 2, Step  1580] loss: 0.512\n",
            "[Epoch 2, Step  1590] loss: 0.614\n",
            "[Epoch 2, Step  1600] loss: 0.442\n",
            "[Epoch 3, Step    10] loss: 0.499\n",
            "[Epoch 3, Step    20] loss: 0.538\n",
            "[Epoch 3, Step    30] loss: 0.531\n",
            "[Epoch 3, Step    40] loss: 0.547\n",
            "[Epoch 3, Step    50] loss: 0.355\n",
            "[Epoch 3, Step    60] loss: 0.451\n",
            "[Epoch 3, Step    70] loss: 0.633\n",
            "[Epoch 3, Step    80] loss: 0.441\n",
            "[Epoch 3, Step    90] loss: 0.478\n",
            "[Epoch 3, Step   100] loss: 0.571\n",
            "[Epoch 3, Step   110] loss: 0.533\n",
            "[Epoch 3, Step   120] loss: 0.520\n",
            "[Epoch 3, Step   130] loss: 0.535\n",
            "[Epoch 3, Step   140] loss: 0.409\n",
            "[Epoch 3, Step   150] loss: 0.609\n",
            "[Epoch 3, Step   160] loss: 0.297\n",
            "[Epoch 3, Step   170] loss: 0.511\n",
            "[Epoch 3, Step   180] loss: 0.501\n",
            "[Epoch 3, Step   190] loss: 0.698\n",
            "[Epoch 3, Step   200] loss: 0.392\n",
            "[Epoch 3, Step   210] loss: 0.431\n",
            "[Epoch 3, Step   220] loss: 0.560\n",
            "[Epoch 3, Step   230] loss: 0.284\n",
            "[Epoch 3, Step   240] loss: 0.437\n",
            "[Epoch 3, Step   250] loss: 0.698\n",
            "[Epoch 3, Step   260] loss: 0.529\n",
            "[Epoch 3, Step   270] loss: 0.394\n",
            "[Epoch 3, Step   280] loss: 0.387\n",
            "[Epoch 3, Step   290] loss: 0.405\n",
            "[Epoch 3, Step   300] loss: 0.554\n",
            "[Epoch 3, Step   310] loss: 0.609\n",
            "[Epoch 3, Step   320] loss: 0.506\n",
            "[Epoch 3, Step   330] loss: 0.468\n",
            "[Epoch 3, Step   340] loss: 0.537\n",
            "[Epoch 3, Step   350] loss: 0.511\n",
            "[Epoch 3, Step   360] loss: 0.505\n",
            "[Epoch 3, Step   370] loss: 0.503\n",
            "[Epoch 3, Step   380] loss: 0.509\n",
            "[Epoch 3, Step   390] loss: 0.576\n",
            "[Epoch 3, Step   400] loss: 0.585\n",
            "[Epoch 3, Step   410] loss: 0.305\n",
            "[Epoch 3, Step   420] loss: 0.523\n",
            "[Epoch 3, Step   430] loss: 0.359\n",
            "[Epoch 3, Step   440] loss: 0.500\n",
            "[Epoch 3, Step   450] loss: 0.461\n",
            "[Epoch 3, Step   460] loss: 0.541\n",
            "[Epoch 3, Step   470] loss: 0.527\n",
            "[Epoch 3, Step   480] loss: 0.458\n",
            "[Epoch 3, Step   490] loss: 0.486\n",
            "[Epoch 3, Step   500] loss: 0.544\n",
            "[Epoch 3, Step   510] loss: 0.470\n",
            "[Epoch 3, Step   520] loss: 0.403\n",
            "[Epoch 3, Step   530] loss: 0.573\n",
            "[Epoch 3, Step   540] loss: 0.464\n",
            "[Epoch 3, Step   550] loss: 0.343\n",
            "[Epoch 3, Step   560] loss: 0.478\n",
            "[Epoch 3, Step   570] loss: 0.464\n",
            "[Epoch 3, Step   580] loss: 0.391\n",
            "[Epoch 3, Step   590] loss: 0.618\n",
            "[Epoch 3, Step   600] loss: 0.539\n",
            "[Epoch 3, Step   610] loss: 0.334\n",
            "[Epoch 3, Step   620] loss: 0.373\n",
            "[Epoch 3, Step   630] loss: 0.463\n",
            "[Epoch 3, Step   640] loss: 0.452\n",
            "[Epoch 3, Step   650] loss: 0.501\n",
            "[Epoch 3, Step   660] loss: 0.369\n",
            "[Epoch 3, Step   670] loss: 0.503\n",
            "[Epoch 3, Step   680] loss: 0.354\n",
            "[Epoch 3, Step   690] loss: 0.767\n",
            "[Epoch 3, Step   700] loss: 0.473\n",
            "[Epoch 3, Step   710] loss: 0.461\n",
            "[Epoch 3, Step   720] loss: 0.286\n",
            "[Epoch 3, Step   730] loss: 0.515\n",
            "[Epoch 3, Step   740] loss: 0.290\n",
            "[Epoch 3, Step   750] loss: 0.497\n",
            "[Epoch 3, Step   760] loss: 0.540\n",
            "[Epoch 3, Step   770] loss: 0.642\n",
            "[Epoch 3, Step   780] loss: 0.336\n",
            "[Epoch 3, Step   790] loss: 0.370\n",
            "[Epoch 3, Step   800] loss: 0.597\n",
            "[Epoch 3, Step   810] loss: 0.511\n",
            "[Epoch 3, Step   820] loss: 0.394\n",
            "[Epoch 3, Step   830] loss: 0.439\n",
            "[Epoch 3, Step   840] loss: 0.455\n",
            "[Epoch 3, Step   850] loss: 0.546\n",
            "[Epoch 3, Step   860] loss: 0.483\n",
            "[Epoch 3, Step   870] loss: 0.502\n",
            "[Epoch 3, Step   880] loss: 0.563\n",
            "[Epoch 3, Step   890] loss: 0.368\n",
            "[Epoch 3, Step   900] loss: 0.495\n",
            "[Epoch 3, Step   910] loss: 0.572\n",
            "[Epoch 3, Step   920] loss: 0.576\n",
            "[Epoch 3, Step   930] loss: 0.313\n",
            "[Epoch 3, Step   940] loss: 0.543\n",
            "[Epoch 3, Step   950] loss: 0.471\n",
            "[Epoch 3, Step   960] loss: 0.493\n",
            "[Epoch 3, Step   970] loss: 0.462\n",
            "[Epoch 3, Step   980] loss: 0.495\n",
            "[Epoch 3, Step   990] loss: 0.464\n",
            "[Epoch 3, Step  1000] loss: 0.392\n",
            "[Epoch 3, Step  1010] loss: 0.415\n",
            "[Epoch 3, Step  1020] loss: 0.314\n",
            "[Epoch 3, Step  1030] loss: 0.405\n",
            "[Epoch 3, Step  1040] loss: 0.304\n",
            "[Epoch 3, Step  1050] loss: 0.429\n",
            "[Epoch 3, Step  1060] loss: 0.492\n",
            "[Epoch 3, Step  1070] loss: 0.389\n",
            "[Epoch 3, Step  1080] loss: 0.407\n",
            "[Epoch 3, Step  1090] loss: 0.424\n",
            "[Epoch 3, Step  1100] loss: 0.524\n",
            "[Epoch 3, Step  1110] loss: 0.358\n",
            "[Epoch 3, Step  1120] loss: 0.392\n",
            "[Epoch 3, Step  1130] loss: 0.512\n",
            "[Epoch 3, Step  1140] loss: 0.455\n",
            "[Epoch 3, Step  1150] loss: 0.509\n",
            "[Epoch 3, Step  1160] loss: 0.604\n",
            "[Epoch 3, Step  1170] loss: 0.561\n",
            "[Epoch 3, Step  1180] loss: 0.419\n",
            "[Epoch 3, Step  1190] loss: 0.441\n",
            "[Epoch 3, Step  1200] loss: 0.339\n",
            "[Epoch 3, Step  1210] loss: 0.382\n",
            "[Epoch 3, Step  1220] loss: 0.430\n",
            "[Epoch 3, Step  1230] loss: 0.510\n",
            "[Epoch 3, Step  1240] loss: 0.345\n",
            "[Epoch 3, Step  1250] loss: 0.436\n",
            "[Epoch 3, Step  1260] loss: 0.291\n",
            "[Epoch 3, Step  1270] loss: 0.323\n",
            "[Epoch 3, Step  1280] loss: 0.502\n",
            "[Epoch 3, Step  1290] loss: 0.426\n",
            "[Epoch 3, Step  1300] loss: 0.583\n",
            "[Epoch 3, Step  1310] loss: 0.440\n",
            "[Epoch 3, Step  1320] loss: 0.508\n",
            "[Epoch 3, Step  1330] loss: 0.500\n",
            "[Epoch 3, Step  1340] loss: 0.489\n",
            "[Epoch 3, Step  1350] loss: 0.621\n",
            "[Epoch 3, Step  1360] loss: 0.359\n",
            "[Epoch 3, Step  1370] loss: 0.471\n",
            "[Epoch 3, Step  1380] loss: 0.300\n",
            "[Epoch 3, Step  1390] loss: 0.572\n",
            "[Epoch 3, Step  1400] loss: 0.492\n",
            "[Epoch 3, Step  1410] loss: 0.505\n",
            "[Epoch 3, Step  1420] loss: 0.418\n",
            "[Epoch 3, Step  1430] loss: 0.471\n",
            "[Epoch 3, Step  1440] loss: 0.566\n",
            "[Epoch 3, Step  1450] loss: 0.351\n",
            "[Epoch 3, Step  1460] loss: 0.312\n",
            "[Epoch 3, Step  1470] loss: 0.454\n",
            "[Epoch 3, Step  1480] loss: 0.592\n",
            "[Epoch 3, Step  1490] loss: 0.367\n",
            "[Epoch 3, Step  1500] loss: 0.524\n",
            "[Epoch 3, Step  1510] loss: 0.427\n",
            "[Epoch 3, Step  1520] loss: 0.381\n",
            "[Epoch 3, Step  1530] loss: 0.358\n",
            "[Epoch 3, Step  1540] loss: 0.448\n",
            "[Epoch 3, Step  1550] loss: 0.284\n",
            "[Epoch 3, Step  1560] loss: 0.382\n",
            "[Epoch 3, Step  1570] loss: 0.549\n",
            "[Epoch 3, Step  1580] loss: 0.765\n",
            "[Epoch 3, Step  1590] loss: 0.536\n",
            "[Epoch 3, Step  1600] loss: 0.548\n",
            "[Epoch 4, Step    10] loss: 0.433\n",
            "[Epoch 4, Step    20] loss: 0.412\n",
            "[Epoch 4, Step    30] loss: 0.392\n",
            "[Epoch 4, Step    40] loss: 0.387\n",
            "[Epoch 4, Step    50] loss: 0.432\n",
            "[Epoch 4, Step    60] loss: 0.558\n",
            "[Epoch 4, Step    70] loss: 0.673\n",
            "[Epoch 4, Step    80] loss: 0.325\n",
            "[Epoch 4, Step    90] loss: 0.502\n",
            "[Epoch 4, Step   100] loss: 0.498\n",
            "[Epoch 4, Step   110] loss: 0.389\n",
            "[Epoch 4, Step   120] loss: 0.391\n",
            "[Epoch 4, Step   130] loss: 0.374\n",
            "[Epoch 4, Step   140] loss: 0.276\n",
            "[Epoch 4, Step   150] loss: 0.578\n",
            "[Epoch 4, Step   160] loss: 0.348\n",
            "[Epoch 4, Step   170] loss: 0.345\n",
            "[Epoch 4, Step   180] loss: 0.370\n",
            "[Epoch 4, Step   190] loss: 0.419\n",
            "[Epoch 4, Step   200] loss: 0.468\n",
            "[Epoch 4, Step   210] loss: 0.324\n",
            "[Epoch 4, Step   220] loss: 0.621\n",
            "[Epoch 4, Step   230] loss: 0.361\n",
            "[Epoch 4, Step   240] loss: 0.368\n",
            "[Epoch 4, Step   250] loss: 0.643\n",
            "[Epoch 4, Step   260] loss: 0.314\n",
            "[Epoch 4, Step   270] loss: 0.371\n",
            "[Epoch 4, Step   280] loss: 0.480\n",
            "[Epoch 4, Step   290] loss: 0.255\n",
            "[Epoch 4, Step   300] loss: 0.267\n",
            "[Epoch 4, Step   310] loss: 0.616\n",
            "[Epoch 4, Step   320] loss: 0.386\n",
            "[Epoch 4, Step   330] loss: 0.357\n",
            "[Epoch 4, Step   340] loss: 0.598\n",
            "[Epoch 4, Step   350] loss: 0.361\n",
            "[Epoch 4, Step   360] loss: 0.261\n",
            "[Epoch 4, Step   370] loss: 0.426\n",
            "[Epoch 4, Step   380] loss: 0.492\n",
            "[Epoch 4, Step   390] loss: 0.396\n",
            "[Epoch 4, Step   400] loss: 0.484\n",
            "[Epoch 4, Step   410] loss: 0.488\n",
            "[Epoch 4, Step   420] loss: 0.359\n",
            "[Epoch 4, Step   430] loss: 0.302\n",
            "[Epoch 4, Step   440] loss: 0.333\n",
            "[Epoch 4, Step   450] loss: 0.459\n",
            "[Epoch 4, Step   460] loss: 0.550\n",
            "[Epoch 4, Step   470] loss: 0.394\n",
            "[Epoch 4, Step   480] loss: 0.485\n",
            "[Epoch 4, Step   490] loss: 0.477\n",
            "[Epoch 4, Step   500] loss: 0.315\n",
            "[Epoch 4, Step   510] loss: 0.514\n",
            "[Epoch 4, Step   520] loss: 0.496\n",
            "[Epoch 4, Step   530] loss: 0.370\n",
            "[Epoch 4, Step   540] loss: 0.402\n",
            "[Epoch 4, Step   550] loss: 0.472\n",
            "[Epoch 4, Step   560] loss: 0.387\n",
            "[Epoch 4, Step   570] loss: 0.417\n",
            "[Epoch 4, Step   580] loss: 0.510\n",
            "[Epoch 4, Step   590] loss: 0.338\n",
            "[Epoch 4, Step   600] loss: 0.554\n",
            "[Epoch 4, Step   610] loss: 0.382\n",
            "[Epoch 4, Step   620] loss: 0.552\n",
            "[Epoch 4, Step   630] loss: 0.392\n",
            "[Epoch 4, Step   640] loss: 0.346\n",
            "[Epoch 4, Step   650] loss: 0.453\n",
            "[Epoch 4, Step   660] loss: 0.469\n",
            "[Epoch 4, Step   670] loss: 0.441\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-56-cb5351e83412>\u001b[0m in \u001b[0;36m<cell line: 42>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     40\u001b[0m   \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Finished Training'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     41\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 42\u001b[0;31m \u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmlp\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptimizer\u001b[0m\u001b[0;34m=\u001b[0m \u001b[0moptimizer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcriterion\u001b[0m\u001b[0;34m=\u001b[0m \u001b[0mcriterion\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlearning_rate\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlearning_rate\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn_epochs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mn_epochs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrainloader\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrainloader\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdevice\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdevice\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mprintbool\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m \u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m<ipython-input-56-cb5351e83412>\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(model, optimizer, criterion, learning_rate, n_epochs, trainloader, device, printbool)\u001b[0m\n\u001b[1;32m     29\u001b[0m           \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcriterion\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabels\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mview\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# Ensure labels have shape (batch_size, 1)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     30\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 31\u001b[0;31m           \u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mzero_grad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     32\u001b[0m           \u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     33\u001b[0m           \u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/_compile.py\u001b[0m in \u001b[0;36minner\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     22\u001b[0m             \u001b[0;32mimport\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_dynamo\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     23\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 24\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_dynamo\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdisable\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrecursive\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     25\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     26\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0minner\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/_dynamo/decorators.py\u001b[0m in \u001b[0;36mdisable\u001b[0;34m(fn, recursive)\u001b[0m\n\u001b[1;32m     45\u001b[0m             \u001b[0mfn\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0minnermost_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfn\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     46\u001b[0m             \u001b[0;32massert\u001b[0m \u001b[0mcallable\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfn\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 47\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mDisableContext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfn\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     48\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mDisableContext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     49\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/_dynamo/eval_frame.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, fn)\u001b[0m\n\u001b[1;32m    344\u001b[0m         \u001b[0;31m# when compiling user function instead of nn.Module\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    345\u001b[0m         \u001b[0;31m# provide public api _fn.get_compiler_config()\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 346\u001b[0;31m         \u001b[0;32massert\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mhasattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_fn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"get_compiler_config\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    347\u001b[0m         \u001b[0m_fn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_compiler_config\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mget_compiler_config\u001b[0m  \u001b[0;31m# type: ignore[attr-defined]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    348\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Eval logic"
      ],
      "metadata": {
        "id": "-g3WkdNMXXke"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import f1_score, classification_report, confusion_matrix, accuracy_score\n",
        "\n",
        "def eval(model,testloader,device):\n",
        "    # Move the model to CPU\n",
        "    model.cpu()\n",
        "    correct = 0\n",
        "    total = 0\n",
        "    all_labels = []\n",
        "    all_predicted = []\n",
        "\n",
        "    with torch.no_grad():\n",
        "        for data in testloader:\n",
        "            inputs, labels = data\n",
        "            # Move data to CPU\n",
        "            inputs = inputs.cpu()\n",
        "            labels = labels.cpu()\n",
        "\n",
        "            outputs = model(inputs)\n",
        "\n",
        "            outputs = torch.round(outputs)\n",
        "\n",
        "            # Append NumPy arrays instead of tensors\n",
        "            all_labels.extend(labels.numpy())\n",
        "            all_predicted.extend(outputs.numpy())\n",
        "\n",
        "    # Calculate F1 score\n",
        "    f1 = f1_score(all_labels, all_predicted, average='weighted')\n",
        "    print('F1 Score: %.2f' % f1)\n",
        "\n",
        "    # Convert to NumPy arrays before using classification_report\n",
        "    all_labels = np.array(all_labels)\n",
        "    all_predicted = np.array(all_predicted)\n",
        "\n",
        "    class_report = classification_report(all_labels, all_predicted)\n",
        "    accuracy = accuracy_score(all_labels, all_predicted)\n",
        "    confusion_Mat = confusion_matrix(all_labels, all_predicted)\n",
        "    print('Classification Report:\\n', class_report)\n",
        "    model.to(device)\n",
        "    return f1, accuracy, confusion_Mat\n",
        "eval(model = mlp, testloader = testloader,device = device)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "O3rrhDc7XVsu",
        "outputId": "f1bdd4b4-01cf-4aba-bf00-78d1330470df"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "F1 Score: 0.63\n",
            "Classification Report:\n",
            "               precision    recall  f1-score   support\n",
            "\n",
            "         0.0       0.70      0.73      0.72       255\n",
            "         1.0       0.50      0.46      0.48       147\n",
            "\n",
            "    accuracy                           0.63       402\n",
            "   macro avg       0.60      0.60      0.60       402\n",
            "weighted avg       0.63      0.63      0.63       402\n",
            "\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(0.6288991122394527,\n",
              " 0.6318407960199005,\n",
              " array([[186,  69],\n",
              "        [ 79,  68]]))"
            ]
          },
          "metadata": {},
          "execution_count": 28
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Grid Search"
      ],
      "metadata": {
        "id": "FTOf_pQ_JcS4"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from itertools import product\n",
        "\n",
        "grid = {'Hidden_size':[10,50,75,100],\n",
        "        'Learning Rate': [0.001,0.01,0.1,1],\n",
        "        'Epochs': [10,20,50,100],\n",
        "        }\n",
        "\n",
        "\n",
        "all_param_combinations = list(product(*grid.values()))\n",
        "f1s = []\n",
        "maxf1 = 0\n",
        "maxf1index = 0\n",
        "for params in all_param_combinations:\n",
        "    gmlp = ShallowMLP(params[0])\n",
        "    optimizer = torch.optim.Adam(gmlp.parameters(), lr=(params[1]))\n",
        "    train(model = gmlp, optimizer =  optimizer, criterion = criterion ,learning_rate = (params[1]) , n_epochs = (params[2]), trainloader = trainloader, device = device, printbool = False)\n",
        "    f1, _, _ = eval(model = gmlp, testloader = testloader , device = device)\n",
        "    f1s.append(f1)\n",
        "\n",
        "for index, score in f1s:\n",
        "  if score > maxf1:\n",
        "    maxf1 = score\n",
        "    maxf1index = index\n",
        "\n",
        "best_params = all_param_combinations[maxf1index]\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "-U8H8uLUJcAy",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 633
        },
        "outputId": "c7428a97-b5fb-4877-d1af-e9c67f8de572"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Finished Training\n",
            "F1 Score: 0.80\n",
            "Classification Report:\n",
            "               precision    recall  f1-score   support\n",
            "\n",
            "         0.0       0.87      0.81      0.84       255\n",
            "         1.0       0.71      0.78      0.74       147\n",
            "\n",
            "    accuracy                           0.80       402\n",
            "   macro avg       0.79      0.80      0.79       402\n",
            "weighted avg       0.81      0.80      0.80       402\n",
            "\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-29-1a0a289e86c3>\u001b[0m in \u001b[0;36m<cell line: 13>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     14\u001b[0m     \u001b[0mgmlp\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mShallowMLP\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mparams\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     15\u001b[0m     \u001b[0moptimizer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moptim\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mAdam\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgmlp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mparameters\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlr\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mparams\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 16\u001b[0;31m     \u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgmlp\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptimizer\u001b[0m \u001b[0;34m=\u001b[0m  \u001b[0moptimizer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcriterion\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcriterion\u001b[0m \u001b[0;34m,\u001b[0m\u001b[0mlearning_rate\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mparams\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m,\u001b[0m \u001b[0mn_epochs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mparams\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrainloader\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrainloader\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdevice\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdevice\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mprintbool\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     17\u001b[0m     \u001b[0mf1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0meval\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgmlp\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtestloader\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtestloader\u001b[0m \u001b[0;34m,\u001b[0m \u001b[0mdevice\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     18\u001b[0m     \u001b[0mf1s\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mf1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-20-347688f5d846>\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(model, optimizer, criterion, learning_rate, n_epochs, trainloader, device, printbool)\u001b[0m\n\u001b[1;32m     30\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     31\u001b[0m           \u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mzero_grad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 32\u001b[0;31m           \u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     33\u001b[0m           \u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     34\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/_tensor.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(self, gradient, retain_graph, create_graph, inputs)\u001b[0m\n\u001b[1;32m    490\u001b[0m                 \u001b[0minputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    491\u001b[0m             )\n\u001b[0;32m--> 492\u001b[0;31m         torch.autograd.backward(\n\u001b[0m\u001b[1;32m    493\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgradient\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    494\u001b[0m         )\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/autograd/__init__.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables, inputs)\u001b[0m\n\u001b[1;32m    249\u001b[0m     \u001b[0;31m# some Python versions print out the first line of a multi-line function\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    250\u001b[0m     \u001b[0;31m# calls in the traceback and some print out the last line\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 251\u001b[0;31m     Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n\u001b[0m\u001b[1;32m    252\u001b[0m         \u001b[0mtensors\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    253\u001b[0m         \u001b[0mgrad_tensors_\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "best_params = all_param_combinations[50]\n",
        "\n",
        "print(best_params)\n",
        "\n",
        "best_params = all_param_combinations[3]\n",
        "\n",
        "print(best_params)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2vWvjiFLWSBy",
        "outputId": "89fcb269-02bb-4c2e-e326-3597acda6aaf"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(100, 0.001, 50)\n",
            "(10, 0.001, 100)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Cross validation"
      ],
      "metadata": {
        "id": "8HCJ9uUTw3y5"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# cross VAL for best grid search model\n",
        "k = 5\n",
        "fold_size = len(df_encoded) // k\n",
        "\n",
        "hidden_size = 10\n",
        "lr = 0.001\n",
        "epochs = 500\n",
        "criterion = nn.BCELoss()\n",
        "mean_accuracy = 0\n",
        "mean_f1 = 0\n",
        "\n",
        "for fold in range(k):\n",
        "    # Define train and validation indices for this fold\n",
        "    bestMLP = ShallowMLP(hidden_size)\n",
        "    optimizer = torch.optim.Adam(bestMLP.parameters(), lr=lr)\n",
        "\n",
        "    val_start = fold * fold_size\n",
        "    val_end = (fold + 1) * fold_size\n",
        "    kval_data = df_encoded.iloc[val_start:val_end]\n",
        "\n",
        "    ktrain_data = pd.concat([df_encoded.iloc[:val_start], df_encoded.iloc[val_end:]])\n",
        "    kval_data = kval_data.reset_index()\n",
        "    ktrain_data = ktrain_data.reset_index()\n",
        "    ktrain_dataset = MetabolicSyndromeData(dataframe = ktrain_data)\n",
        "    ktest_dataset = MetabolicSyndromeData(dataframe = kval_data)\n",
        "\n",
        "    kbatch_size = 10\n",
        "    ktrain_loader = DataLoader(ktrain_dataset, batch_size=batch_size, shuffle=True)\n",
        "    ktest_loader = DataLoader(ktest_dataset, batch_size=batch_size, shuffle=True)\n",
        "\n",
        "    train(model = bestMLP, optimizer = optimizer, criterion = criterion ,learning_rate = lr, n_epochs = epochs, trainloader = ktrain_loader, device = device, printbool = True)\n",
        "    f1, accuracy, _ = eval(bestMLP, ktest_loader,device)\n",
        "    mean_accuracy += accuracy\n",
        "    mean_f1 += f1\n",
        "\n",
        "mean_f1 =  mean_f1 / 5.0\n",
        "mean_accuracy = mean_accuracy / 5.0\n",
        "print('Cross Val f1')\n",
        "print(mean_f1)\n",
        "print('Cross Val Accuracy')\n",
        "print(mean_accuracy)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KCH4gTlOR_sp",
        "outputId": "68ee4474-1966-4e79-de4b-9c4073907d07"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1;30;43mStreaming output truncated to the last 5000 lines.\u001b[0m\n",
            "[Epoch 19, Step  1370] loss: 0.070\n",
            "[Epoch 19, Step  1380] loss: 0.199\n",
            "[Epoch 19, Step  1390] loss: 0.438\n",
            "[Epoch 19, Step  1400] loss: 0.099\n",
            "[Epoch 19, Step  1410] loss: 0.286\n",
            "[Epoch 19, Step  1420] loss: 0.320\n",
            "[Epoch 19, Step  1430] loss: 0.405\n",
            "[Epoch 19, Step  1440] loss: 0.063\n",
            "[Epoch 19, Step  1450] loss: 0.099\n",
            "[Epoch 19, Step  1460] loss: 0.197\n",
            "[Epoch 19, Step  1470] loss: 0.152\n",
            "[Epoch 19, Step  1480] loss: 0.041\n",
            "[Epoch 19, Step  1490] loss: 0.205\n",
            "[Epoch 19, Step  1500] loss: 0.232\n",
            "[Epoch 19, Step  1510] loss: 0.331\n",
            "[Epoch 19, Step  1520] loss: 0.419\n",
            "[Epoch 19, Step  1530] loss: 0.334\n",
            "[Epoch 19, Step  1540] loss: 0.448\n",
            "[Epoch 19, Step  1550] loss: 0.120\n",
            "[Epoch 19, Step  1560] loss: 0.381\n",
            "[Epoch 19, Step  1570] loss: 0.152\n",
            "[Epoch 19, Step  1580] loss: 0.688\n",
            "[Epoch 19, Step  1590] loss: 0.347\n",
            "[Epoch 19, Step  1600] loss: 0.501\n",
            "[Epoch 20, Step    10] loss: 0.246\n",
            "[Epoch 20, Step    20] loss: 0.463\n",
            "[Epoch 20, Step    30] loss: 0.219\n",
            "[Epoch 20, Step    40] loss: 0.234\n",
            "[Epoch 20, Step    50] loss: 0.249\n",
            "[Epoch 20, Step    60] loss: 0.107\n",
            "[Epoch 20, Step    70] loss: 0.245\n",
            "[Epoch 20, Step    80] loss: 0.423\n",
            "[Epoch 20, Step    90] loss: 0.247\n",
            "[Epoch 20, Step   100] loss: 0.113\n",
            "[Epoch 20, Step   110] loss: 0.090\n",
            "[Epoch 20, Step   120] loss: 0.064\n",
            "[Epoch 20, Step   130] loss: 0.160\n",
            "[Epoch 20, Step   140] loss: 0.335\n",
            "[Epoch 20, Step   150] loss: 0.298\n",
            "[Epoch 20, Step   160] loss: 0.307\n",
            "[Epoch 20, Step   170] loss: 0.052\n",
            "[Epoch 20, Step   180] loss: 0.321\n",
            "[Epoch 20, Step   190] loss: 0.499\n",
            "[Epoch 20, Step   200] loss: 0.416\n",
            "[Epoch 20, Step   210] loss: 0.319\n",
            "[Epoch 20, Step   220] loss: 0.092\n",
            "[Epoch 20, Step   230] loss: 0.504\n",
            "[Epoch 20, Step   240] loss: 0.362\n",
            "[Epoch 20, Step   250] loss: 0.078\n",
            "[Epoch 20, Step   260] loss: 0.214\n",
            "[Epoch 20, Step   270] loss: 0.142\n",
            "[Epoch 20, Step   280] loss: 0.185\n",
            "[Epoch 20, Step   290] loss: 0.245\n",
            "[Epoch 20, Step   300] loss: 0.315\n",
            "[Epoch 20, Step   310] loss: 0.060\n",
            "[Epoch 20, Step   320] loss: 0.305\n",
            "[Epoch 20, Step   330] loss: 0.543\n",
            "[Epoch 20, Step   340] loss: 0.108\n",
            "[Epoch 20, Step   350] loss: 0.354\n",
            "[Epoch 20, Step   360] loss: 0.309\n",
            "[Epoch 20, Step   370] loss: 0.314\n",
            "[Epoch 20, Step   380] loss: 0.673\n",
            "[Epoch 20, Step   390] loss: 0.330\n",
            "[Epoch 20, Step   400] loss: 0.237\n",
            "[Epoch 20, Step   410] loss: 0.189\n",
            "[Epoch 20, Step   420] loss: 0.127\n",
            "[Epoch 20, Step   430] loss: 0.631\n",
            "[Epoch 20, Step   440] loss: 0.478\n",
            "[Epoch 20, Step   450] loss: 0.402\n",
            "[Epoch 20, Step   460] loss: 0.330\n",
            "[Epoch 20, Step   470] loss: 0.282\n",
            "[Epoch 20, Step   480] loss: 0.517\n",
            "[Epoch 20, Step   490] loss: 0.167\n",
            "[Epoch 20, Step   500] loss: 0.230\n",
            "[Epoch 20, Step   510] loss: 0.265\n",
            "[Epoch 20, Step   520] loss: 0.334\n",
            "[Epoch 20, Step   530] loss: 0.080\n",
            "[Epoch 20, Step   540] loss: 0.181\n",
            "[Epoch 20, Step   550] loss: 0.400\n",
            "[Epoch 20, Step   560] loss: 0.744\n",
            "[Epoch 20, Step   570] loss: 0.327\n",
            "[Epoch 20, Step   580] loss: 0.233\n",
            "[Epoch 20, Step   590] loss: 0.302\n",
            "[Epoch 20, Step   600] loss: 0.169\n",
            "[Epoch 20, Step   610] loss: 0.055\n",
            "[Epoch 20, Step   620] loss: 0.161\n",
            "[Epoch 20, Step   630] loss: 0.175\n",
            "[Epoch 20, Step   640] loss: 0.234\n",
            "[Epoch 20, Step   650] loss: 0.138\n",
            "[Epoch 20, Step   660] loss: 0.165\n",
            "[Epoch 20, Step   670] loss: 0.346\n",
            "[Epoch 20, Step   680] loss: 0.260\n",
            "[Epoch 20, Step   690] loss: 0.244\n",
            "[Epoch 20, Step   700] loss: 0.270\n",
            "[Epoch 20, Step   710] loss: 0.681\n",
            "[Epoch 20, Step   720] loss: 0.238\n",
            "[Epoch 20, Step   730] loss: 0.352\n",
            "[Epoch 20, Step   740] loss: 0.656\n",
            "[Epoch 20, Step   750] loss: 0.165\n",
            "[Epoch 20, Step   760] loss: 0.445\n",
            "[Epoch 20, Step   770] loss: 0.222\n",
            "[Epoch 20, Step   780] loss: 0.226\n",
            "[Epoch 20, Step   790] loss: 0.191\n",
            "[Epoch 20, Step   800] loss: 0.134\n",
            "[Epoch 20, Step   810] loss: 0.468\n",
            "[Epoch 20, Step   820] loss: 0.273\n",
            "[Epoch 20, Step   830] loss: 0.212\n",
            "[Epoch 20, Step   840] loss: 0.087\n",
            "[Epoch 20, Step   850] loss: 0.155\n",
            "[Epoch 20, Step   860] loss: 0.387\n",
            "[Epoch 20, Step   870] loss: 0.111\n",
            "[Epoch 20, Step   880] loss: 0.250\n",
            "[Epoch 20, Step   890] loss: 0.103\n",
            "[Epoch 20, Step   900] loss: 0.082\n",
            "[Epoch 20, Step   910] loss: 0.436\n",
            "[Epoch 20, Step   920] loss: 0.258\n",
            "[Epoch 20, Step   930] loss: 0.499\n",
            "[Epoch 20, Step   940] loss: 0.246\n",
            "[Epoch 20, Step   950] loss: 0.399\n",
            "[Epoch 20, Step   960] loss: 0.159\n",
            "[Epoch 20, Step   970] loss: 0.609\n",
            "[Epoch 20, Step   980] loss: 0.084\n",
            "[Epoch 20, Step   990] loss: 0.349\n",
            "[Epoch 20, Step  1000] loss: 0.284\n",
            "[Epoch 20, Step  1010] loss: 0.606\n",
            "[Epoch 20, Step  1020] loss: 0.129\n",
            "[Epoch 20, Step  1030] loss: 0.078\n",
            "[Epoch 20, Step  1040] loss: 0.219\n",
            "[Epoch 20, Step  1050] loss: 0.178\n",
            "[Epoch 20, Step  1060] loss: 0.241\n",
            "[Epoch 20, Step  1070] loss: 0.368\n",
            "[Epoch 20, Step  1080] loss: 0.151\n",
            "[Epoch 20, Step  1090] loss: 0.426\n",
            "[Epoch 20, Step  1100] loss: 0.379\n",
            "[Epoch 20, Step  1110] loss: 0.333\n",
            "[Epoch 20, Step  1120] loss: 0.357\n",
            "[Epoch 20, Step  1130] loss: 0.179\n",
            "[Epoch 20, Step  1140] loss: 0.251\n",
            "[Epoch 20, Step  1150] loss: 0.329\n",
            "[Epoch 20, Step  1160] loss: 0.316\n",
            "[Epoch 20, Step  1170] loss: 0.087\n",
            "[Epoch 20, Step  1180] loss: 0.195\n",
            "[Epoch 20, Step  1190] loss: 0.310\n",
            "[Epoch 20, Step  1200] loss: 0.166\n",
            "[Epoch 20, Step  1210] loss: 0.156\n",
            "[Epoch 20, Step  1220] loss: 0.300\n",
            "[Epoch 20, Step  1230] loss: 0.832\n",
            "[Epoch 20, Step  1240] loss: 0.353\n",
            "[Epoch 20, Step  1250] loss: 0.372\n",
            "[Epoch 20, Step  1260] loss: 0.323\n",
            "[Epoch 20, Step  1270] loss: 0.491\n",
            "[Epoch 20, Step  1280] loss: 0.240\n",
            "[Epoch 20, Step  1290] loss: 0.334\n",
            "[Epoch 20, Step  1300] loss: 0.043\n",
            "[Epoch 20, Step  1310] loss: 0.277\n",
            "[Epoch 20, Step  1320] loss: 0.353\n",
            "[Epoch 20, Step  1330] loss: 0.081\n",
            "[Epoch 20, Step  1340] loss: 0.355\n",
            "[Epoch 20, Step  1350] loss: 0.330\n",
            "[Epoch 20, Step  1360] loss: 0.639\n",
            "[Epoch 20, Step  1370] loss: 0.154\n",
            "[Epoch 20, Step  1380] loss: 0.164\n",
            "[Epoch 20, Step  1390] loss: 0.492\n",
            "[Epoch 20, Step  1400] loss: 0.327\n",
            "[Epoch 20, Step  1410] loss: 0.378\n",
            "[Epoch 20, Step  1420] loss: 0.264\n",
            "[Epoch 20, Step  1430] loss: 0.399\n",
            "[Epoch 20, Step  1440] loss: 0.262\n",
            "[Epoch 20, Step  1450] loss: 0.312\n",
            "[Epoch 20, Step  1460] loss: 0.185\n",
            "[Epoch 20, Step  1470] loss: 0.134\n",
            "[Epoch 20, Step  1480] loss: 0.460\n",
            "[Epoch 20, Step  1490] loss: 0.385\n",
            "[Epoch 20, Step  1500] loss: 0.308\n",
            "[Epoch 20, Step  1510] loss: 0.462\n",
            "[Epoch 20, Step  1520] loss: 0.268\n",
            "[Epoch 20, Step  1530] loss: 0.565\n",
            "[Epoch 20, Step  1540] loss: 0.269\n",
            "[Epoch 20, Step  1550] loss: 0.377\n",
            "[Epoch 20, Step  1560] loss: 0.098\n",
            "[Epoch 20, Step  1570] loss: 0.506\n",
            "[Epoch 20, Step  1580] loss: 0.282\n",
            "[Epoch 20, Step  1590] loss: 0.321\n",
            "[Epoch 20, Step  1600] loss: 0.309\n",
            "[Epoch 21, Step    10] loss: 0.067\n",
            "[Epoch 21, Step    20] loss: 0.085\n",
            "[Epoch 21, Step    30] loss: 0.382\n",
            "[Epoch 21, Step    40] loss: 0.380\n",
            "[Epoch 21, Step    50] loss: 0.133\n",
            "[Epoch 21, Step    60] loss: 0.432\n",
            "[Epoch 21, Step    70] loss: 0.558\n",
            "[Epoch 21, Step    80] loss: 0.443\n",
            "[Epoch 21, Step    90] loss: 0.174\n",
            "[Epoch 21, Step   100] loss: 0.221\n",
            "[Epoch 21, Step   110] loss: 0.123\n",
            "[Epoch 21, Step   120] loss: 0.298\n",
            "[Epoch 21, Step   130] loss: 0.098\n",
            "[Epoch 21, Step   140] loss: 0.244\n",
            "[Epoch 21, Step   150] loss: 0.136\n",
            "[Epoch 21, Step   160] loss: 0.057\n",
            "[Epoch 21, Step   170] loss: 0.386\n",
            "[Epoch 21, Step   180] loss: 0.163\n",
            "[Epoch 21, Step   190] loss: 0.218\n",
            "[Epoch 21, Step   200] loss: 0.465\n",
            "[Epoch 21, Step   210] loss: 0.100\n",
            "[Epoch 21, Step   220] loss: 0.078\n",
            "[Epoch 21, Step   230] loss: 0.068\n",
            "[Epoch 21, Step   240] loss: 0.518\n",
            "[Epoch 21, Step   250] loss: 0.139\n",
            "[Epoch 21, Step   260] loss: 0.400\n",
            "[Epoch 21, Step   270] loss: 0.620\n",
            "[Epoch 21, Step   280] loss: 0.228\n",
            "[Epoch 21, Step   290] loss: 0.119\n",
            "[Epoch 21, Step   300] loss: 0.152\n",
            "[Epoch 21, Step   310] loss: 0.082\n",
            "[Epoch 21, Step   320] loss: 0.106\n",
            "[Epoch 21, Step   330] loss: 0.289\n",
            "[Epoch 21, Step   340] loss: 0.524\n",
            "[Epoch 21, Step   350] loss: 0.111\n",
            "[Epoch 21, Step   360] loss: 0.317\n",
            "[Epoch 21, Step   370] loss: 0.436\n",
            "[Epoch 21, Step   380] loss: 0.158\n",
            "[Epoch 21, Step   390] loss: 0.236\n",
            "[Epoch 21, Step   400] loss: 0.151\n",
            "[Epoch 21, Step   410] loss: 0.377\n",
            "[Epoch 21, Step   420] loss: 0.213\n",
            "[Epoch 21, Step   430] loss: 0.407\n",
            "[Epoch 21, Step   440] loss: 0.152\n",
            "[Epoch 21, Step   450] loss: 0.297\n",
            "[Epoch 21, Step   460] loss: 0.037\n",
            "[Epoch 21, Step   470] loss: 0.068\n",
            "[Epoch 21, Step   480] loss: 0.433\n",
            "[Epoch 21, Step   490] loss: 0.401\n",
            "[Epoch 21, Step   500] loss: 0.544\n",
            "[Epoch 21, Step   510] loss: 0.120\n",
            "[Epoch 21, Step   520] loss: 0.839\n",
            "[Epoch 21, Step   530] loss: 0.284\n",
            "[Epoch 21, Step   540] loss: 0.618\n",
            "[Epoch 21, Step   550] loss: 0.191\n",
            "[Epoch 21, Step   560] loss: 0.281\n",
            "[Epoch 21, Step   570] loss: 0.158\n",
            "[Epoch 21, Step   580] loss: 0.292\n",
            "[Epoch 21, Step   590] loss: 0.395\n",
            "[Epoch 21, Step   600] loss: 0.198\n",
            "[Epoch 21, Step   610] loss: 0.300\n",
            "[Epoch 21, Step   620] loss: 0.237\n",
            "[Epoch 21, Step   630] loss: 0.108\n",
            "[Epoch 21, Step   640] loss: 0.271\n",
            "[Epoch 21, Step   650] loss: 0.332\n",
            "[Epoch 21, Step   660] loss: 0.275\n",
            "[Epoch 21, Step   670] loss: 0.347\n",
            "[Epoch 21, Step   680] loss: 0.439\n",
            "[Epoch 21, Step   690] loss: 0.102\n",
            "[Epoch 21, Step   700] loss: 0.251\n",
            "[Epoch 21, Step   710] loss: 0.417\n",
            "[Epoch 21, Step   720] loss: 0.378\n",
            "[Epoch 21, Step   730] loss: 0.206\n",
            "[Epoch 21, Step   740] loss: 0.343\n",
            "[Epoch 21, Step   750] loss: 0.314\n",
            "[Epoch 21, Step   760] loss: 0.411\n",
            "[Epoch 21, Step   770] loss: 0.281\n",
            "[Epoch 21, Step   780] loss: 0.793\n",
            "[Epoch 21, Step   790] loss: 0.192\n",
            "[Epoch 21, Step   800] loss: 0.367\n",
            "[Epoch 21, Step   810] loss: 0.334\n",
            "[Epoch 21, Step   820] loss: 0.203\n",
            "[Epoch 21, Step   830] loss: 0.205\n",
            "[Epoch 21, Step   840] loss: 0.242\n",
            "[Epoch 21, Step   850] loss: 0.317\n",
            "[Epoch 21, Step   860] loss: 0.426\n",
            "[Epoch 21, Step   870] loss: 0.187\n",
            "[Epoch 21, Step   880] loss: 0.246\n",
            "[Epoch 21, Step   890] loss: 0.209\n",
            "[Epoch 21, Step   900] loss: 0.207\n",
            "[Epoch 21, Step   910] loss: 0.459\n",
            "[Epoch 21, Step   920] loss: 0.137\n",
            "[Epoch 21, Step   930] loss: 0.207\n",
            "[Epoch 21, Step   940] loss: 0.288\n",
            "[Epoch 21, Step   950] loss: 0.201\n",
            "[Epoch 21, Step   960] loss: 0.379\n",
            "[Epoch 21, Step   970] loss: 0.217\n",
            "[Epoch 21, Step   980] loss: 0.637\n",
            "[Epoch 21, Step   990] loss: 0.134\n",
            "[Epoch 21, Step  1000] loss: 0.064\n",
            "[Epoch 21, Step  1010] loss: 0.534\n",
            "[Epoch 21, Step  1020] loss: 0.172\n",
            "[Epoch 21, Step  1030] loss: 0.148\n",
            "[Epoch 21, Step  1040] loss: 0.305\n",
            "[Epoch 21, Step  1050] loss: 0.249\n",
            "[Epoch 21, Step  1060] loss: 0.209\n",
            "[Epoch 21, Step  1070] loss: 0.207\n",
            "[Epoch 21, Step  1080] loss: 0.165\n",
            "[Epoch 21, Step  1090] loss: 1.017\n",
            "[Epoch 21, Step  1100] loss: 0.422\n",
            "[Epoch 21, Step  1110] loss: 0.467\n",
            "[Epoch 21, Step  1120] loss: 0.232\n",
            "[Epoch 21, Step  1130] loss: 0.257\n",
            "[Epoch 21, Step  1140] loss: 0.342\n",
            "[Epoch 21, Step  1150] loss: 0.345\n",
            "[Epoch 21, Step  1160] loss: 0.241\n",
            "[Epoch 21, Step  1170] loss: 0.264\n",
            "[Epoch 21, Step  1180] loss: 0.319\n",
            "[Epoch 21, Step  1190] loss: 0.203\n",
            "[Epoch 21, Step  1200] loss: 0.241\n",
            "[Epoch 21, Step  1210] loss: 0.245\n",
            "[Epoch 21, Step  1220] loss: 0.313\n",
            "[Epoch 21, Step  1230] loss: 0.248\n",
            "[Epoch 21, Step  1240] loss: 0.203\n",
            "[Epoch 21, Step  1250] loss: 0.077\n",
            "[Epoch 21, Step  1260] loss: 0.524\n",
            "[Epoch 21, Step  1270] loss: 0.327\n",
            "[Epoch 21, Step  1280] loss: 0.071\n",
            "[Epoch 21, Step  1290] loss: 0.304\n",
            "[Epoch 21, Step  1300] loss: 0.165\n",
            "[Epoch 21, Step  1310] loss: 0.341\n",
            "[Epoch 21, Step  1320] loss: 0.249\n",
            "[Epoch 21, Step  1330] loss: 0.062\n",
            "[Epoch 21, Step  1340] loss: 0.225\n",
            "[Epoch 21, Step  1350] loss: 0.214\n",
            "[Epoch 21, Step  1360] loss: 0.326\n",
            "[Epoch 21, Step  1370] loss: 0.455\n",
            "[Epoch 21, Step  1380] loss: 0.396\n",
            "[Epoch 21, Step  1390] loss: 0.265\n",
            "[Epoch 21, Step  1400] loss: 0.379\n",
            "[Epoch 21, Step  1410] loss: 0.106\n",
            "[Epoch 21, Step  1420] loss: 0.179\n",
            "[Epoch 21, Step  1430] loss: 0.256\n",
            "[Epoch 21, Step  1440] loss: 0.130\n",
            "[Epoch 21, Step  1450] loss: 0.636\n",
            "[Epoch 21, Step  1460] loss: 0.587\n",
            "[Epoch 21, Step  1470] loss: 0.187\n",
            "[Epoch 21, Step  1480] loss: 0.103\n",
            "[Epoch 21, Step  1490] loss: 0.425\n",
            "[Epoch 21, Step  1500] loss: 0.478\n",
            "[Epoch 21, Step  1510] loss: 0.312\n",
            "[Epoch 21, Step  1520] loss: 0.536\n",
            "[Epoch 21, Step  1530] loss: 0.263\n",
            "[Epoch 21, Step  1540] loss: 0.637\n",
            "[Epoch 21, Step  1550] loss: 0.176\n",
            "[Epoch 21, Step  1560] loss: 0.138\n",
            "[Epoch 21, Step  1570] loss: 0.528\n",
            "[Epoch 21, Step  1580] loss: 0.100\n",
            "[Epoch 21, Step  1590] loss: 0.216\n",
            "[Epoch 21, Step  1600] loss: 0.515\n",
            "[Epoch 22, Step    10] loss: 0.360\n",
            "[Epoch 22, Step    20] loss: 0.085\n",
            "[Epoch 22, Step    30] loss: 0.468\n",
            "[Epoch 22, Step    40] loss: 0.061\n",
            "[Epoch 22, Step    50] loss: 0.356\n",
            "[Epoch 22, Step    60] loss: 0.225\n",
            "[Epoch 22, Step    70] loss: 0.351\n",
            "[Epoch 22, Step    80] loss: 0.454\n",
            "[Epoch 22, Step    90] loss: 0.357\n",
            "[Epoch 22, Step   100] loss: 0.369\n",
            "[Epoch 22, Step   110] loss: 0.228\n",
            "[Epoch 22, Step   120] loss: 0.142\n",
            "[Epoch 22, Step   130] loss: 0.058\n",
            "[Epoch 22, Step   140] loss: 0.250\n",
            "[Epoch 22, Step   150] loss: 0.198\n",
            "[Epoch 22, Step   160] loss: 0.206\n",
            "[Epoch 22, Step   170] loss: 0.398\n",
            "[Epoch 22, Step   180] loss: 0.107\n",
            "[Epoch 22, Step   190] loss: 0.569\n",
            "[Epoch 22, Step   200] loss: 0.285\n",
            "[Epoch 22, Step   210] loss: 0.185\n",
            "[Epoch 22, Step   220] loss: 0.195\n",
            "[Epoch 22, Step   230] loss: 0.330\n",
            "[Epoch 22, Step   240] loss: 0.159\n",
            "[Epoch 22, Step   250] loss: 0.098\n",
            "[Epoch 22, Step   260] loss: 0.068\n",
            "[Epoch 22, Step   270] loss: 0.201\n",
            "[Epoch 22, Step   280] loss: 0.209\n",
            "[Epoch 22, Step   290] loss: 0.646\n",
            "[Epoch 22, Step   300] loss: 0.286\n",
            "[Epoch 22, Step   310] loss: 0.124\n",
            "[Epoch 22, Step   320] loss: 0.254\n",
            "[Epoch 22, Step   330] loss: 0.279\n",
            "[Epoch 22, Step   340] loss: 0.277\n",
            "[Epoch 22, Step   350] loss: 0.339\n",
            "[Epoch 22, Step   360] loss: 0.118\n",
            "[Epoch 22, Step   370] loss: 0.615\n",
            "[Epoch 22, Step   380] loss: 0.447\n",
            "[Epoch 22, Step   390] loss: 0.231\n",
            "[Epoch 22, Step   400] loss: 0.271\n",
            "[Epoch 22, Step   410] loss: 0.286\n",
            "[Epoch 22, Step   420] loss: 0.097\n",
            "[Epoch 22, Step   430] loss: 0.403\n",
            "[Epoch 22, Step   440] loss: 0.234\n",
            "[Epoch 22, Step   450] loss: 0.241\n",
            "[Epoch 22, Step   460] loss: 0.418\n",
            "[Epoch 22, Step   470] loss: 0.146\n",
            "[Epoch 22, Step   480] loss: 0.504\n",
            "[Epoch 22, Step   490] loss: 0.347\n",
            "[Epoch 22, Step   500] loss: 0.082\n",
            "[Epoch 22, Step   510] loss: 0.181\n",
            "[Epoch 22, Step   520] loss: 0.452\n",
            "[Epoch 22, Step   530] loss: 0.282\n",
            "[Epoch 22, Step   540] loss: 0.597\n",
            "[Epoch 22, Step   550] loss: 0.323\n",
            "[Epoch 22, Step   560] loss: 0.419\n",
            "[Epoch 22, Step   570] loss: 0.082\n",
            "[Epoch 22, Step   580] loss: 0.346\n",
            "[Epoch 22, Step   590] loss: 0.165\n",
            "[Epoch 22, Step   600] loss: 0.240\n",
            "[Epoch 22, Step   610] loss: 0.317\n",
            "[Epoch 22, Step   620] loss: 0.191\n",
            "[Epoch 22, Step   630] loss: 0.232\n",
            "[Epoch 22, Step   640] loss: 0.650\n",
            "[Epoch 22, Step   650] loss: 0.609\n",
            "[Epoch 22, Step   660] loss: 0.085\n",
            "[Epoch 22, Step   670] loss: 0.338\n",
            "[Epoch 22, Step   680] loss: 0.442\n",
            "[Epoch 22, Step   690] loss: 0.125\n",
            "[Epoch 22, Step   700] loss: 0.225\n",
            "[Epoch 22, Step   710] loss: 0.182\n",
            "[Epoch 22, Step   720] loss: 0.202\n",
            "[Epoch 22, Step   730] loss: 0.249\n",
            "[Epoch 22, Step   740] loss: 0.330\n",
            "[Epoch 22, Step   750] loss: 0.219\n",
            "[Epoch 22, Step   760] loss: 0.452\n",
            "[Epoch 22, Step   770] loss: 0.081\n",
            "[Epoch 22, Step   780] loss: 0.469\n",
            "[Epoch 22, Step   790] loss: 0.178\n",
            "[Epoch 22, Step   800] loss: 0.443\n",
            "[Epoch 22, Step   810] loss: 0.294\n",
            "[Epoch 22, Step   820] loss: 0.405\n",
            "[Epoch 22, Step   830] loss: 0.563\n",
            "[Epoch 22, Step   840] loss: 0.267\n",
            "[Epoch 22, Step   850] loss: 0.223\n",
            "[Epoch 22, Step   860] loss: 0.459\n",
            "[Epoch 22, Step   870] loss: 0.369\n",
            "[Epoch 22, Step   880] loss: 0.255\n",
            "[Epoch 22, Step   890] loss: 0.227\n",
            "[Epoch 22, Step   900] loss: 0.414\n",
            "[Epoch 22, Step   910] loss: 0.107\n",
            "[Epoch 22, Step   920] loss: 0.092\n",
            "[Epoch 22, Step   930] loss: 0.590\n",
            "[Epoch 22, Step   940] loss: 0.757\n",
            "[Epoch 22, Step   950] loss: 0.213\n",
            "[Epoch 22, Step   960] loss: 0.176\n",
            "[Epoch 22, Step   970] loss: 0.385\n",
            "[Epoch 22, Step   980] loss: 0.144\n",
            "[Epoch 22, Step   990] loss: 0.521\n",
            "[Epoch 22, Step  1000] loss: 0.188\n",
            "[Epoch 22, Step  1010] loss: 0.574\n",
            "[Epoch 22, Step  1020] loss: 0.189\n",
            "[Epoch 22, Step  1030] loss: 0.376\n",
            "[Epoch 22, Step  1040] loss: 0.441\n",
            "[Epoch 22, Step  1050] loss: 0.369\n",
            "[Epoch 22, Step  1060] loss: 0.272\n",
            "[Epoch 22, Step  1070] loss: 0.387\n",
            "[Epoch 22, Step  1080] loss: 0.257\n",
            "[Epoch 22, Step  1090] loss: 0.396\n",
            "[Epoch 22, Step  1100] loss: 0.407\n",
            "[Epoch 22, Step  1110] loss: 0.312\n",
            "[Epoch 22, Step  1120] loss: 0.099\n",
            "[Epoch 22, Step  1130] loss: 0.100\n",
            "[Epoch 22, Step  1140] loss: 0.144\n",
            "[Epoch 22, Step  1150] loss: 0.326\n",
            "[Epoch 22, Step  1160] loss: 0.322\n",
            "[Epoch 22, Step  1170] loss: 0.071\n",
            "[Epoch 22, Step  1180] loss: 0.384\n",
            "[Epoch 22, Step  1190] loss: 0.229\n",
            "[Epoch 22, Step  1200] loss: 0.408\n",
            "[Epoch 22, Step  1210] loss: 0.253\n",
            "[Epoch 22, Step  1220] loss: 0.075\n",
            "[Epoch 22, Step  1230] loss: 0.190\n",
            "[Epoch 22, Step  1240] loss: 0.261\n",
            "[Epoch 22, Step  1250] loss: 0.191\n",
            "[Epoch 22, Step  1260] loss: 0.337\n",
            "[Epoch 22, Step  1270] loss: 0.181\n",
            "[Epoch 22, Step  1280] loss: 0.111\n",
            "[Epoch 22, Step  1290] loss: 0.382\n",
            "[Epoch 22, Step  1300] loss: 0.280\n",
            "[Epoch 22, Step  1310] loss: 0.144\n",
            "[Epoch 22, Step  1320] loss: 0.227\n",
            "[Epoch 22, Step  1330] loss: 0.270\n",
            "[Epoch 22, Step  1340] loss: 0.143\n",
            "[Epoch 22, Step  1350] loss: 0.367\n",
            "[Epoch 22, Step  1360] loss: 0.179\n",
            "[Epoch 22, Step  1370] loss: 0.221\n",
            "[Epoch 22, Step  1380] loss: 0.219\n",
            "[Epoch 22, Step  1390] loss: 0.273\n",
            "[Epoch 22, Step  1400] loss: 0.303\n",
            "[Epoch 22, Step  1410] loss: 0.333\n",
            "[Epoch 22, Step  1420] loss: 0.140\n",
            "[Epoch 22, Step  1430] loss: 0.178\n",
            "[Epoch 22, Step  1440] loss: 0.111\n",
            "[Epoch 22, Step  1450] loss: 0.300\n",
            "[Epoch 22, Step  1460] loss: 0.270\n",
            "[Epoch 22, Step  1470] loss: 0.401\n",
            "[Epoch 22, Step  1480] loss: 0.145\n",
            "[Epoch 22, Step  1490] loss: 0.276\n",
            "[Epoch 22, Step  1500] loss: 0.256\n",
            "[Epoch 22, Step  1510] loss: 0.229\n",
            "[Epoch 22, Step  1520] loss: 0.137\n",
            "[Epoch 22, Step  1530] loss: 0.191\n",
            "[Epoch 22, Step  1540] loss: 0.234\n",
            "[Epoch 22, Step  1550] loss: 0.199\n",
            "[Epoch 22, Step  1560] loss: 0.380\n",
            "[Epoch 22, Step  1570] loss: 0.442\n",
            "[Epoch 22, Step  1580] loss: 0.173\n",
            "[Epoch 22, Step  1590] loss: 0.261\n",
            "[Epoch 22, Step  1600] loss: 0.248\n",
            "[Epoch 23, Step    10] loss: 0.179\n",
            "[Epoch 23, Step    20] loss: 0.853\n",
            "[Epoch 23, Step    30] loss: 0.271\n",
            "[Epoch 23, Step    40] loss: 0.202\n",
            "[Epoch 23, Step    50] loss: 0.470\n",
            "[Epoch 23, Step    60] loss: 0.501\n",
            "[Epoch 23, Step    70] loss: 0.216\n",
            "[Epoch 23, Step    80] loss: 0.231\n",
            "[Epoch 23, Step    90] loss: 0.368\n",
            "[Epoch 23, Step   100] loss: 0.345\n",
            "[Epoch 23, Step   110] loss: 0.137\n",
            "[Epoch 23, Step   120] loss: 0.217\n",
            "[Epoch 23, Step   130] loss: 0.237\n",
            "[Epoch 23, Step   140] loss: 0.411\n",
            "[Epoch 23, Step   150] loss: 0.293\n",
            "[Epoch 23, Step   160] loss: 0.387\n",
            "[Epoch 23, Step   170] loss: 0.189\n",
            "[Epoch 23, Step   180] loss: 0.295\n",
            "[Epoch 23, Step   190] loss: 0.205\n",
            "[Epoch 23, Step   200] loss: 0.417\n",
            "[Epoch 23, Step   210] loss: 0.407\n",
            "[Epoch 23, Step   220] loss: 0.384\n",
            "[Epoch 23, Step   230] loss: 0.319\n",
            "[Epoch 23, Step   240] loss: 0.267\n",
            "[Epoch 23, Step   250] loss: 0.142\n",
            "[Epoch 23, Step   260] loss: 0.208\n",
            "[Epoch 23, Step   270] loss: 0.519\n",
            "[Epoch 23, Step   280] loss: 0.150\n",
            "[Epoch 23, Step   290] loss: 0.154\n",
            "[Epoch 23, Step   300] loss: 0.599\n",
            "[Epoch 23, Step   310] loss: 0.137\n",
            "[Epoch 23, Step   320] loss: 0.045\n",
            "[Epoch 23, Step   330] loss: 0.130\n",
            "[Epoch 23, Step   340] loss: 0.215\n",
            "[Epoch 23, Step   350] loss: 0.224\n",
            "[Epoch 23, Step   360] loss: 0.264\n",
            "[Epoch 23, Step   370] loss: 0.588\n",
            "[Epoch 23, Step   380] loss: 0.203\n",
            "[Epoch 23, Step   390] loss: 0.593\n",
            "[Epoch 23, Step   400] loss: 0.240\n",
            "[Epoch 23, Step   410] loss: 0.112\n",
            "[Epoch 23, Step   420] loss: 0.446\n",
            "[Epoch 23, Step   430] loss: 0.158\n",
            "[Epoch 23, Step   440] loss: 0.246\n",
            "[Epoch 23, Step   450] loss: 0.280\n",
            "[Epoch 23, Step   460] loss: 0.224\n",
            "[Epoch 23, Step   470] loss: 0.578\n",
            "[Epoch 23, Step   480] loss: 0.324\n",
            "[Epoch 23, Step   490] loss: 0.134\n",
            "[Epoch 23, Step   500] loss: 0.269\n",
            "[Epoch 23, Step   510] loss: 0.845\n",
            "[Epoch 23, Step   520] loss: 0.219\n",
            "[Epoch 23, Step   530] loss: 0.318\n",
            "[Epoch 23, Step   540] loss: 0.014\n",
            "[Epoch 23, Step   550] loss: 0.393\n",
            "[Epoch 23, Step   560] loss: 0.211\n",
            "[Epoch 23, Step   570] loss: 0.267\n",
            "[Epoch 23, Step   580] loss: 0.333\n",
            "[Epoch 23, Step   590] loss: 0.259\n",
            "[Epoch 23, Step   600] loss: 0.271\n",
            "[Epoch 23, Step   610] loss: 0.219\n",
            "[Epoch 23, Step   620] loss: 0.072\n",
            "[Epoch 23, Step   630] loss: 0.136\n",
            "[Epoch 23, Step   640] loss: 0.277\n",
            "[Epoch 23, Step   650] loss: 0.178\n",
            "[Epoch 23, Step   660] loss: 0.346\n",
            "[Epoch 23, Step   670] loss: 0.628\n",
            "[Epoch 23, Step   680] loss: 0.520\n",
            "[Epoch 23, Step   690] loss: 0.378\n",
            "[Epoch 23, Step   700] loss: 0.551\n",
            "[Epoch 23, Step   710] loss: 0.288\n",
            "[Epoch 23, Step   720] loss: 0.405\n",
            "[Epoch 23, Step   730] loss: 0.541\n",
            "[Epoch 23, Step   740] loss: 0.142\n",
            "[Epoch 23, Step   750] loss: 0.176\n",
            "[Epoch 23, Step   760] loss: 0.144\n",
            "[Epoch 23, Step   770] loss: 0.317\n",
            "[Epoch 23, Step   780] loss: 0.239\n",
            "[Epoch 23, Step   790] loss: 0.305\n",
            "[Epoch 23, Step   800] loss: 0.078\n",
            "[Epoch 23, Step   810] loss: 0.178\n",
            "[Epoch 23, Step   820] loss: 0.311\n",
            "[Epoch 23, Step   830] loss: 0.166\n",
            "[Epoch 23, Step   840] loss: 0.691\n",
            "[Epoch 23, Step   850] loss: 0.577\n",
            "[Epoch 23, Step   860] loss: 0.123\n",
            "[Epoch 23, Step   870] loss: 0.141\n",
            "[Epoch 23, Step   880] loss: 0.217\n",
            "[Epoch 23, Step   890] loss: 0.206\n",
            "[Epoch 23, Step   900] loss: 0.218\n",
            "[Epoch 23, Step   910] loss: 0.312\n",
            "[Epoch 23, Step   920] loss: 0.296\n",
            "[Epoch 23, Step   930] loss: 0.408\n",
            "[Epoch 23, Step   940] loss: 0.144\n",
            "[Epoch 23, Step   950] loss: 0.125\n",
            "[Epoch 23, Step   960] loss: 0.332\n",
            "[Epoch 23, Step   970] loss: 0.343\n",
            "[Epoch 23, Step   980] loss: 0.085\n",
            "[Epoch 23, Step   990] loss: 0.142\n",
            "[Epoch 23, Step  1000] loss: 0.150\n",
            "[Epoch 23, Step  1010] loss: 0.596\n",
            "[Epoch 23, Step  1020] loss: 0.061\n",
            "[Epoch 23, Step  1030] loss: 0.291\n",
            "[Epoch 23, Step  1040] loss: 0.381\n",
            "[Epoch 23, Step  1050] loss: 0.079\n",
            "[Epoch 23, Step  1060] loss: 0.191\n",
            "[Epoch 23, Step  1070] loss: 0.204\n",
            "[Epoch 23, Step  1080] loss: 0.236\n",
            "[Epoch 23, Step  1090] loss: 0.147\n",
            "[Epoch 23, Step  1100] loss: 0.311\n",
            "[Epoch 23, Step  1110] loss: 0.409\n",
            "[Epoch 23, Step  1120] loss: 0.260\n",
            "[Epoch 23, Step  1130] loss: 0.485\n",
            "[Epoch 23, Step  1140] loss: 0.308\n",
            "[Epoch 23, Step  1150] loss: 0.380\n",
            "[Epoch 23, Step  1160] loss: 0.297\n",
            "[Epoch 23, Step  1170] loss: 0.287\n",
            "[Epoch 23, Step  1180] loss: 0.070\n",
            "[Epoch 23, Step  1190] loss: 0.472\n",
            "[Epoch 23, Step  1200] loss: 0.224\n",
            "[Epoch 23, Step  1210] loss: 0.117\n",
            "[Epoch 23, Step  1220] loss: 0.219\n",
            "[Epoch 23, Step  1230] loss: 0.370\n",
            "[Epoch 23, Step  1240] loss: 0.303\n",
            "[Epoch 23, Step  1250] loss: 0.141\n",
            "[Epoch 23, Step  1260] loss: 0.632\n",
            "[Epoch 23, Step  1270] loss: 0.311\n",
            "[Epoch 23, Step  1280] loss: 0.227\n",
            "[Epoch 23, Step  1290] loss: 0.158\n",
            "[Epoch 23, Step  1300] loss: 0.091\n",
            "[Epoch 23, Step  1310] loss: 0.363\n",
            "[Epoch 23, Step  1320] loss: 0.151\n",
            "[Epoch 23, Step  1330] loss: 0.336\n",
            "[Epoch 23, Step  1340] loss: 0.279\n",
            "[Epoch 23, Step  1350] loss: 0.222\n",
            "[Epoch 23, Step  1360] loss: 0.197\n",
            "[Epoch 23, Step  1370] loss: 0.082\n",
            "[Epoch 23, Step  1380] loss: 0.164\n",
            "[Epoch 23, Step  1390] loss: 0.209\n",
            "[Epoch 23, Step  1400] loss: 0.026\n",
            "[Epoch 23, Step  1410] loss: 0.171\n",
            "[Epoch 23, Step  1420] loss: 0.210\n",
            "[Epoch 23, Step  1430] loss: 0.315\n",
            "[Epoch 23, Step  1440] loss: 0.238\n",
            "[Epoch 23, Step  1450] loss: 0.427\n",
            "[Epoch 23, Step  1460] loss: 0.193\n",
            "[Epoch 23, Step  1470] loss: 0.528\n",
            "[Epoch 23, Step  1480] loss: 0.323\n",
            "[Epoch 23, Step  1490] loss: 0.101\n",
            "[Epoch 23, Step  1500] loss: 0.109\n",
            "[Epoch 23, Step  1510] loss: 0.162\n",
            "[Epoch 23, Step  1520] loss: 0.267\n",
            "[Epoch 23, Step  1530] loss: 0.275\n",
            "[Epoch 23, Step  1540] loss: 0.180\n",
            "[Epoch 23, Step  1550] loss: 0.355\n",
            "[Epoch 23, Step  1560] loss: 0.237\n",
            "[Epoch 23, Step  1570] loss: 0.500\n",
            "[Epoch 23, Step  1580] loss: 0.265\n",
            "[Epoch 23, Step  1590] loss: 0.348\n",
            "[Epoch 23, Step  1600] loss: 0.176\n",
            "[Epoch 24, Step    10] loss: 0.536\n",
            "[Epoch 24, Step    20] loss: 0.302\n",
            "[Epoch 24, Step    30] loss: 0.117\n",
            "[Epoch 24, Step    40] loss: 0.164\n",
            "[Epoch 24, Step    50] loss: 0.091\n",
            "[Epoch 24, Step    60] loss: 0.264\n",
            "[Epoch 24, Step    70] loss: 0.490\n",
            "[Epoch 24, Step    80] loss: 0.311\n",
            "[Epoch 24, Step    90] loss: 0.204\n",
            "[Epoch 24, Step   100] loss: 0.485\n",
            "[Epoch 24, Step   110] loss: 0.487\n",
            "[Epoch 24, Step   120] loss: 0.154\n",
            "[Epoch 24, Step   130] loss: 0.111\n",
            "[Epoch 24, Step   140] loss: 0.553\n",
            "[Epoch 24, Step   150] loss: 0.157\n",
            "[Epoch 24, Step   160] loss: 0.304\n",
            "[Epoch 24, Step   170] loss: 0.281\n",
            "[Epoch 24, Step   180] loss: 0.272\n",
            "[Epoch 24, Step   190] loss: 0.105\n",
            "[Epoch 24, Step   200] loss: 0.048\n",
            "[Epoch 24, Step   210] loss: 0.093\n",
            "[Epoch 24, Step   220] loss: 0.333\n",
            "[Epoch 24, Step   230] loss: 0.199\n",
            "[Epoch 24, Step   240] loss: 0.243\n",
            "[Epoch 24, Step   250] loss: 0.189\n",
            "[Epoch 24, Step   260] loss: 0.193\n",
            "[Epoch 24, Step   270] loss: 0.204\n",
            "[Epoch 24, Step   280] loss: 0.273\n",
            "[Epoch 24, Step   290] loss: 0.524\n",
            "[Epoch 24, Step   300] loss: 0.161\n",
            "[Epoch 24, Step   310] loss: 0.791\n",
            "[Epoch 24, Step   320] loss: 0.277\n",
            "[Epoch 24, Step   330] loss: 0.263\n",
            "[Epoch 24, Step   340] loss: 0.189\n",
            "[Epoch 24, Step   350] loss: 0.539\n",
            "[Epoch 24, Step   360] loss: 0.260\n",
            "[Epoch 24, Step   370] loss: 0.826\n",
            "[Epoch 24, Step   380] loss: 0.191\n",
            "[Epoch 24, Step   390] loss: 0.290\n",
            "[Epoch 24, Step   400] loss: 0.270\n",
            "[Epoch 24, Step   410] loss: 0.245\n",
            "[Epoch 24, Step   420] loss: 0.239\n",
            "[Epoch 24, Step   430] loss: 0.587\n",
            "[Epoch 24, Step   440] loss: 0.378\n",
            "[Epoch 24, Step   450] loss: 0.246\n",
            "[Epoch 24, Step   460] loss: 0.062\n",
            "[Epoch 24, Step   470] loss: 0.313\n",
            "[Epoch 24, Step   480] loss: 0.836\n",
            "[Epoch 24, Step   490] loss: 0.304\n",
            "[Epoch 24, Step   500] loss: 0.184\n",
            "[Epoch 24, Step   510] loss: 0.160\n",
            "[Epoch 24, Step   520] loss: 0.355\n",
            "[Epoch 24, Step   530] loss: 0.370\n",
            "[Epoch 24, Step   540] loss: 0.122\n",
            "[Epoch 24, Step   550] loss: 0.115\n",
            "[Epoch 24, Step   560] loss: 0.526\n",
            "[Epoch 24, Step   570] loss: 0.194\n",
            "[Epoch 24, Step   580] loss: 0.310\n",
            "[Epoch 24, Step   590] loss: 0.163\n",
            "[Epoch 24, Step   600] loss: 0.335\n",
            "[Epoch 24, Step   610] loss: 0.403\n",
            "[Epoch 24, Step   620] loss: 0.110\n",
            "[Epoch 24, Step   630] loss: 0.225\n",
            "[Epoch 24, Step   640] loss: 0.216\n",
            "[Epoch 24, Step   650] loss: 0.176\n",
            "[Epoch 24, Step   660] loss: 0.567\n",
            "[Epoch 24, Step   670] loss: 0.315\n",
            "[Epoch 24, Step   680] loss: 0.411\n",
            "[Epoch 24, Step   690] loss: 0.263\n",
            "[Epoch 24, Step   700] loss: 0.213\n",
            "[Epoch 24, Step   710] loss: 0.246\n",
            "[Epoch 24, Step   720] loss: 0.300\n",
            "[Epoch 24, Step   730] loss: 0.399\n",
            "[Epoch 24, Step   740] loss: 0.334\n",
            "[Epoch 24, Step   750] loss: 0.369\n",
            "[Epoch 24, Step   760] loss: 0.299\n",
            "[Epoch 24, Step   770] loss: 0.327\n",
            "[Epoch 24, Step   780] loss: 0.344\n",
            "[Epoch 24, Step   790] loss: 0.316\n",
            "[Epoch 24, Step   800] loss: 0.124\n",
            "[Epoch 24, Step   810] loss: 0.153\n",
            "[Epoch 24, Step   820] loss: 0.322\n",
            "[Epoch 24, Step   830] loss: 0.193\n",
            "[Epoch 24, Step   840] loss: 0.296\n",
            "[Epoch 24, Step   850] loss: 0.296\n",
            "[Epoch 24, Step   860] loss: 0.369\n",
            "[Epoch 24, Step   870] loss: 0.060\n",
            "[Epoch 24, Step   880] loss: 0.244\n",
            "[Epoch 24, Step   890] loss: 0.160\n",
            "[Epoch 24, Step   900] loss: 0.373\n",
            "[Epoch 24, Step   910] loss: 0.356\n",
            "[Epoch 24, Step   920] loss: 0.177\n",
            "[Epoch 24, Step   930] loss: 0.193\n",
            "[Epoch 24, Step   940] loss: 0.093\n",
            "[Epoch 24, Step   950] loss: 0.086\n",
            "[Epoch 24, Step   960] loss: 0.162\n",
            "[Epoch 24, Step   970] loss: 0.179\n",
            "[Epoch 24, Step   980] loss: 0.185\n",
            "[Epoch 24, Step   990] loss: 0.399\n",
            "[Epoch 24, Step  1000] loss: 0.045\n",
            "[Epoch 24, Step  1010] loss: 0.182\n",
            "[Epoch 24, Step  1020] loss: 0.128\n",
            "[Epoch 24, Step  1030] loss: 0.103\n",
            "[Epoch 24, Step  1040] loss: 0.333\n",
            "[Epoch 24, Step  1050] loss: 0.065\n",
            "[Epoch 24, Step  1060] loss: 0.126\n",
            "[Epoch 24, Step  1070] loss: 0.033\n",
            "[Epoch 24, Step  1080] loss: 0.212\n",
            "[Epoch 24, Step  1090] loss: 0.176\n",
            "[Epoch 24, Step  1100] loss: 0.177\n",
            "[Epoch 24, Step  1110] loss: 0.320\n",
            "[Epoch 24, Step  1120] loss: 0.071\n",
            "[Epoch 24, Step  1130] loss: 0.151\n",
            "[Epoch 24, Step  1140] loss: 0.552\n",
            "[Epoch 24, Step  1150] loss: 0.174\n",
            "[Epoch 24, Step  1160] loss: 0.100\n",
            "[Epoch 24, Step  1170] loss: 0.142\n",
            "[Epoch 24, Step  1180] loss: 0.615\n",
            "[Epoch 24, Step  1190] loss: 0.243\n",
            "[Epoch 24, Step  1200] loss: 0.390\n",
            "[Epoch 24, Step  1210] loss: 0.091\n",
            "[Epoch 24, Step  1220] loss: 0.412\n",
            "[Epoch 24, Step  1230] loss: 0.257\n",
            "[Epoch 24, Step  1240] loss: 0.138\n",
            "[Epoch 24, Step  1250] loss: 0.557\n",
            "[Epoch 24, Step  1260] loss: 0.200\n",
            "[Epoch 24, Step  1270] loss: 0.742\n",
            "[Epoch 24, Step  1280] loss: 0.259\n",
            "[Epoch 24, Step  1290] loss: 0.282\n",
            "[Epoch 24, Step  1300] loss: 0.219\n",
            "[Epoch 24, Step  1310] loss: 0.283\n",
            "[Epoch 24, Step  1320] loss: 0.189\n",
            "[Epoch 24, Step  1330] loss: 0.188\n",
            "[Epoch 24, Step  1340] loss: 0.630\n",
            "[Epoch 24, Step  1350] loss: 0.218\n",
            "[Epoch 24, Step  1360] loss: 0.207\n",
            "[Epoch 24, Step  1370] loss: 0.358\n",
            "[Epoch 24, Step  1380] loss: 0.486\n",
            "[Epoch 24, Step  1390] loss: 0.129\n",
            "[Epoch 24, Step  1400] loss: 0.253\n",
            "[Epoch 24, Step  1410] loss: 0.436\n",
            "[Epoch 24, Step  1420] loss: 0.058\n",
            "[Epoch 24, Step  1430] loss: 0.175\n",
            "[Epoch 24, Step  1440] loss: 0.202\n",
            "[Epoch 24, Step  1450] loss: 0.250\n",
            "[Epoch 24, Step  1460] loss: 0.298\n",
            "[Epoch 24, Step  1470] loss: 0.320\n",
            "[Epoch 24, Step  1480] loss: 0.195\n",
            "[Epoch 24, Step  1490] loss: 0.867\n",
            "[Epoch 24, Step  1500] loss: 0.273\n",
            "[Epoch 24, Step  1510] loss: 0.407\n",
            "[Epoch 24, Step  1520] loss: 0.134\n",
            "[Epoch 24, Step  1530] loss: 0.341\n",
            "[Epoch 24, Step  1540] loss: 0.372\n",
            "[Epoch 24, Step  1550] loss: 0.542\n",
            "[Epoch 24, Step  1560] loss: 0.149\n",
            "[Epoch 24, Step  1570] loss: 0.547\n",
            "[Epoch 24, Step  1580] loss: 0.276\n",
            "[Epoch 24, Step  1590] loss: 0.361\n",
            "[Epoch 24, Step  1600] loss: 0.219\n",
            "[Epoch 25, Step    10] loss: 0.259\n",
            "[Epoch 25, Step    20] loss: 0.075\n",
            "[Epoch 25, Step    30] loss: 0.396\n",
            "[Epoch 25, Step    40] loss: 0.234\n",
            "[Epoch 25, Step    50] loss: 0.109\n",
            "[Epoch 25, Step    60] loss: 0.446\n",
            "[Epoch 25, Step    70] loss: 0.236\n",
            "[Epoch 25, Step    80] loss: 0.467\n",
            "[Epoch 25, Step    90] loss: 0.277\n",
            "[Epoch 25, Step   100] loss: 0.420\n",
            "[Epoch 25, Step   110] loss: 0.513\n",
            "[Epoch 25, Step   120] loss: 0.298\n",
            "[Epoch 25, Step   130] loss: 0.482\n",
            "[Epoch 25, Step   140] loss: 0.170\n",
            "[Epoch 25, Step   150] loss: 0.418\n",
            "[Epoch 25, Step   160] loss: 0.220\n",
            "[Epoch 25, Step   170] loss: 0.095\n",
            "[Epoch 25, Step   180] loss: 0.272\n",
            "[Epoch 25, Step   190] loss: 0.310\n",
            "[Epoch 25, Step   200] loss: 0.083\n",
            "[Epoch 25, Step   210] loss: 0.170\n",
            "[Epoch 25, Step   220] loss: 0.657\n",
            "[Epoch 25, Step   230] loss: 0.326\n",
            "[Epoch 25, Step   240] loss: 0.399\n",
            "[Epoch 25, Step   250] loss: 0.377\n",
            "[Epoch 25, Step   260] loss: 0.027\n",
            "[Epoch 25, Step   270] loss: 0.289\n",
            "[Epoch 25, Step   280] loss: 0.162\n",
            "[Epoch 25, Step   290] loss: 0.146\n",
            "[Epoch 25, Step   300] loss: 0.126\n",
            "[Epoch 25, Step   310] loss: 0.065\n",
            "[Epoch 25, Step   320] loss: 0.259\n",
            "[Epoch 25, Step   330] loss: 0.102\n",
            "[Epoch 25, Step   340] loss: 0.267\n",
            "[Epoch 25, Step   350] loss: 0.243\n",
            "[Epoch 25, Step   360] loss: 0.415\n",
            "[Epoch 25, Step   370] loss: 0.163\n",
            "[Epoch 25, Step   380] loss: 0.267\n",
            "[Epoch 25, Step   390] loss: 0.230\n",
            "[Epoch 25, Step   400] loss: 0.320\n",
            "[Epoch 25, Step   410] loss: 0.193\n",
            "[Epoch 25, Step   420] loss: 0.084\n",
            "[Epoch 25, Step   430] loss: 0.575\n",
            "[Epoch 25, Step   440] loss: 0.226\n",
            "[Epoch 25, Step   450] loss: 0.159\n",
            "[Epoch 25, Step   460] loss: 0.240\n",
            "[Epoch 25, Step   470] loss: 0.236\n",
            "[Epoch 25, Step   480] loss: 0.161\n",
            "[Epoch 25, Step   490] loss: 0.087\n",
            "[Epoch 25, Step   500] loss: 0.528\n",
            "[Epoch 25, Step   510] loss: 0.189\n",
            "[Epoch 25, Step   520] loss: 0.162\n",
            "[Epoch 25, Step   530] loss: 0.309\n",
            "[Epoch 25, Step   540] loss: 0.117\n",
            "[Epoch 25, Step   550] loss: 0.752\n",
            "[Epoch 25, Step   560] loss: 0.282\n",
            "[Epoch 25, Step   570] loss: 0.371\n",
            "[Epoch 25, Step   580] loss: 0.314\n",
            "[Epoch 25, Step   590] loss: 0.335\n",
            "[Epoch 25, Step   600] loss: 0.178\n",
            "[Epoch 25, Step   610] loss: 0.052\n",
            "[Epoch 25, Step   620] loss: 0.388\n",
            "[Epoch 25, Step   630] loss: 0.170\n",
            "[Epoch 25, Step   640] loss: 0.403\n",
            "[Epoch 25, Step   650] loss: 0.348\n",
            "[Epoch 25, Step   660] loss: 0.134\n",
            "[Epoch 25, Step   670] loss: 0.221\n",
            "[Epoch 25, Step   680] loss: 0.212\n",
            "[Epoch 25, Step   690] loss: 0.363\n",
            "[Epoch 25, Step   700] loss: 0.427\n",
            "[Epoch 25, Step   710] loss: 0.180\n",
            "[Epoch 25, Step   720] loss: 0.259\n",
            "[Epoch 25, Step   730] loss: 0.390\n",
            "[Epoch 25, Step   740] loss: 0.635\n",
            "[Epoch 25, Step   750] loss: 0.111\n",
            "[Epoch 25, Step   760] loss: 0.659\n",
            "[Epoch 25, Step   770] loss: 0.326\n",
            "[Epoch 25, Step   780] loss: 0.090\n",
            "[Epoch 25, Step   790] loss: 0.209\n",
            "[Epoch 25, Step   800] loss: 0.162\n",
            "[Epoch 25, Step   810] loss: 0.234\n",
            "[Epoch 25, Step   820] loss: 0.170\n",
            "[Epoch 25, Step   830] loss: 0.180\n",
            "[Epoch 25, Step   840] loss: 0.300\n",
            "[Epoch 25, Step   850] loss: 0.153\n",
            "[Epoch 25, Step   860] loss: 0.296\n",
            "[Epoch 25, Step   870] loss: 0.249\n",
            "[Epoch 25, Step   880] loss: 0.829\n",
            "[Epoch 25, Step   890] loss: 0.740\n",
            "[Epoch 25, Step   900] loss: 0.125\n",
            "[Epoch 25, Step   910] loss: 0.328\n",
            "[Epoch 25, Step   920] loss: 0.119\n",
            "[Epoch 25, Step   930] loss: 0.201\n",
            "[Epoch 25, Step   940] loss: 0.631\n",
            "[Epoch 25, Step   950] loss: 0.169\n",
            "[Epoch 25, Step   960] loss: 0.225\n",
            "[Epoch 25, Step   970] loss: 0.173\n",
            "[Epoch 25, Step   980] loss: 0.264\n",
            "[Epoch 25, Step   990] loss: 0.479\n",
            "[Epoch 25, Step  1000] loss: 0.399\n",
            "[Epoch 25, Step  1010] loss: 0.392\n",
            "[Epoch 25, Step  1020] loss: 0.059\n",
            "[Epoch 25, Step  1030] loss: 0.299\n",
            "[Epoch 25, Step  1040] loss: 0.316\n",
            "[Epoch 25, Step  1050] loss: 0.636\n",
            "[Epoch 25, Step  1060] loss: 0.197\n",
            "[Epoch 25, Step  1070] loss: 0.421\n",
            "[Epoch 25, Step  1080] loss: 0.343\n",
            "[Epoch 25, Step  1090] loss: 0.127\n",
            "[Epoch 25, Step  1100] loss: 0.110\n",
            "[Epoch 25, Step  1110] loss: 0.176\n",
            "[Epoch 25, Step  1120] loss: 0.455\n",
            "[Epoch 25, Step  1130] loss: 0.249\n",
            "[Epoch 25, Step  1140] loss: 0.247\n",
            "[Epoch 25, Step  1150] loss: 0.299\n",
            "[Epoch 25, Step  1160] loss: 0.076\n",
            "[Epoch 25, Step  1170] loss: 0.476\n",
            "[Epoch 25, Step  1180] loss: 0.349\n",
            "[Epoch 25, Step  1190] loss: 0.233\n",
            "[Epoch 25, Step  1200] loss: 0.088\n",
            "[Epoch 25, Step  1210] loss: 0.203\n",
            "[Epoch 25, Step  1220] loss: 0.316\n",
            "[Epoch 25, Step  1230] loss: 0.129\n",
            "[Epoch 25, Step  1240] loss: 0.477\n",
            "[Epoch 25, Step  1250] loss: 0.549\n",
            "[Epoch 25, Step  1260] loss: 0.282\n",
            "[Epoch 25, Step  1270] loss: 0.414\n",
            "[Epoch 25, Step  1280] loss: 0.100\n",
            "[Epoch 25, Step  1290] loss: 0.220\n",
            "[Epoch 25, Step  1300] loss: 0.448\n",
            "[Epoch 25, Step  1310] loss: 0.356\n",
            "[Epoch 25, Step  1320] loss: 0.153\n",
            "[Epoch 25, Step  1330] loss: 0.336\n",
            "[Epoch 25, Step  1340] loss: 0.147\n",
            "[Epoch 25, Step  1350] loss: 0.401\n",
            "[Epoch 25, Step  1360] loss: 0.107\n",
            "[Epoch 25, Step  1370] loss: 0.256\n",
            "[Epoch 25, Step  1380] loss: 0.088\n",
            "[Epoch 25, Step  1390] loss: 0.272\n",
            "[Epoch 25, Step  1400] loss: 0.335\n",
            "[Epoch 25, Step  1410] loss: 0.477\n",
            "[Epoch 25, Step  1420] loss: 0.462\n",
            "[Epoch 25, Step  1430] loss: 0.151\n",
            "[Epoch 25, Step  1440] loss: 0.164\n",
            "[Epoch 25, Step  1450] loss: 0.189\n",
            "[Epoch 25, Step  1460] loss: 0.233\n",
            "[Epoch 25, Step  1470] loss: 0.142\n",
            "[Epoch 25, Step  1480] loss: 0.030\n",
            "[Epoch 25, Step  1490] loss: 0.059\n",
            "[Epoch 25, Step  1500] loss: 0.140\n",
            "[Epoch 25, Step  1510] loss: 0.348\n",
            "[Epoch 25, Step  1520] loss: 0.275\n",
            "[Epoch 25, Step  1530] loss: 0.335\n",
            "[Epoch 25, Step  1540] loss: 0.242\n",
            "[Epoch 25, Step  1550] loss: 0.441\n",
            "[Epoch 25, Step  1560] loss: 0.247\n",
            "[Epoch 25, Step  1570] loss: 0.243\n",
            "[Epoch 25, Step  1580] loss: 0.352\n",
            "[Epoch 25, Step  1590] loss: 0.171\n",
            "[Epoch 25, Step  1600] loss: 0.172\n",
            "[Epoch 26, Step    10] loss: 0.130\n",
            "[Epoch 26, Step    20] loss: 0.606\n",
            "[Epoch 26, Step    30] loss: 0.085\n",
            "[Epoch 26, Step    40] loss: 0.104\n",
            "[Epoch 26, Step    50] loss: 0.225\n",
            "[Epoch 26, Step    60] loss: 0.180\n",
            "[Epoch 26, Step    70] loss: 0.438\n",
            "[Epoch 26, Step    80] loss: 0.108\n",
            "[Epoch 26, Step    90] loss: 0.197\n",
            "[Epoch 26, Step   100] loss: 0.238\n",
            "[Epoch 26, Step   110] loss: 0.346\n",
            "[Epoch 26, Step   120] loss: 0.134\n",
            "[Epoch 26, Step   130] loss: 0.265\n",
            "[Epoch 26, Step   140] loss: 0.161\n",
            "[Epoch 26, Step   150] loss: 0.619\n",
            "[Epoch 26, Step   160] loss: 0.091\n",
            "[Epoch 26, Step   170] loss: 0.781\n",
            "[Epoch 26, Step   180] loss: 0.175\n",
            "[Epoch 26, Step   190] loss: 0.274\n",
            "[Epoch 26, Step   200] loss: 0.396\n",
            "[Epoch 26, Step   210] loss: 0.432\n",
            "[Epoch 26, Step   220] loss: 0.208\n",
            "[Epoch 26, Step   230] loss: 0.166\n",
            "[Epoch 26, Step   240] loss: 0.338\n",
            "[Epoch 26, Step   250] loss: 0.111\n",
            "[Epoch 26, Step   260] loss: 0.129\n",
            "[Epoch 26, Step   270] loss: 0.282\n",
            "[Epoch 26, Step   280] loss: 0.340\n",
            "[Epoch 26, Step   290] loss: 0.286\n",
            "[Epoch 26, Step   300] loss: 0.334\n",
            "[Epoch 26, Step   310] loss: 0.303\n",
            "[Epoch 26, Step   320] loss: 0.278\n",
            "[Epoch 26, Step   330] loss: 0.196\n",
            "[Epoch 26, Step   340] loss: 0.302\n",
            "[Epoch 26, Step   350] loss: 0.497\n",
            "[Epoch 26, Step   360] loss: 0.136\n",
            "[Epoch 26, Step   370] loss: 0.271\n",
            "[Epoch 26, Step   380] loss: 0.634\n",
            "[Epoch 26, Step   390] loss: 0.250\n",
            "[Epoch 26, Step   400] loss: 0.238\n",
            "[Epoch 26, Step   410] loss: 0.091\n",
            "[Epoch 26, Step   420] loss: 0.591\n",
            "[Epoch 26, Step   430] loss: 0.464\n",
            "[Epoch 26, Step   440] loss: 0.298\n",
            "[Epoch 26, Step   450] loss: 0.241\n",
            "[Epoch 26, Step   460] loss: 0.293\n",
            "[Epoch 26, Step   470] loss: 0.322\n",
            "[Epoch 26, Step   480] loss: 0.422\n",
            "[Epoch 26, Step   490] loss: 0.538\n",
            "[Epoch 26, Step   500] loss: 0.132\n",
            "[Epoch 26, Step   510] loss: 0.450\n",
            "[Epoch 26, Step   520] loss: 0.229\n",
            "[Epoch 26, Step   530] loss: 0.410\n",
            "[Epoch 26, Step   540] loss: 0.618\n",
            "[Epoch 26, Step   550] loss: 0.181\n",
            "[Epoch 26, Step   560] loss: 0.432\n",
            "[Epoch 26, Step   570] loss: 0.115\n",
            "[Epoch 26, Step   580] loss: 0.213\n",
            "[Epoch 26, Step   590] loss: 0.159\n",
            "[Epoch 26, Step   600] loss: 0.607\n",
            "[Epoch 26, Step   610] loss: 0.330\n",
            "[Epoch 26, Step   620] loss: 0.291\n",
            "[Epoch 26, Step   630] loss: 0.353\n",
            "[Epoch 26, Step   640] loss: 0.284\n",
            "[Epoch 26, Step   650] loss: 0.253\n",
            "[Epoch 26, Step   660] loss: 0.277\n",
            "[Epoch 26, Step   670] loss: 0.262\n",
            "[Epoch 26, Step   680] loss: 0.158\n",
            "[Epoch 26, Step   690] loss: 0.064\n",
            "[Epoch 26, Step   700] loss: 0.085\n",
            "[Epoch 26, Step   710] loss: 0.364\n",
            "[Epoch 26, Step   720] loss: 0.211\n",
            "[Epoch 26, Step   730] loss: 0.377\n",
            "[Epoch 26, Step   740] loss: 0.537\n",
            "[Epoch 26, Step   750] loss: 0.307\n",
            "[Epoch 26, Step   760] loss: 0.078\n",
            "[Epoch 26, Step   770] loss: 0.407\n",
            "[Epoch 26, Step   780] loss: 0.421\n",
            "[Epoch 26, Step   790] loss: 0.269\n",
            "[Epoch 26, Step   800] loss: 0.277\n",
            "[Epoch 26, Step   810] loss: 0.089\n",
            "[Epoch 26, Step   820] loss: 0.265\n",
            "[Epoch 26, Step   830] loss: 0.267\n",
            "[Epoch 26, Step   840] loss: 0.421\n",
            "[Epoch 26, Step   850] loss: 0.142\n",
            "[Epoch 26, Step   860] loss: 0.304\n",
            "[Epoch 26, Step   870] loss: 0.229\n",
            "[Epoch 26, Step   880] loss: 0.307\n",
            "[Epoch 26, Step   890] loss: 0.081\n",
            "[Epoch 26, Step   900] loss: 0.285\n",
            "[Epoch 26, Step   910] loss: 0.539\n",
            "[Epoch 26, Step   920] loss: 0.600\n",
            "[Epoch 26, Step   930] loss: 0.515\n",
            "[Epoch 26, Step   940] loss: 0.065\n",
            "[Epoch 26, Step   950] loss: 0.165\n",
            "[Epoch 26, Step   960] loss: 0.265\n",
            "[Epoch 26, Step   970] loss: 0.136\n",
            "[Epoch 26, Step   980] loss: 0.176\n",
            "[Epoch 26, Step   990] loss: 0.227\n",
            "[Epoch 26, Step  1000] loss: 0.279\n",
            "[Epoch 26, Step  1010] loss: 0.365\n",
            "[Epoch 26, Step  1020] loss: 0.241\n",
            "[Epoch 26, Step  1030] loss: 0.091\n",
            "[Epoch 26, Step  1040] loss: 0.298\n",
            "[Epoch 26, Step  1050] loss: 0.224\n",
            "[Epoch 26, Step  1060] loss: 0.249\n",
            "[Epoch 26, Step  1070] loss: 0.189\n",
            "[Epoch 26, Step  1080] loss: 0.238\n",
            "[Epoch 26, Step  1090] loss: 0.028\n",
            "[Epoch 26, Step  1100] loss: 0.397\n",
            "[Epoch 26, Step  1110] loss: 0.161\n",
            "[Epoch 26, Step  1120] loss: 0.215\n",
            "[Epoch 26, Step  1130] loss: 0.284\n",
            "[Epoch 26, Step  1140] loss: 0.326\n",
            "[Epoch 26, Step  1150] loss: 0.303\n",
            "[Epoch 26, Step  1160] loss: 0.345\n",
            "[Epoch 26, Step  1170] loss: 0.028\n",
            "[Epoch 26, Step  1180] loss: 0.163\n",
            "[Epoch 26, Step  1190] loss: 0.120\n",
            "[Epoch 26, Step  1200] loss: 0.091\n",
            "[Epoch 26, Step  1210] loss: 0.115\n",
            "[Epoch 26, Step  1220] loss: 0.571\n",
            "[Epoch 26, Step  1230] loss: 0.285\n",
            "[Epoch 26, Step  1240] loss: 0.451\n",
            "[Epoch 26, Step  1250] loss: 0.340\n",
            "[Epoch 26, Step  1260] loss: 0.249\n",
            "[Epoch 26, Step  1270] loss: 0.205\n",
            "[Epoch 26, Step  1280] loss: 0.175\n",
            "[Epoch 26, Step  1290] loss: 0.256\n",
            "[Epoch 26, Step  1300] loss: 0.363\n",
            "[Epoch 26, Step  1310] loss: 0.115\n",
            "[Epoch 26, Step  1320] loss: 0.143\n",
            "[Epoch 26, Step  1330] loss: 0.435\n",
            "[Epoch 26, Step  1340] loss: 0.639\n",
            "[Epoch 26, Step  1350] loss: 0.079\n",
            "[Epoch 26, Step  1360] loss: 0.375\n",
            "[Epoch 26, Step  1370] loss: 0.124\n",
            "[Epoch 26, Step  1380] loss: 0.130\n",
            "[Epoch 26, Step  1390] loss: 0.225\n",
            "[Epoch 26, Step  1400] loss: 0.307\n",
            "[Epoch 26, Step  1410] loss: 0.266\n",
            "[Epoch 26, Step  1420] loss: 0.765\n",
            "[Epoch 26, Step  1430] loss: 0.168\n",
            "[Epoch 26, Step  1440] loss: 0.150\n",
            "[Epoch 26, Step  1450] loss: 0.358\n",
            "[Epoch 26, Step  1460] loss: 0.155\n",
            "[Epoch 26, Step  1470] loss: 0.260\n",
            "[Epoch 26, Step  1480] loss: 0.220\n",
            "[Epoch 26, Step  1490] loss: 0.484\n",
            "[Epoch 26, Step  1500] loss: 0.156\n",
            "[Epoch 26, Step  1510] loss: 0.202\n",
            "[Epoch 26, Step  1520] loss: 0.100\n",
            "[Epoch 26, Step  1530] loss: 0.257\n",
            "[Epoch 26, Step  1540] loss: 0.125\n",
            "[Epoch 26, Step  1550] loss: 0.212\n",
            "[Epoch 26, Step  1560] loss: 0.162\n",
            "[Epoch 26, Step  1570] loss: 0.222\n",
            "[Epoch 26, Step  1580] loss: 0.120\n",
            "[Epoch 26, Step  1590] loss: 0.304\n",
            "[Epoch 26, Step  1600] loss: 0.084\n",
            "[Epoch 27, Step    10] loss: 0.202\n",
            "[Epoch 27, Step    20] loss: 0.245\n",
            "[Epoch 27, Step    30] loss: 0.174\n",
            "[Epoch 27, Step    40] loss: 0.352\n",
            "[Epoch 27, Step    50] loss: 0.095\n",
            "[Epoch 27, Step    60] loss: 0.448\n",
            "[Epoch 27, Step    70] loss: 0.151\n",
            "[Epoch 27, Step    80] loss: 0.095\n",
            "[Epoch 27, Step    90] loss: 0.272\n",
            "[Epoch 27, Step   100] loss: 0.283\n",
            "[Epoch 27, Step   110] loss: 0.197\n",
            "[Epoch 27, Step   120] loss: 0.569\n",
            "[Epoch 27, Step   130] loss: 0.420\n",
            "[Epoch 27, Step   140] loss: 0.204\n",
            "[Epoch 27, Step   150] loss: 0.207\n",
            "[Epoch 27, Step   160] loss: 0.098\n",
            "[Epoch 27, Step   170] loss: 0.113\n",
            "[Epoch 27, Step   180] loss: 0.387\n",
            "[Epoch 27, Step   190] loss: 0.138\n",
            "[Epoch 27, Step   200] loss: 0.385\n",
            "[Epoch 27, Step   210] loss: 0.218\n",
            "[Epoch 27, Step   220] loss: 0.280\n",
            "[Epoch 27, Step   230] loss: 0.485\n",
            "[Epoch 27, Step   240] loss: 0.483\n",
            "[Epoch 27, Step   250] loss: 0.154\n",
            "[Epoch 27, Step   260] loss: 0.233\n",
            "[Epoch 27, Step   270] loss: 0.313\n",
            "[Epoch 27, Step   280] loss: 0.307\n",
            "[Epoch 27, Step   290] loss: 0.419\n",
            "[Epoch 27, Step   300] loss: 0.253\n",
            "[Epoch 27, Step   310] loss: 0.132\n",
            "[Epoch 27, Step   320] loss: 0.306\n",
            "[Epoch 27, Step   330] loss: 0.207\n",
            "[Epoch 27, Step   340] loss: 0.107\n",
            "[Epoch 27, Step   350] loss: 0.443\n",
            "[Epoch 27, Step   360] loss: 0.409\n",
            "[Epoch 27, Step   370] loss: 0.362\n",
            "[Epoch 27, Step   380] loss: 0.320\n",
            "[Epoch 27, Step   390] loss: 0.085\n",
            "[Epoch 27, Step   400] loss: 0.351\n",
            "[Epoch 27, Step   410] loss: 0.530\n",
            "[Epoch 27, Step   420] loss: 0.122\n",
            "[Epoch 27, Step   430] loss: 0.071\n",
            "[Epoch 27, Step   440] loss: 0.127\n",
            "[Epoch 27, Step   450] loss: 0.126\n",
            "[Epoch 27, Step   460] loss: 0.277\n",
            "[Epoch 27, Step   470] loss: 0.061\n",
            "[Epoch 27, Step   480] loss: 0.208\n",
            "[Epoch 27, Step   490] loss: 0.141\n",
            "[Epoch 27, Step   500] loss: 0.242\n",
            "[Epoch 27, Step   510] loss: 0.131\n",
            "[Epoch 27, Step   520] loss: 0.363\n",
            "[Epoch 27, Step   530] loss: 0.193\n",
            "[Epoch 27, Step   540] loss: 0.169\n",
            "[Epoch 27, Step   550] loss: 0.581\n",
            "[Epoch 27, Step   560] loss: 0.121\n",
            "[Epoch 27, Step   570] loss: 0.269\n",
            "[Epoch 27, Step   580] loss: 0.208\n",
            "[Epoch 27, Step   590] loss: 0.486\n",
            "[Epoch 27, Step   600] loss: 0.477\n",
            "[Epoch 27, Step   610] loss: 0.232\n",
            "[Epoch 27, Step   620] loss: 0.101\n",
            "[Epoch 27, Step   630] loss: 0.100\n",
            "[Epoch 27, Step   640] loss: 0.088\n",
            "[Epoch 27, Step   650] loss: 0.539\n",
            "[Epoch 27, Step   660] loss: 0.113\n",
            "[Epoch 27, Step   670] loss: 0.029\n",
            "[Epoch 27, Step   680] loss: 0.210\n",
            "[Epoch 27, Step   690] loss: 0.585\n",
            "[Epoch 27, Step   700] loss: 0.401\n",
            "[Epoch 27, Step   710] loss: 0.168\n",
            "[Epoch 27, Step   720] loss: 0.167\n",
            "[Epoch 27, Step   730] loss: 0.079\n",
            "[Epoch 27, Step   740] loss: 0.312\n",
            "[Epoch 27, Step   750] loss: 0.367\n",
            "[Epoch 27, Step   760] loss: 0.299\n",
            "[Epoch 27, Step   770] loss: 0.261\n",
            "[Epoch 27, Step   780] loss: 0.348\n",
            "[Epoch 27, Step   790] loss: 0.329\n",
            "[Epoch 27, Step   800] loss: 0.174\n",
            "[Epoch 27, Step   810] loss: 0.168\n",
            "[Epoch 27, Step   820] loss: 0.098\n",
            "[Epoch 27, Step   830] loss: 0.536\n",
            "[Epoch 27, Step   840] loss: 0.571\n",
            "[Epoch 27, Step   850] loss: 0.539\n",
            "[Epoch 27, Step   860] loss: 0.430\n",
            "[Epoch 27, Step   870] loss: 0.136\n",
            "[Epoch 27, Step   880] loss: 0.482\n",
            "[Epoch 27, Step   890] loss: 0.491\n",
            "[Epoch 27, Step   900] loss: 1.175\n",
            "[Epoch 27, Step   910] loss: 0.109\n",
            "[Epoch 27, Step   920] loss: 0.366\n",
            "[Epoch 27, Step   930] loss: 0.357\n",
            "[Epoch 27, Step   940] loss: 0.294\n",
            "[Epoch 27, Step   950] loss: 0.102\n",
            "[Epoch 27, Step   960] loss: 0.313\n",
            "[Epoch 27, Step   970] loss: 0.269\n",
            "[Epoch 27, Step   980] loss: 0.504\n",
            "[Epoch 27, Step   990] loss: 0.032\n",
            "[Epoch 27, Step  1000] loss: 0.299\n",
            "[Epoch 27, Step  1010] loss: 0.310\n",
            "[Epoch 27, Step  1020] loss: 0.527\n",
            "[Epoch 27, Step  1030] loss: 0.298\n",
            "[Epoch 27, Step  1040] loss: 0.494\n",
            "[Epoch 27, Step  1050] loss: 0.467\n",
            "[Epoch 27, Step  1060] loss: 0.196\n",
            "[Epoch 27, Step  1070] loss: 0.149\n",
            "[Epoch 27, Step  1080] loss: 0.272\n",
            "[Epoch 27, Step  1090] loss: 0.427\n",
            "[Epoch 27, Step  1100] loss: 0.096\n",
            "[Epoch 27, Step  1110] loss: 0.305\n",
            "[Epoch 27, Step  1120] loss: 0.194\n",
            "[Epoch 27, Step  1130] loss: 0.347\n",
            "[Epoch 27, Step  1140] loss: 0.169\n",
            "[Epoch 27, Step  1150] loss: 0.141\n",
            "[Epoch 27, Step  1160] loss: 0.059\n",
            "[Epoch 27, Step  1170] loss: 0.518\n",
            "[Epoch 27, Step  1180] loss: 0.203\n",
            "[Epoch 27, Step  1190] loss: 0.124\n",
            "[Epoch 27, Step  1200] loss: 0.206\n",
            "[Epoch 27, Step  1210] loss: 0.381\n",
            "[Epoch 27, Step  1220] loss: 0.160\n",
            "[Epoch 27, Step  1230] loss: 0.274\n",
            "[Epoch 27, Step  1240] loss: 0.417\n",
            "[Epoch 27, Step  1250] loss: 0.268\n",
            "[Epoch 27, Step  1260] loss: 0.532\n",
            "[Epoch 27, Step  1270] loss: 0.474\n",
            "[Epoch 27, Step  1280] loss: 0.096\n",
            "[Epoch 27, Step  1290] loss: 0.154\n",
            "[Epoch 27, Step  1300] loss: 0.146\n",
            "[Epoch 27, Step  1310] loss: 0.354\n",
            "[Epoch 27, Step  1320] loss: 0.390\n",
            "[Epoch 27, Step  1330] loss: 0.129\n",
            "[Epoch 27, Step  1340] loss: 0.134\n",
            "[Epoch 27, Step  1350] loss: 0.282\n",
            "[Epoch 27, Step  1360] loss: 0.414\n",
            "[Epoch 27, Step  1370] loss: 0.216\n",
            "[Epoch 27, Step  1380] loss: 0.344\n",
            "[Epoch 27, Step  1390] loss: 0.229\n",
            "[Epoch 27, Step  1400] loss: 0.032\n",
            "[Epoch 27, Step  1410] loss: 0.298\n",
            "[Epoch 27, Step  1420] loss: 0.203\n",
            "[Epoch 27, Step  1430] loss: 0.180\n",
            "[Epoch 27, Step  1440] loss: 0.155\n",
            "[Epoch 27, Step  1450] loss: 0.152\n",
            "[Epoch 27, Step  1460] loss: 0.127\n",
            "[Epoch 27, Step  1470] loss: 0.540\n",
            "[Epoch 27, Step  1480] loss: 0.291\n",
            "[Epoch 27, Step  1490] loss: 0.192\n",
            "[Epoch 27, Step  1500] loss: 0.278\n",
            "[Epoch 27, Step  1510] loss: 0.457\n",
            "[Epoch 27, Step  1520] loss: 0.186\n",
            "[Epoch 27, Step  1530] loss: 0.222\n",
            "[Epoch 27, Step  1540] loss: 0.179\n",
            "[Epoch 27, Step  1550] loss: 0.330\n",
            "[Epoch 27, Step  1560] loss: 0.513\n",
            "[Epoch 27, Step  1570] loss: 0.187\n",
            "[Epoch 27, Step  1580] loss: 0.244\n",
            "[Epoch 27, Step  1590] loss: 0.186\n",
            "[Epoch 27, Step  1600] loss: 0.197\n",
            "[Epoch 28, Step    10] loss: 0.106\n",
            "[Epoch 28, Step    20] loss: 0.192\n",
            "[Epoch 28, Step    30] loss: 0.097\n",
            "[Epoch 28, Step    40] loss: 0.304\n",
            "[Epoch 28, Step    50] loss: 0.088\n",
            "[Epoch 28, Step    60] loss: 0.110\n",
            "[Epoch 28, Step    70] loss: 0.045\n",
            "[Epoch 28, Step    80] loss: 0.372\n",
            "[Epoch 28, Step    90] loss: 0.097\n",
            "[Epoch 28, Step   100] loss: 0.276\n",
            "[Epoch 28, Step   110] loss: 0.638\n",
            "[Epoch 28, Step   120] loss: 0.295\n",
            "[Epoch 28, Step   130] loss: 0.044\n",
            "[Epoch 28, Step   140] loss: 0.063\n",
            "[Epoch 28, Step   150] loss: 0.125\n",
            "[Epoch 28, Step   160] loss: 0.318\n",
            "[Epoch 28, Step   170] loss: 0.143\n",
            "[Epoch 28, Step   180] loss: 0.162\n",
            "[Epoch 28, Step   190] loss: 0.461\n",
            "[Epoch 28, Step   200] loss: 0.245\n",
            "[Epoch 28, Step   210] loss: 0.146\n",
            "[Epoch 28, Step   220] loss: 0.247\n",
            "[Epoch 28, Step   230] loss: 0.052\n",
            "[Epoch 28, Step   240] loss: 0.510\n",
            "[Epoch 28, Step   250] loss: 0.290\n",
            "[Epoch 28, Step   260] loss: 0.156\n",
            "[Epoch 28, Step   270] loss: 0.376\n",
            "[Epoch 28, Step   280] loss: 0.161\n",
            "[Epoch 28, Step   290] loss: 0.629\n",
            "[Epoch 28, Step   300] loss: 0.427\n",
            "[Epoch 28, Step   310] loss: 0.320\n",
            "[Epoch 28, Step   320] loss: 0.156\n",
            "[Epoch 28, Step   330] loss: 0.351\n",
            "[Epoch 28, Step   340] loss: 0.169\n",
            "[Epoch 28, Step   350] loss: 0.130\n",
            "[Epoch 28, Step   360] loss: 0.096\n",
            "[Epoch 28, Step   370] loss: 0.549\n",
            "[Epoch 28, Step   380] loss: 0.172\n",
            "[Epoch 28, Step   390] loss: 0.146\n",
            "[Epoch 28, Step   400] loss: 0.278\n",
            "[Epoch 28, Step   410] loss: 0.091\n",
            "[Epoch 28, Step   420] loss: 0.126\n",
            "[Epoch 28, Step   430] loss: 0.065\n",
            "[Epoch 28, Step   440] loss: 0.409\n",
            "[Epoch 28, Step   450] loss: 0.491\n",
            "[Epoch 28, Step   460] loss: 0.274\n",
            "[Epoch 28, Step   470] loss: 0.552\n",
            "[Epoch 28, Step   480] loss: 0.088\n",
            "[Epoch 28, Step   490] loss: 0.061\n",
            "[Epoch 28, Step   500] loss: 0.021\n",
            "[Epoch 28, Step   510] loss: 0.188\n",
            "[Epoch 28, Step   520] loss: 0.187\n",
            "[Epoch 28, Step   530] loss: 0.303\n",
            "[Epoch 28, Step   540] loss: 0.133\n",
            "[Epoch 28, Step   550] loss: 0.371\n",
            "[Epoch 28, Step   560] loss: 0.099\n",
            "[Epoch 28, Step   570] loss: 0.083\n",
            "[Epoch 28, Step   580] loss: 0.151\n",
            "[Epoch 28, Step   590] loss: 0.140\n",
            "[Epoch 28, Step   600] loss: 0.397\n",
            "[Epoch 28, Step   610] loss: 0.308\n",
            "[Epoch 28, Step   620] loss: 0.087\n",
            "[Epoch 28, Step   630] loss: 0.224\n",
            "[Epoch 28, Step   640] loss: 0.240\n",
            "[Epoch 28, Step   650] loss: 0.287\n",
            "[Epoch 28, Step   660] loss: 0.232\n",
            "[Epoch 28, Step   670] loss: 0.183\n",
            "[Epoch 28, Step   680] loss: 0.084\n",
            "[Epoch 28, Step   690] loss: 0.126\n",
            "[Epoch 28, Step   700] loss: 0.109\n",
            "[Epoch 28, Step   710] loss: 0.242\n",
            "[Epoch 28, Step   720] loss: 0.398\n",
            "[Epoch 28, Step   730] loss: 0.154\n",
            "[Epoch 28, Step   740] loss: 0.290\n",
            "[Epoch 28, Step   750] loss: 0.330\n",
            "[Epoch 28, Step   760] loss: 0.355\n",
            "[Epoch 28, Step   770] loss: 0.232\n",
            "[Epoch 28, Step   780] loss: 0.243\n",
            "[Epoch 28, Step   790] loss: 0.256\n",
            "[Epoch 28, Step   800] loss: 0.255\n",
            "[Epoch 28, Step   810] loss: 0.244\n",
            "[Epoch 28, Step   820] loss: 0.607\n",
            "[Epoch 28, Step   830] loss: 0.266\n",
            "[Epoch 28, Step   840] loss: 0.276\n",
            "[Epoch 28, Step   850] loss: 0.060\n",
            "[Epoch 28, Step   860] loss: 0.070\n",
            "[Epoch 28, Step   870] loss: 0.320\n",
            "[Epoch 28, Step   880] loss: 0.315\n",
            "[Epoch 28, Step   890] loss: 0.590\n",
            "[Epoch 28, Step   900] loss: 0.157\n",
            "[Epoch 28, Step   910] loss: 0.215\n",
            "[Epoch 28, Step   920] loss: 0.272\n",
            "[Epoch 28, Step   930] loss: 0.577\n",
            "[Epoch 28, Step   940] loss: 0.271\n",
            "[Epoch 28, Step   950] loss: 0.159\n",
            "[Epoch 28, Step   960] loss: 0.401\n",
            "[Epoch 28, Step   970] loss: 0.774\n",
            "[Epoch 28, Step   980] loss: 0.624\n",
            "[Epoch 28, Step   990] loss: 0.278\n",
            "[Epoch 28, Step  1000] loss: 0.614\n",
            "[Epoch 28, Step  1010] loss: 0.201\n",
            "[Epoch 28, Step  1020] loss: 0.175\n",
            "[Epoch 28, Step  1030] loss: 0.098\n",
            "[Epoch 28, Step  1040] loss: 0.131\n",
            "[Epoch 28, Step  1050] loss: 0.161\n",
            "[Epoch 28, Step  1060] loss: 0.153\n",
            "[Epoch 28, Step  1070] loss: 0.279\n",
            "[Epoch 28, Step  1080] loss: 0.506\n",
            "[Epoch 28, Step  1090] loss: 0.297\n",
            "[Epoch 28, Step  1100] loss: 0.338\n",
            "[Epoch 28, Step  1110] loss: 0.402\n",
            "[Epoch 28, Step  1120] loss: 0.665\n",
            "[Epoch 28, Step  1130] loss: 0.824\n",
            "[Epoch 28, Step  1140] loss: 0.638\n",
            "[Epoch 28, Step  1150] loss: 0.525\n",
            "[Epoch 28, Step  1160] loss: 0.430\n",
            "[Epoch 28, Step  1170] loss: 0.135\n",
            "[Epoch 28, Step  1180] loss: 0.515\n",
            "[Epoch 28, Step  1190] loss: 0.094\n",
            "[Epoch 28, Step  1200] loss: 0.446\n",
            "[Epoch 28, Step  1210] loss: 0.086\n",
            "[Epoch 28, Step  1220] loss: 0.255\n",
            "[Epoch 28, Step  1230] loss: 0.096\n",
            "[Epoch 28, Step  1240] loss: 0.210\n",
            "[Epoch 28, Step  1250] loss: 0.232\n",
            "[Epoch 28, Step  1260] loss: 0.327\n",
            "[Epoch 28, Step  1270] loss: 0.267\n",
            "[Epoch 28, Step  1280] loss: 0.237\n",
            "[Epoch 28, Step  1290] loss: 0.274\n",
            "[Epoch 28, Step  1300] loss: 0.377\n",
            "[Epoch 28, Step  1310] loss: 0.048\n",
            "[Epoch 28, Step  1320] loss: 0.248\n",
            "[Epoch 28, Step  1330] loss: 0.258\n",
            "[Epoch 28, Step  1340] loss: 0.603\n",
            "[Epoch 28, Step  1350] loss: 0.141\n",
            "[Epoch 28, Step  1360] loss: 0.221\n",
            "[Epoch 28, Step  1370] loss: 0.450\n",
            "[Epoch 28, Step  1380] loss: 0.055\n",
            "[Epoch 28, Step  1390] loss: 0.424\n",
            "[Epoch 28, Step  1400] loss: 0.266\n",
            "[Epoch 28, Step  1410] loss: 0.195\n",
            "[Epoch 28, Step  1420] loss: 0.745\n",
            "[Epoch 28, Step  1430] loss: 0.126\n",
            "[Epoch 28, Step  1440] loss: 0.099\n",
            "[Epoch 28, Step  1450] loss: 0.227\n",
            "[Epoch 28, Step  1460] loss: 0.092\n",
            "[Epoch 28, Step  1470] loss: 0.445\n",
            "[Epoch 28, Step  1480] loss: 0.282\n",
            "[Epoch 28, Step  1490] loss: 0.425\n",
            "[Epoch 28, Step  1500] loss: 0.118\n",
            "[Epoch 28, Step  1510] loss: 0.522\n",
            "[Epoch 28, Step  1520] loss: 0.296\n",
            "[Epoch 28, Step  1530] loss: 0.195\n",
            "[Epoch 28, Step  1540] loss: 0.188\n",
            "[Epoch 28, Step  1550] loss: 0.125\n",
            "[Epoch 28, Step  1560] loss: 0.513\n",
            "[Epoch 28, Step  1570] loss: 0.397\n",
            "[Epoch 28, Step  1580] loss: 0.050\n",
            "[Epoch 28, Step  1590] loss: 0.269\n",
            "[Epoch 28, Step  1600] loss: 0.508\n",
            "[Epoch 29, Step    10] loss: 0.171\n",
            "[Epoch 29, Step    20] loss: 0.227\n",
            "[Epoch 29, Step    30] loss: 0.098\n",
            "[Epoch 29, Step    40] loss: 0.066\n",
            "[Epoch 29, Step    50] loss: 0.465\n",
            "[Epoch 29, Step    60] loss: 0.151\n",
            "[Epoch 29, Step    70] loss: 0.122\n",
            "[Epoch 29, Step    80] loss: 0.333\n",
            "[Epoch 29, Step    90] loss: 0.076\n",
            "[Epoch 29, Step   100] loss: 0.228\n",
            "[Epoch 29, Step   110] loss: 0.571\n",
            "[Epoch 29, Step   120] loss: 0.158\n",
            "[Epoch 29, Step   130] loss: 0.323\n",
            "[Epoch 29, Step   140] loss: 0.129\n",
            "[Epoch 29, Step   150] loss: 0.378\n",
            "[Epoch 29, Step   160] loss: 0.098\n",
            "[Epoch 29, Step   170] loss: 0.592\n",
            "[Epoch 29, Step   180] loss: 0.265\n",
            "[Epoch 29, Step   190] loss: 0.168\n",
            "[Epoch 29, Step   200] loss: 0.260\n",
            "[Epoch 29, Step   210] loss: 0.209\n",
            "[Epoch 29, Step   220] loss: 0.203\n",
            "[Epoch 29, Step   230] loss: 0.220\n",
            "[Epoch 29, Step   240] loss: 0.619\n",
            "[Epoch 29, Step   250] loss: 0.263\n",
            "[Epoch 29, Step   260] loss: 0.292\n",
            "[Epoch 29, Step   270] loss: 0.168\n",
            "[Epoch 29, Step   280] loss: 0.258\n",
            "[Epoch 29, Step   290] loss: 0.056\n",
            "[Epoch 29, Step   300] loss: 0.387\n",
            "[Epoch 29, Step   310] loss: 0.419\n",
            "[Epoch 29, Step   320] loss: 0.106\n",
            "[Epoch 29, Step   330] loss: 0.350\n",
            "[Epoch 29, Step   340] loss: 0.499\n",
            "[Epoch 29, Step   350] loss: 0.240\n",
            "[Epoch 29, Step   360] loss: 0.438\n",
            "[Epoch 29, Step   370] loss: 0.486\n",
            "[Epoch 29, Step   380] loss: 0.168\n",
            "[Epoch 29, Step   390] loss: 0.192\n",
            "[Epoch 29, Step   400] loss: 0.246\n",
            "[Epoch 29, Step   410] loss: 0.139\n",
            "[Epoch 29, Step   420] loss: 0.136\n",
            "[Epoch 29, Step   430] loss: 0.438\n",
            "[Epoch 29, Step   440] loss: 0.208\n",
            "[Epoch 29, Step   450] loss: 0.829\n",
            "[Epoch 29, Step   460] loss: 0.269\n",
            "[Epoch 29, Step   470] loss: 0.547\n",
            "[Epoch 29, Step   480] loss: 0.625\n",
            "[Epoch 29, Step   490] loss: 0.057\n",
            "[Epoch 29, Step   500] loss: 0.195\n",
            "[Epoch 29, Step   510] loss: 0.386\n",
            "[Epoch 29, Step   520] loss: 0.228\n",
            "[Epoch 29, Step   530] loss: 0.058\n",
            "[Epoch 29, Step   540] loss: 0.311\n",
            "[Epoch 29, Step   550] loss: 0.083\n",
            "[Epoch 29, Step   560] loss: 0.534\n",
            "[Epoch 29, Step   570] loss: 0.186\n",
            "[Epoch 29, Step   580] loss: 0.066\n",
            "[Epoch 29, Step   590] loss: 0.151\n",
            "[Epoch 29, Step   600] loss: 0.361\n",
            "[Epoch 29, Step   610] loss: 0.239\n",
            "[Epoch 29, Step   620] loss: 0.078\n",
            "[Epoch 29, Step   630] loss: 0.392\n",
            "[Epoch 29, Step   640] loss: 0.388\n",
            "[Epoch 29, Step   650] loss: 0.198\n",
            "[Epoch 29, Step   660] loss: 0.048\n",
            "[Epoch 29, Step   670] loss: 0.110\n",
            "[Epoch 29, Step   680] loss: 0.117\n",
            "[Epoch 29, Step   690] loss: 0.148\n",
            "[Epoch 29, Step   700] loss: 0.287\n",
            "[Epoch 29, Step   710] loss: 0.155\n",
            "[Epoch 29, Step   720] loss: 0.257\n",
            "[Epoch 29, Step   730] loss: 0.163\n",
            "[Epoch 29, Step   740] loss: 0.369\n",
            "[Epoch 29, Step   750] loss: 0.491\n",
            "[Epoch 29, Step   760] loss: 0.253\n",
            "[Epoch 29, Step   770] loss: 0.483\n",
            "[Epoch 29, Step   780] loss: 0.131\n",
            "[Epoch 29, Step   790] loss: 0.275\n",
            "[Epoch 29, Step   800] loss: 0.251\n",
            "[Epoch 29, Step   810] loss: 0.195\n",
            "[Epoch 29, Step   820] loss: 0.135\n",
            "[Epoch 29, Step   830] loss: 0.335\n",
            "[Epoch 29, Step   840] loss: 0.104\n",
            "[Epoch 29, Step   850] loss: 0.468\n",
            "[Epoch 29, Step   860] loss: 0.500\n",
            "[Epoch 29, Step   870] loss: 0.053\n",
            "[Epoch 29, Step   880] loss: 0.280\n",
            "[Epoch 29, Step   890] loss: 0.380\n",
            "[Epoch 29, Step   900] loss: 0.165\n",
            "[Epoch 29, Step   910] loss: 0.285\n",
            "[Epoch 29, Step   920] loss: 0.199\n",
            "[Epoch 29, Step   930] loss: 0.052\n",
            "[Epoch 29, Step   940] loss: 0.162\n",
            "[Epoch 29, Step   950] loss: 0.220\n",
            "[Epoch 29, Step   960] loss: 0.283\n",
            "[Epoch 29, Step   970] loss: 0.412\n",
            "[Epoch 29, Step   980] loss: 0.307\n",
            "[Epoch 29, Step   990] loss: 0.317\n",
            "[Epoch 29, Step  1000] loss: 0.361\n",
            "[Epoch 29, Step  1010] loss: 0.091\n",
            "[Epoch 29, Step  1020] loss: 0.382\n",
            "[Epoch 29, Step  1030] loss: 0.135\n",
            "[Epoch 29, Step  1040] loss: 0.238\n",
            "[Epoch 29, Step  1050] loss: 0.207\n",
            "[Epoch 29, Step  1060] loss: 0.678\n",
            "[Epoch 29, Step  1070] loss: 0.018\n",
            "[Epoch 29, Step  1080] loss: 0.338\n",
            "[Epoch 29, Step  1090] loss: 0.547\n",
            "[Epoch 29, Step  1100] loss: 0.100\n",
            "[Epoch 29, Step  1110] loss: 0.101\n",
            "[Epoch 29, Step  1120] loss: 0.191\n",
            "[Epoch 29, Step  1130] loss: 0.138\n",
            "[Epoch 29, Step  1140] loss: 0.219\n",
            "[Epoch 29, Step  1150] loss: 0.141\n",
            "[Epoch 29, Step  1160] loss: 0.274\n",
            "[Epoch 29, Step  1170] loss: 0.190\n",
            "[Epoch 29, Step  1180] loss: 0.145\n",
            "[Epoch 29, Step  1190] loss: 0.291\n",
            "[Epoch 29, Step  1200] loss: 0.726\n",
            "[Epoch 29, Step  1210] loss: 0.173\n",
            "[Epoch 29, Step  1220] loss: 0.175\n",
            "[Epoch 29, Step  1230] loss: 0.093\n",
            "[Epoch 29, Step  1240] loss: 0.225\n",
            "[Epoch 29, Step  1250] loss: 0.315\n",
            "[Epoch 29, Step  1260] loss: 0.288\n",
            "[Epoch 29, Step  1270] loss: 0.459\n",
            "[Epoch 29, Step  1280] loss: 0.506\n",
            "[Epoch 29, Step  1290] loss: 0.444\n",
            "[Epoch 29, Step  1300] loss: 0.335\n",
            "[Epoch 29, Step  1310] loss: 0.339\n",
            "[Epoch 29, Step  1320] loss: 0.178\n",
            "[Epoch 29, Step  1330] loss: 0.271\n",
            "[Epoch 29, Step  1340] loss: 0.190\n",
            "[Epoch 29, Step  1350] loss: 0.191\n",
            "[Epoch 29, Step  1360] loss: 0.276\n",
            "[Epoch 29, Step  1370] loss: 0.133\n",
            "[Epoch 29, Step  1380] loss: 0.282\n",
            "[Epoch 29, Step  1390] loss: 0.171\n",
            "[Epoch 29, Step  1400] loss: 0.110\n",
            "[Epoch 29, Step  1410] loss: 0.337\n",
            "[Epoch 29, Step  1420] loss: 0.536\n",
            "[Epoch 29, Step  1430] loss: 0.241\n",
            "[Epoch 29, Step  1440] loss: 0.232\n",
            "[Epoch 29, Step  1450] loss: 0.273\n",
            "[Epoch 29, Step  1460] loss: 0.277\n",
            "[Epoch 29, Step  1470] loss: 0.279\n",
            "[Epoch 29, Step  1480] loss: 0.098\n",
            "[Epoch 29, Step  1490] loss: 0.643\n",
            "[Epoch 29, Step  1500] loss: 0.087\n",
            "[Epoch 29, Step  1510] loss: 0.222\n",
            "[Epoch 29, Step  1520] loss: 0.242\n",
            "[Epoch 29, Step  1530] loss: 0.280\n",
            "[Epoch 29, Step  1540] loss: 0.354\n",
            "[Epoch 29, Step  1550] loss: 0.252\n",
            "[Epoch 29, Step  1560] loss: 0.208\n",
            "[Epoch 29, Step  1570] loss: 0.232\n",
            "[Epoch 29, Step  1580] loss: 0.513\n",
            "[Epoch 29, Step  1590] loss: 0.784\n",
            "[Epoch 29, Step  1600] loss: 0.058\n",
            "[Epoch 30, Step    10] loss: 0.188\n",
            "[Epoch 30, Step    20] loss: 0.308\n",
            "[Epoch 30, Step    30] loss: 0.329\n",
            "[Epoch 30, Step    40] loss: 0.113\n",
            "[Epoch 30, Step    50] loss: 0.457\n",
            "[Epoch 30, Step    60] loss: 0.415\n",
            "[Epoch 30, Step    70] loss: 0.164\n",
            "[Epoch 30, Step    80] loss: 0.279\n",
            "[Epoch 30, Step    90] loss: 0.230\n",
            "[Epoch 30, Step   100] loss: 0.185\n",
            "[Epoch 30, Step   110] loss: 0.064\n",
            "[Epoch 30, Step   120] loss: 0.506\n",
            "[Epoch 30, Step   130] loss: 0.253\n",
            "[Epoch 30, Step   140] loss: 0.112\n",
            "[Epoch 30, Step   150] loss: 0.559\n",
            "[Epoch 30, Step   160] loss: 0.183\n",
            "[Epoch 30, Step   170] loss: 0.209\n",
            "[Epoch 30, Step   180] loss: 0.811\n",
            "[Epoch 30, Step   190] loss: 0.294\n",
            "[Epoch 30, Step   200] loss: 0.228\n",
            "[Epoch 30, Step   210] loss: 0.206\n",
            "[Epoch 30, Step   220] loss: 0.378\n",
            "[Epoch 30, Step   230] loss: 0.367\n",
            "[Epoch 30, Step   240] loss: 0.115\n",
            "[Epoch 30, Step   250] loss: 0.330\n",
            "[Epoch 30, Step   260] loss: 0.277\n",
            "[Epoch 30, Step   270] loss: 0.064\n",
            "[Epoch 30, Step   280] loss: 0.228\n",
            "[Epoch 30, Step   290] loss: 0.110\n",
            "[Epoch 30, Step   300] loss: 0.127\n",
            "[Epoch 30, Step   310] loss: 0.123\n",
            "[Epoch 30, Step   320] loss: 0.599\n",
            "[Epoch 30, Step   330] loss: 0.104\n",
            "[Epoch 30, Step   340] loss: 0.237\n",
            "[Epoch 30, Step   350] loss: 0.151\n",
            "[Epoch 30, Step   360] loss: 0.251\n",
            "[Epoch 30, Step   370] loss: 0.114\n",
            "[Epoch 30, Step   380] loss: 0.389\n",
            "[Epoch 30, Step   390] loss: 0.383\n",
            "[Epoch 30, Step   400] loss: 0.397\n",
            "[Epoch 30, Step   410] loss: 0.212\n",
            "[Epoch 30, Step   420] loss: 0.074\n",
            "[Epoch 30, Step   430] loss: 0.124\n",
            "[Epoch 30, Step   440] loss: 0.160\n",
            "[Epoch 30, Step   450] loss: 0.132\n",
            "[Epoch 30, Step   460] loss: 0.423\n",
            "[Epoch 30, Step   470] loss: 0.622\n",
            "[Epoch 30, Step   480] loss: 0.192\n",
            "[Epoch 30, Step   490] loss: 0.135\n",
            "[Epoch 30, Step   500] loss: 0.487\n",
            "[Epoch 30, Step   510] loss: 0.103\n",
            "[Epoch 30, Step   520] loss: 0.135\n",
            "[Epoch 30, Step   530] loss: 0.194\n",
            "[Epoch 30, Step   540] loss: 0.241\n",
            "[Epoch 30, Step   550] loss: 0.247\n",
            "[Epoch 30, Step   560] loss: 0.255\n",
            "[Epoch 30, Step   570] loss: 0.264\n",
            "[Epoch 30, Step   580] loss: 0.093\n",
            "[Epoch 30, Step   590] loss: 0.198\n",
            "[Epoch 30, Step   600] loss: 0.155\n",
            "[Epoch 30, Step   610] loss: 0.614\n",
            "[Epoch 30, Step   620] loss: 0.289\n",
            "[Epoch 30, Step   630] loss: 0.470\n",
            "[Epoch 30, Step   640] loss: 0.170\n",
            "[Epoch 30, Step   650] loss: 0.495\n",
            "[Epoch 30, Step   660] loss: 0.563\n",
            "[Epoch 30, Step   670] loss: 0.288\n",
            "[Epoch 30, Step   680] loss: 0.110\n",
            "[Epoch 30, Step   690] loss: 0.074\n",
            "[Epoch 30, Step   700] loss: 0.159\n",
            "[Epoch 30, Step   710] loss: 0.065\n",
            "[Epoch 30, Step   720] loss: 0.418\n",
            "[Epoch 30, Step   730] loss: 0.196\n",
            "[Epoch 30, Step   740] loss: 0.119\n",
            "[Epoch 30, Step   750] loss: 0.208\n",
            "[Epoch 30, Step   760] loss: 0.118\n",
            "[Epoch 30, Step   770] loss: 0.504\n",
            "[Epoch 30, Step   780] loss: 0.472\n",
            "[Epoch 30, Step   790] loss: 0.241\n",
            "[Epoch 30, Step   800] loss: 0.359\n",
            "[Epoch 30, Step   810] loss: 0.541\n",
            "[Epoch 30, Step   820] loss: 0.133\n",
            "[Epoch 30, Step   830] loss: 0.263\n",
            "[Epoch 30, Step   840] loss: 0.141\n",
            "[Epoch 30, Step   850] loss: 0.353\n",
            "[Epoch 30, Step   860] loss: 0.110\n",
            "[Epoch 30, Step   870] loss: 0.120\n",
            "[Epoch 30, Step   880] loss: 0.188\n",
            "[Epoch 30, Step   890] loss: 0.259\n",
            "[Epoch 30, Step   900] loss: 0.239\n",
            "[Epoch 30, Step   910] loss: 0.247\n",
            "[Epoch 30, Step   920] loss: 0.070\n",
            "[Epoch 30, Step   930] loss: 0.260\n",
            "[Epoch 30, Step   940] loss: 0.199\n",
            "[Epoch 30, Step   950] loss: 0.259\n",
            "[Epoch 30, Step   960] loss: 0.055\n",
            "[Epoch 30, Step   970] loss: 0.515\n",
            "[Epoch 30, Step   980] loss: 0.293\n",
            "[Epoch 30, Step   990] loss: 0.131\n",
            "[Epoch 30, Step  1000] loss: 0.395\n",
            "[Epoch 30, Step  1010] loss: 0.302\n",
            "[Epoch 30, Step  1020] loss: 0.292\n",
            "[Epoch 30, Step  1030] loss: 0.080\n",
            "[Epoch 30, Step  1040] loss: 0.426\n",
            "[Epoch 30, Step  1050] loss: 0.256\n",
            "[Epoch 30, Step  1060] loss: 0.139\n",
            "[Epoch 30, Step  1070] loss: 0.195\n",
            "[Epoch 30, Step  1080] loss: 0.046\n",
            "[Epoch 30, Step  1090] loss: 0.404\n",
            "[Epoch 30, Step  1100] loss: 0.191\n",
            "[Epoch 30, Step  1110] loss: 0.288\n",
            "[Epoch 30, Step  1120] loss: 0.304\n",
            "[Epoch 30, Step  1130] loss: 0.135\n",
            "[Epoch 30, Step  1140] loss: 0.402\n",
            "[Epoch 30, Step  1150] loss: 0.365\n",
            "[Epoch 30, Step  1160] loss: 0.212\n",
            "[Epoch 30, Step  1170] loss: 0.224\n",
            "[Epoch 30, Step  1180] loss: 0.177\n",
            "[Epoch 30, Step  1190] loss: 0.278\n",
            "[Epoch 30, Step  1200] loss: 0.057\n",
            "[Epoch 30, Step  1210] loss: 0.193\n",
            "[Epoch 30, Step  1220] loss: 0.171\n",
            "[Epoch 30, Step  1230] loss: 0.599\n",
            "[Epoch 30, Step  1240] loss: 0.209\n",
            "[Epoch 30, Step  1250] loss: 0.147\n",
            "[Epoch 30, Step  1260] loss: 0.400\n",
            "[Epoch 30, Step  1270] loss: 0.225\n",
            "[Epoch 30, Step  1280] loss: 0.250\n",
            "[Epoch 30, Step  1290] loss: 0.299\n",
            "[Epoch 30, Step  1300] loss: 0.348\n",
            "[Epoch 30, Step  1310] loss: 0.244\n",
            "[Epoch 30, Step  1320] loss: 0.650\n",
            "[Epoch 30, Step  1330] loss: 0.270\n",
            "[Epoch 30, Step  1340] loss: 0.215\n",
            "[Epoch 30, Step  1350] loss: 0.414\n",
            "[Epoch 30, Step  1360] loss: 0.187\n",
            "[Epoch 30, Step  1370] loss: 0.183\n",
            "[Epoch 30, Step  1380] loss: 0.233\n",
            "[Epoch 30, Step  1390] loss: 0.303\n",
            "[Epoch 30, Step  1400] loss: 0.306\n",
            "[Epoch 30, Step  1410] loss: 0.646\n",
            "[Epoch 30, Step  1420] loss: 0.231\n",
            "[Epoch 30, Step  1430] loss: 0.393\n",
            "[Epoch 30, Step  1440] loss: 0.270\n",
            "[Epoch 30, Step  1450] loss: 0.212\n",
            "[Epoch 30, Step  1460] loss: 0.294\n",
            "[Epoch 30, Step  1470] loss: 0.469\n",
            "[Epoch 30, Step  1480] loss: 0.404\n",
            "[Epoch 30, Step  1490] loss: 0.488\n",
            "[Epoch 30, Step  1500] loss: 0.377\n",
            "[Epoch 30, Step  1510] loss: 0.151\n",
            "[Epoch 30, Step  1520] loss: 0.140\n",
            "[Epoch 30, Step  1530] loss: 0.072\n",
            "[Epoch 30, Step  1540] loss: 0.089\n",
            "[Epoch 30, Step  1550] loss: 0.567\n",
            "[Epoch 30, Step  1560] loss: 0.243\n",
            "[Epoch 30, Step  1570] loss: 0.326\n",
            "[Epoch 30, Step  1580] loss: 0.008\n",
            "[Epoch 30, Step  1590] loss: 0.307\n",
            "[Epoch 30, Step  1600] loss: 0.167\n",
            "[Epoch 31, Step    10] loss: 0.105\n",
            "[Epoch 31, Step    20] loss: 0.403\n",
            "[Epoch 31, Step    30] loss: 0.048\n",
            "[Epoch 31, Step    40] loss: 0.217\n",
            "[Epoch 31, Step    50] loss: 0.281\n",
            "[Epoch 31, Step    60] loss: 0.184\n",
            "[Epoch 31, Step    70] loss: 0.111\n",
            "[Epoch 31, Step    80] loss: 0.661\n",
            "[Epoch 31, Step    90] loss: 0.422\n",
            "[Epoch 31, Step   100] loss: 0.102\n",
            "[Epoch 31, Step   110] loss: 0.404\n",
            "[Epoch 31, Step   120] loss: 0.417\n",
            "[Epoch 31, Step   130] loss: 0.202\n",
            "[Epoch 31, Step   140] loss: 0.255\n",
            "[Epoch 31, Step   150] loss: 0.210\n",
            "[Epoch 31, Step   160] loss: 0.436\n",
            "[Epoch 31, Step   170] loss: 0.314\n",
            "[Epoch 31, Step   180] loss: 0.172\n",
            "[Epoch 31, Step   190] loss: 0.349\n",
            "[Epoch 31, Step   200] loss: 0.179\n",
            "[Epoch 31, Step   210] loss: 0.214\n",
            "[Epoch 31, Step   220] loss: 0.432\n",
            "[Epoch 31, Step   230] loss: 0.398\n",
            "[Epoch 31, Step   240] loss: 0.401\n",
            "[Epoch 31, Step   250] loss: 0.225\n",
            "[Epoch 31, Step   260] loss: 0.254\n",
            "[Epoch 31, Step   270] loss: 0.201\n",
            "[Epoch 31, Step   280] loss: 0.090\n",
            "[Epoch 31, Step   290] loss: 0.516\n",
            "[Epoch 31, Step   300] loss: 0.133\n",
            "[Epoch 31, Step   310] loss: 0.175\n",
            "[Epoch 31, Step   320] loss: 0.303\n",
            "[Epoch 31, Step   330] loss: 0.499\n",
            "[Epoch 31, Step   340] loss: 0.235\n",
            "[Epoch 31, Step   350] loss: 0.442\n",
            "[Epoch 31, Step   360] loss: 0.086\n",
            "[Epoch 31, Step   370] loss: 0.106\n",
            "[Epoch 31, Step   380] loss: 0.190\n",
            "[Epoch 31, Step   390] loss: 0.206\n",
            "[Epoch 31, Step   400] loss: 0.236\n",
            "[Epoch 31, Step   410] loss: 0.180\n",
            "[Epoch 31, Step   420] loss: 0.782\n",
            "[Epoch 31, Step   430] loss: 0.272\n",
            "[Epoch 31, Step   440] loss: 0.073\n",
            "[Epoch 31, Step   450] loss: 0.418\n",
            "[Epoch 31, Step   460] loss: 0.064\n",
            "[Epoch 31, Step   470] loss: 0.461\n",
            "[Epoch 31, Step   480] loss: 0.460\n",
            "[Epoch 31, Step   490] loss: 0.099\n",
            "[Epoch 31, Step   500] loss: 0.519\n",
            "[Epoch 31, Step   510] loss: 0.336\n",
            "[Epoch 31, Step   520] loss: 0.351\n",
            "[Epoch 31, Step   530] loss: 0.170\n",
            "[Epoch 31, Step   540] loss: 0.246\n",
            "[Epoch 31, Step   550] loss: 0.049\n",
            "[Epoch 31, Step   560] loss: 0.337\n",
            "[Epoch 31, Step   570] loss: 0.180\n",
            "[Epoch 31, Step   580] loss: 0.054\n",
            "[Epoch 31, Step   590] loss: 0.421\n",
            "[Epoch 31, Step   600] loss: 0.570\n",
            "[Epoch 31, Step   610] loss: 0.214\n",
            "[Epoch 31, Step   620] loss: 0.245\n",
            "[Epoch 31, Step   630] loss: 0.302\n",
            "[Epoch 31, Step   640] loss: 0.032\n",
            "[Epoch 31, Step   650] loss: 0.139\n",
            "[Epoch 31, Step   660] loss: 0.416\n",
            "[Epoch 31, Step   670] loss: 0.151\n",
            "[Epoch 31, Step   680] loss: 0.239\n",
            "[Epoch 31, Step   690] loss: 0.379\n",
            "[Epoch 31, Step   700] loss: 0.238\n",
            "[Epoch 31, Step   710] loss: 0.453\n",
            "[Epoch 31, Step   720] loss: 0.146\n",
            "[Epoch 31, Step   730] loss: 0.261\n",
            "[Epoch 31, Step   740] loss: 0.177\n",
            "[Epoch 31, Step   750] loss: 0.185\n",
            "[Epoch 31, Step   760] loss: 0.231\n",
            "[Epoch 31, Step   770] loss: 0.185\n",
            "[Epoch 31, Step   780] loss: 0.117\n",
            "[Epoch 31, Step   790] loss: 0.299\n",
            "[Epoch 31, Step   800] loss: 0.239\n",
            "[Epoch 31, Step   810] loss: 0.090\n",
            "[Epoch 31, Step   820] loss: 0.104\n",
            "[Epoch 31, Step   830] loss: 0.291\n",
            "[Epoch 31, Step   840] loss: 0.358\n",
            "[Epoch 31, Step   850] loss: 0.193\n",
            "[Epoch 31, Step   860] loss: 0.264\n",
            "[Epoch 31, Step   870] loss: 0.093\n",
            "[Epoch 31, Step   880] loss: 0.054\n",
            "[Epoch 31, Step   890] loss: 0.122\n",
            "[Epoch 31, Step   900] loss: 0.320\n",
            "[Epoch 31, Step   910] loss: 0.169\n",
            "[Epoch 31, Step   920] loss: 0.308\n",
            "[Epoch 31, Step   930] loss: 0.453\n",
            "[Epoch 31, Step   940] loss: 0.496\n",
            "[Epoch 31, Step   950] loss: 0.345\n",
            "[Epoch 31, Step   960] loss: 0.082\n",
            "[Epoch 31, Step   970] loss: 0.579\n",
            "[Epoch 31, Step   980] loss: 0.205\n",
            "[Epoch 31, Step   990] loss: 0.464\n",
            "[Epoch 31, Step  1000] loss: 0.251\n",
            "[Epoch 31, Step  1010] loss: 0.257\n",
            "[Epoch 31, Step  1020] loss: 0.124\n",
            "[Epoch 31, Step  1030] loss: 0.398\n",
            "[Epoch 31, Step  1040] loss: 0.278\n",
            "[Epoch 31, Step  1050] loss: 0.232\n",
            "[Epoch 31, Step  1060] loss: 0.130\n",
            "[Epoch 31, Step  1070] loss: 0.504\n",
            "[Epoch 31, Step  1080] loss: 0.382\n",
            "[Epoch 31, Step  1090] loss: 0.200\n",
            "[Epoch 31, Step  1100] loss: 0.363\n",
            "[Epoch 31, Step  1110] loss: 0.287\n",
            "[Epoch 31, Step  1120] loss: 0.103\n",
            "[Epoch 31, Step  1130] loss: 0.604\n",
            "[Epoch 31, Step  1140] loss: 0.270\n",
            "[Epoch 31, Step  1150] loss: 0.291\n",
            "[Epoch 31, Step  1160] loss: 0.342\n",
            "[Epoch 31, Step  1170] loss: 0.252\n",
            "[Epoch 31, Step  1180] loss: 0.267\n",
            "[Epoch 31, Step  1190] loss: 0.127\n",
            "[Epoch 31, Step  1200] loss: 0.165\n",
            "[Epoch 31, Step  1210] loss: 0.071\n",
            "[Epoch 31, Step  1220] loss: 0.299\n",
            "[Epoch 31, Step  1230] loss: 0.109\n",
            "[Epoch 31, Step  1240] loss: 0.067\n",
            "[Epoch 31, Step  1250] loss: 0.156\n",
            "[Epoch 31, Step  1260] loss: 0.304\n",
            "[Epoch 31, Step  1270] loss: 0.115\n",
            "[Epoch 31, Step  1280] loss: 0.680\n",
            "[Epoch 31, Step  1290] loss: 0.048\n",
            "[Epoch 31, Step  1300] loss: 0.112\n",
            "[Epoch 31, Step  1310] loss: 0.373\n",
            "[Epoch 31, Step  1320] loss: 0.427\n",
            "[Epoch 31, Step  1330] loss: 0.219\n",
            "[Epoch 31, Step  1340] loss: 0.137\n",
            "[Epoch 31, Step  1350] loss: 0.193\n",
            "[Epoch 31, Step  1360] loss: 0.132\n",
            "[Epoch 31, Step  1370] loss: 0.159\n",
            "[Epoch 31, Step  1380] loss: 0.334\n",
            "[Epoch 31, Step  1390] loss: 0.153\n",
            "[Epoch 31, Step  1400] loss: 0.176\n",
            "[Epoch 31, Step  1410] loss: 0.404\n",
            "[Epoch 31, Step  1420] loss: 0.061\n",
            "[Epoch 31, Step  1430] loss: 0.623\n",
            "[Epoch 31, Step  1440] loss: 0.369\n",
            "[Epoch 31, Step  1450] loss: 0.167\n",
            "[Epoch 31, Step  1460] loss: 0.118\n",
            "[Epoch 31, Step  1470] loss: 0.191\n",
            "[Epoch 31, Step  1480] loss: 0.480\n",
            "[Epoch 31, Step  1490] loss: 0.445\n",
            "[Epoch 31, Step  1500] loss: 0.157\n",
            "[Epoch 31, Step  1510] loss: 0.084\n",
            "[Epoch 31, Step  1520] loss: 0.623\n",
            "[Epoch 31, Step  1530] loss: 0.200\n",
            "[Epoch 31, Step  1540] loss: 0.247\n",
            "[Epoch 31, Step  1550] loss: 0.038\n",
            "[Epoch 31, Step  1560] loss: 0.258\n",
            "[Epoch 31, Step  1570] loss: 0.123\n",
            "[Epoch 31, Step  1580] loss: 0.166\n",
            "[Epoch 31, Step  1590] loss: 0.204\n",
            "[Epoch 31, Step  1600] loss: 0.286\n",
            "[Epoch 32, Step    10] loss: 0.087\n",
            "[Epoch 32, Step    20] loss: 0.170\n",
            "[Epoch 32, Step    30] loss: 0.188\n",
            "[Epoch 32, Step    40] loss: 0.292\n",
            "[Epoch 32, Step    50] loss: 0.057\n",
            "[Epoch 32, Step    60] loss: 0.198\n",
            "[Epoch 32, Step    70] loss: 0.106\n",
            "[Epoch 32, Step    80] loss: 0.452\n",
            "[Epoch 32, Step    90] loss: 0.430\n",
            "[Epoch 32, Step   100] loss: 0.269\n",
            "[Epoch 32, Step   110] loss: 0.441\n",
            "[Epoch 32, Step   120] loss: 0.120\n",
            "[Epoch 32, Step   130] loss: 0.295\n",
            "[Epoch 32, Step   140] loss: 0.165\n",
            "[Epoch 32, Step   150] loss: 0.475\n",
            "[Epoch 32, Step   160] loss: 0.563\n",
            "[Epoch 32, Step   170] loss: 0.341\n",
            "[Epoch 32, Step   180] loss: 0.205\n",
            "[Epoch 32, Step   190] loss: 0.321\n",
            "[Epoch 32, Step   200] loss: 0.255\n",
            "[Epoch 32, Step   210] loss: 0.061\n",
            "[Epoch 32, Step   220] loss: 0.404\n",
            "[Epoch 32, Step   230] loss: 0.423\n",
            "[Epoch 32, Step   240] loss: 0.272\n",
            "[Epoch 32, Step   250] loss: 0.358\n",
            "[Epoch 32, Step   260] loss: 0.324\n",
            "[Epoch 32, Step   270] loss: 0.608\n",
            "[Epoch 32, Step   280] loss: 0.185\n",
            "[Epoch 32, Step   290] loss: 0.060\n",
            "[Epoch 32, Step   300] loss: 0.181\n",
            "[Epoch 32, Step   310] loss: 0.469\n",
            "[Epoch 32, Step   320] loss: 0.212\n",
            "[Epoch 32, Step   330] loss: 0.318\n",
            "[Epoch 32, Step   340] loss: 0.219\n",
            "[Epoch 32, Step   350] loss: 0.107\n",
            "[Epoch 32, Step   360] loss: 0.142\n",
            "[Epoch 32, Step   370] loss: 0.519\n",
            "[Epoch 32, Step   380] loss: 0.399\n",
            "[Epoch 32, Step   390] loss: 0.116\n",
            "[Epoch 32, Step   400] loss: 0.307\n",
            "[Epoch 32, Step   410] loss: 0.362\n",
            "[Epoch 32, Step   420] loss: 0.109\n",
            "[Epoch 32, Step   430] loss: 0.447\n",
            "[Epoch 32, Step   440] loss: 0.095\n",
            "[Epoch 32, Step   450] loss: 0.099\n",
            "[Epoch 32, Step   460] loss: 0.258\n",
            "[Epoch 32, Step   470] loss: 0.342\n",
            "[Epoch 32, Step   480] loss: 0.306\n",
            "[Epoch 32, Step   490] loss: 0.439\n",
            "[Epoch 32, Step   500] loss: 0.252\n",
            "[Epoch 32, Step   510] loss: 0.120\n",
            "[Epoch 32, Step   520] loss: 0.030\n",
            "[Epoch 32, Step   530] loss: 0.579\n",
            "[Epoch 32, Step   540] loss: 0.279\n",
            "[Epoch 32, Step   550] loss: 0.214\n",
            "[Epoch 32, Step   560] loss: 0.516\n",
            "[Epoch 32, Step   570] loss: 0.096\n",
            "[Epoch 32, Step   580] loss: 0.190\n",
            "[Epoch 32, Step   590] loss: 0.324\n",
            "[Epoch 32, Step   600] loss: 0.382\n",
            "[Epoch 32, Step   610] loss: 0.110\n",
            "[Epoch 32, Step   620] loss: 0.063\n",
            "[Epoch 32, Step   630] loss: 0.237\n",
            "[Epoch 32, Step   640] loss: 0.101\n",
            "[Epoch 32, Step   650] loss: 0.081\n",
            "[Epoch 32, Step   660] loss: 0.226\n",
            "[Epoch 32, Step   670] loss: 0.260\n",
            "[Epoch 32, Step   680] loss: 0.297\n",
            "[Epoch 32, Step   690] loss: 0.216\n",
            "[Epoch 32, Step   700] loss: 0.223\n",
            "[Epoch 32, Step   710] loss: 0.643\n",
            "[Epoch 32, Step   720] loss: 0.050\n",
            "[Epoch 32, Step   730] loss: 0.180\n",
            "[Epoch 32, Step   740] loss: 0.349\n",
            "[Epoch 32, Step   750] loss: 0.215\n",
            "[Epoch 32, Step   760] loss: 0.377\n",
            "[Epoch 32, Step   770] loss: 0.212\n",
            "[Epoch 32, Step   780] loss: 0.436\n",
            "[Epoch 32, Step   790] loss: 0.127\n",
            "[Epoch 32, Step   800] loss: 0.101\n",
            "[Epoch 32, Step   810] loss: 0.344\n",
            "[Epoch 32, Step   820] loss: 0.270\n",
            "[Epoch 32, Step   830] loss: 0.123\n",
            "[Epoch 32, Step   840] loss: 0.143\n",
            "[Epoch 32, Step   850] loss: 0.236\n",
            "[Epoch 32, Step   860] loss: 0.339\n",
            "[Epoch 32, Step   870] loss: 0.197\n",
            "[Epoch 32, Step   880] loss: 0.248\n",
            "[Epoch 32, Step   890] loss: 0.196\n",
            "[Epoch 32, Step   900] loss: 0.525\n",
            "[Epoch 32, Step   910] loss: 0.158\n",
            "[Epoch 32, Step   920] loss: 0.162\n",
            "[Epoch 32, Step   930] loss: 0.120\n",
            "[Epoch 32, Step   940] loss: 0.355\n",
            "[Epoch 32, Step   950] loss: 0.064\n",
            "[Epoch 32, Step   960] loss: 0.240\n",
            "[Epoch 32, Step   970] loss: 0.699\n",
            "[Epoch 32, Step   980] loss: 0.301\n",
            "[Epoch 32, Step   990] loss: 0.212\n",
            "[Epoch 32, Step  1000] loss: 0.188\n",
            "[Epoch 32, Step  1010] loss: 0.206\n",
            "[Epoch 32, Step  1020] loss: 0.252\n",
            "[Epoch 32, Step  1030] loss: 0.829\n",
            "[Epoch 32, Step  1040] loss: 0.057\n",
            "[Epoch 32, Step  1050] loss: 0.204\n",
            "[Epoch 32, Step  1060] loss: 0.307\n",
            "[Epoch 32, Step  1070] loss: 0.235\n",
            "[Epoch 32, Step  1080] loss: 0.201\n",
            "[Epoch 32, Step  1090] loss: 0.437\n",
            "[Epoch 32, Step  1100] loss: 0.117\n",
            "[Epoch 32, Step  1110] loss: 0.473\n",
            "[Epoch 32, Step  1120] loss: 0.274\n",
            "[Epoch 32, Step  1130] loss: 0.118\n",
            "[Epoch 32, Step  1140] loss: 0.542\n",
            "[Epoch 32, Step  1150] loss: 0.452\n",
            "[Epoch 32, Step  1160] loss: 0.075\n",
            "[Epoch 32, Step  1170] loss: 0.397\n",
            "[Epoch 32, Step  1180] loss: 0.173\n",
            "[Epoch 32, Step  1190] loss: 0.056\n",
            "[Epoch 32, Step  1200] loss: 0.448\n",
            "[Epoch 32, Step  1210] loss: 0.203\n",
            "[Epoch 32, Step  1220] loss: 0.325\n",
            "[Epoch 32, Step  1230] loss: 0.370\n",
            "[Epoch 32, Step  1240] loss: 0.127\n",
            "[Epoch 32, Step  1250] loss: 0.301\n",
            "[Epoch 32, Step  1260] loss: 0.211\n",
            "[Epoch 32, Step  1270] loss: 0.151\n",
            "[Epoch 32, Step  1280] loss: 0.439\n",
            "[Epoch 32, Step  1290] loss: 0.133\n",
            "[Epoch 32, Step  1300] loss: 0.084\n",
            "[Epoch 32, Step  1310] loss: 0.202\n",
            "[Epoch 32, Step  1320] loss: 0.135\n",
            "[Epoch 32, Step  1330] loss: 0.522\n",
            "[Epoch 32, Step  1340] loss: 0.158\n",
            "[Epoch 32, Step  1350] loss: 0.217\n",
            "[Epoch 32, Step  1360] loss: 0.074\n",
            "[Epoch 32, Step  1370] loss: 0.151\n",
            "[Epoch 32, Step  1380] loss: 0.070\n",
            "[Epoch 32, Step  1390] loss: 0.251\n",
            "[Epoch 32, Step  1400] loss: 0.093\n",
            "[Epoch 32, Step  1410] loss: 0.139\n",
            "[Epoch 32, Step  1420] loss: 0.152\n",
            "[Epoch 32, Step  1430] loss: 0.533\n",
            "[Epoch 32, Step  1440] loss: 0.064\n",
            "[Epoch 32, Step  1450] loss: 0.397\n",
            "[Epoch 32, Step  1460] loss: 0.485\n",
            "[Epoch 32, Step  1470] loss: 0.163\n",
            "[Epoch 32, Step  1480] loss: 0.193\n",
            "[Epoch 32, Step  1490] loss: 0.577\n",
            "[Epoch 32, Step  1500] loss: 0.044\n",
            "[Epoch 32, Step  1510] loss: 0.377\n",
            "[Epoch 32, Step  1520] loss: 0.248\n",
            "[Epoch 32, Step  1530] loss: 0.042\n",
            "[Epoch 32, Step  1540] loss: 0.171\n",
            "[Epoch 32, Step  1550] loss: 0.146\n",
            "[Epoch 32, Step  1560] loss: 0.501\n",
            "[Epoch 32, Step  1570] loss: 0.342\n",
            "[Epoch 32, Step  1580] loss: 0.303\n",
            "[Epoch 32, Step  1590] loss: 0.334\n",
            "[Epoch 32, Step  1600] loss: 0.198\n",
            "[Epoch 33, Step    10] loss: 0.120\n",
            "[Epoch 33, Step    20] loss: 0.292\n",
            "[Epoch 33, Step    30] loss: 0.147\n",
            "[Epoch 33, Step    40] loss: 0.095\n",
            "[Epoch 33, Step    50] loss: 0.369\n",
            "[Epoch 33, Step    60] loss: 0.069\n",
            "[Epoch 33, Step    70] loss: 0.381\n",
            "[Epoch 33, Step    80] loss: 0.049\n",
            "[Epoch 33, Step    90] loss: 0.189\n",
            "[Epoch 33, Step   100] loss: 0.317\n",
            "[Epoch 33, Step   110] loss: 0.303\n",
            "[Epoch 33, Step   120] loss: 0.288\n",
            "[Epoch 33, Step   130] loss: 0.117\n",
            "[Epoch 33, Step   140] loss: 0.675\n",
            "[Epoch 33, Step   150] loss: 0.579\n",
            "[Epoch 33, Step   160] loss: 0.129\n",
            "[Epoch 33, Step   170] loss: 0.231\n",
            "[Epoch 33, Step   180] loss: 0.144\n",
            "[Epoch 33, Step   190] loss: 0.535\n",
            "[Epoch 33, Step   200] loss: 0.133\n",
            "[Epoch 33, Step   210] loss: 0.139\n",
            "[Epoch 33, Step   220] loss: 0.163\n",
            "[Epoch 33, Step   230] loss: 0.080\n",
            "[Epoch 33, Step   240] loss: 0.143\n",
            "[Epoch 33, Step   250] loss: 0.702\n",
            "[Epoch 33, Step   260] loss: 0.100\n",
            "[Epoch 33, Step   270] loss: 0.121\n",
            "[Epoch 33, Step   280] loss: 0.416\n",
            "[Epoch 33, Step   290] loss: 0.524\n",
            "[Epoch 33, Step   300] loss: 0.041\n",
            "[Epoch 33, Step   310] loss: 0.328\n",
            "[Epoch 33, Step   320] loss: 0.186\n",
            "[Epoch 33, Step   330] loss: 0.162\n",
            "[Epoch 33, Step   340] loss: 0.052\n",
            "[Epoch 33, Step   350] loss: 0.079\n",
            "[Epoch 33, Step   360] loss: 0.215\n",
            "[Epoch 33, Step   370] loss: 0.071\n",
            "[Epoch 33, Step   380] loss: 0.302\n",
            "[Epoch 33, Step   390] loss: 0.608\n",
            "[Epoch 33, Step   400] loss: 0.154\n",
            "[Epoch 33, Step   410] loss: 0.406\n",
            "[Epoch 33, Step   420] loss: 0.562\n",
            "[Epoch 33, Step   430] loss: 0.159\n",
            "[Epoch 33, Step   440] loss: 0.546\n",
            "[Epoch 33, Step   450] loss: 0.171\n",
            "[Epoch 33, Step   460] loss: 0.108\n",
            "[Epoch 33, Step   470] loss: 0.359\n",
            "[Epoch 33, Step   480] loss: 0.190\n",
            "[Epoch 33, Step   490] loss: 0.132\n",
            "[Epoch 33, Step   500] loss: 0.004\n",
            "[Epoch 33, Step   510] loss: 0.189\n",
            "[Epoch 33, Step   520] loss: 0.460\n",
            "[Epoch 33, Step   530] loss: 0.574\n",
            "[Epoch 33, Step   540] loss: 0.134\n",
            "[Epoch 33, Step   550] loss: 0.332\n",
            "[Epoch 33, Step   560] loss: 0.577\n",
            "[Epoch 33, Step   570] loss: 0.333\n",
            "[Epoch 33, Step   580] loss: 0.155\n",
            "[Epoch 33, Step   590] loss: 0.245\n",
            "[Epoch 33, Step   600] loss: 0.172\n",
            "[Epoch 33, Step   610] loss: 0.366\n",
            "[Epoch 33, Step   620] loss: 0.150\n",
            "[Epoch 33, Step   630] loss: 0.598\n",
            "[Epoch 33, Step   640] loss: 0.326\n",
            "[Epoch 33, Step   650] loss: 0.090\n",
            "[Epoch 33, Step   660] loss: 0.107\n",
            "[Epoch 33, Step   670] loss: 0.463\n",
            "[Epoch 33, Step   680] loss: 0.276\n",
            "[Epoch 33, Step   690] loss: 0.216\n",
            "[Epoch 33, Step   700] loss: 0.349\n",
            "[Epoch 33, Step   710] loss: 0.102\n",
            "[Epoch 33, Step   720] loss: 0.379\n",
            "[Epoch 33, Step   730] loss: 0.232\n",
            "[Epoch 33, Step   740] loss: 0.146\n",
            "[Epoch 33, Step   750] loss: 0.320\n",
            "[Epoch 33, Step   760] loss: 0.256\n",
            "[Epoch 33, Step   770] loss: 0.348\n",
            "[Epoch 33, Step   780] loss: 0.582\n",
            "[Epoch 33, Step   790] loss: 0.459\n",
            "[Epoch 33, Step   800] loss: 0.240\n",
            "[Epoch 33, Step   810] loss: 0.358\n",
            "[Epoch 33, Step   820] loss: 0.263\n",
            "[Epoch 33, Step   830] loss: 0.122\n",
            "[Epoch 33, Step   840] loss: 0.077\n",
            "[Epoch 33, Step   850] loss: 0.453\n",
            "[Epoch 33, Step   860] loss: 0.143\n",
            "[Epoch 33, Step   870] loss: 0.218\n",
            "[Epoch 33, Step   880] loss: 0.201\n",
            "[Epoch 33, Step   890] loss: 0.194\n",
            "[Epoch 33, Step   900] loss: 0.354\n",
            "[Epoch 33, Step   910] loss: 0.077\n",
            "[Epoch 33, Step   920] loss: 0.306\n",
            "[Epoch 33, Step   930] loss: 0.118\n",
            "[Epoch 33, Step   940] loss: 0.237\n",
            "[Epoch 33, Step   950] loss: 0.174\n",
            "[Epoch 33, Step   960] loss: 0.174\n",
            "[Epoch 33, Step   970] loss: 0.138\n",
            "[Epoch 33, Step   980] loss: 0.201\n",
            "[Epoch 33, Step   990] loss: 0.253\n",
            "[Epoch 33, Step  1000] loss: 0.216\n",
            "[Epoch 33, Step  1010] loss: 0.641\n",
            "[Epoch 33, Step  1020] loss: 0.106\n",
            "[Epoch 33, Step  1030] loss: 0.523\n",
            "[Epoch 33, Step  1040] loss: 0.097\n",
            "[Epoch 33, Step  1050] loss: 0.231\n",
            "[Epoch 33, Step  1060] loss: 0.070\n",
            "[Epoch 33, Step  1070] loss: 0.112\n",
            "[Epoch 33, Step  1080] loss: 0.080\n",
            "[Epoch 33, Step  1090] loss: 0.521\n",
            "[Epoch 33, Step  1100] loss: 0.205\n",
            "[Epoch 33, Step  1110] loss: 0.142\n",
            "[Epoch 33, Step  1120] loss: 0.072\n",
            "[Epoch 33, Step  1130] loss: 0.541\n",
            "[Epoch 33, Step  1140] loss: 0.060\n",
            "[Epoch 33, Step  1150] loss: 0.276\n",
            "[Epoch 33, Step  1160] loss: 0.454\n",
            "[Epoch 33, Step  1170] loss: 0.221\n",
            "[Epoch 33, Step  1180] loss: 0.135\n",
            "[Epoch 33, Step  1190] loss: 0.284\n",
            "[Epoch 33, Step  1200] loss: 0.187\n",
            "[Epoch 33, Step  1210] loss: 0.198\n",
            "[Epoch 33, Step  1220] loss: 0.116\n",
            "[Epoch 33, Step  1230] loss: 0.300\n",
            "[Epoch 33, Step  1240] loss: 0.349\n",
            "[Epoch 33, Step  1250] loss: 0.164\n",
            "[Epoch 33, Step  1260] loss: 0.239\n",
            "[Epoch 33, Step  1270] loss: 0.073\n",
            "[Epoch 33, Step  1280] loss: 0.588\n",
            "[Epoch 33, Step  1290] loss: 0.455\n",
            "[Epoch 33, Step  1300] loss: 0.204\n",
            "[Epoch 33, Step  1310] loss: 0.289\n",
            "[Epoch 33, Step  1320] loss: 0.219\n",
            "[Epoch 33, Step  1330] loss: 0.281\n",
            "[Epoch 33, Step  1340] loss: 0.143\n",
            "[Epoch 33, Step  1350] loss: 0.517\n",
            "[Epoch 33, Step  1360] loss: 0.279\n",
            "[Epoch 33, Step  1370] loss: 0.144\n",
            "[Epoch 33, Step  1380] loss: 0.296\n",
            "[Epoch 33, Step  1390] loss: 0.163\n",
            "[Epoch 33, Step  1400] loss: 0.309\n",
            "[Epoch 33, Step  1410] loss: 0.203\n",
            "[Epoch 33, Step  1420] loss: 0.499\n",
            "[Epoch 33, Step  1430] loss: 0.197\n",
            "[Epoch 33, Step  1440] loss: 0.035\n",
            "[Epoch 33, Step  1450] loss: 0.258\n",
            "[Epoch 33, Step  1460] loss: 0.239\n",
            "[Epoch 33, Step  1470] loss: 0.210\n",
            "[Epoch 33, Step  1480] loss: 0.388\n",
            "[Epoch 33, Step  1490] loss: 0.240\n",
            "[Epoch 33, Step  1500] loss: 0.437\n",
            "[Epoch 33, Step  1510] loss: 0.149\n",
            "[Epoch 33, Step  1520] loss: 0.207\n",
            "[Epoch 33, Step  1530] loss: 0.409\n",
            "[Epoch 33, Step  1540] loss: 0.257\n",
            "[Epoch 33, Step  1550] loss: 0.094\n",
            "[Epoch 33, Step  1560] loss: 0.505\n",
            "[Epoch 33, Step  1570] loss: 0.112\n",
            "[Epoch 33, Step  1580] loss: 0.116\n",
            "[Epoch 33, Step  1590] loss: 0.428\n",
            "[Epoch 33, Step  1600] loss: 0.201\n",
            "[Epoch 34, Step    10] loss: 0.120\n",
            "[Epoch 34, Step    20] loss: 0.179\n",
            "[Epoch 34, Step    30] loss: 0.298\n",
            "[Epoch 34, Step    40] loss: 0.200\n",
            "[Epoch 34, Step    50] loss: 0.219\n",
            "[Epoch 34, Step    60] loss: 0.164\n",
            "[Epoch 34, Step    70] loss: 0.168\n",
            "[Epoch 34, Step    80] loss: 0.233\n",
            "[Epoch 34, Step    90] loss: 0.321\n",
            "[Epoch 34, Step   100] loss: 0.221\n",
            "[Epoch 34, Step   110] loss: 0.122\n",
            "[Epoch 34, Step   120] loss: 0.157\n",
            "[Epoch 34, Step   130] loss: 0.272\n",
            "[Epoch 34, Step   140] loss: 0.090\n",
            "[Epoch 34, Step   150] loss: 0.124\n",
            "[Epoch 34, Step   160] loss: 0.610\n",
            "[Epoch 34, Step   170] loss: 0.175\n",
            "[Epoch 34, Step   180] loss: 0.098\n",
            "[Epoch 34, Step   190] loss: 0.248\n",
            "[Epoch 34, Step   200] loss: 0.126\n",
            "[Epoch 34, Step   210] loss: 0.147\n",
            "[Epoch 34, Step   220] loss: 0.095\n",
            "[Epoch 34, Step   230] loss: 0.616\n",
            "[Epoch 34, Step   240] loss: 0.680\n",
            "[Epoch 34, Step   250] loss: 0.093\n",
            "[Epoch 34, Step   260] loss: 0.152\n",
            "[Epoch 34, Step   270] loss: 0.160\n",
            "[Epoch 34, Step   280] loss: 0.190\n",
            "[Epoch 34, Step   290] loss: 0.185\n",
            "[Epoch 34, Step   300] loss: 0.104\n",
            "[Epoch 34, Step   310] loss: 0.233\n",
            "[Epoch 34, Step   320] loss: 0.181\n",
            "[Epoch 34, Step   330] loss: 0.170\n",
            "[Epoch 34, Step   340] loss: 0.559\n",
            "[Epoch 34, Step   350] loss: 0.309\n",
            "[Epoch 34, Step   360] loss: 0.280\n",
            "[Epoch 34, Step   370] loss: 0.269\n",
            "[Epoch 34, Step   380] loss: 0.452\n",
            "[Epoch 34, Step   390] loss: 0.634\n",
            "[Epoch 34, Step   400] loss: 0.133\n",
            "[Epoch 34, Step   410] loss: 0.594\n",
            "[Epoch 34, Step   420] loss: 0.260\n",
            "[Epoch 34, Step   430] loss: 0.118\n",
            "[Epoch 34, Step   440] loss: 0.286\n",
            "[Epoch 34, Step   450] loss: 0.266\n",
            "[Epoch 34, Step   460] loss: 0.323\n",
            "[Epoch 34, Step   470] loss: 0.326\n",
            "[Epoch 34, Step   480] loss: 0.146\n",
            "[Epoch 34, Step   490] loss: 0.160\n",
            "[Epoch 34, Step   500] loss: 0.329\n",
            "[Epoch 34, Step   510] loss: 0.557\n",
            "[Epoch 34, Step   520] loss: 0.306\n",
            "[Epoch 34, Step   530] loss: 0.329\n",
            "[Epoch 34, Step   540] loss: 0.130\n",
            "[Epoch 34, Step   550] loss: 0.234\n",
            "[Epoch 34, Step   560] loss: 0.099\n",
            "[Epoch 34, Step   570] loss: 0.100\n",
            "[Epoch 34, Step   580] loss: 0.149\n",
            "[Epoch 34, Step   590] loss: 0.443\n",
            "[Epoch 34, Step   600] loss: 0.294\n",
            "[Epoch 34, Step   610] loss: 0.382\n",
            "[Epoch 34, Step   620] loss: 0.267\n",
            "[Epoch 34, Step   630] loss: 0.298\n",
            "[Epoch 34, Step   640] loss: 0.584\n",
            "[Epoch 34, Step   650] loss: 0.172\n",
            "[Epoch 34, Step   660] loss: 0.255\n",
            "[Epoch 34, Step   670] loss: 0.059\n",
            "[Epoch 34, Step   680] loss: 0.330\n",
            "[Epoch 34, Step   690] loss: 0.157\n",
            "[Epoch 34, Step   700] loss: 0.087\n",
            "[Epoch 34, Step   710] loss: 0.207\n",
            "[Epoch 34, Step   720] loss: 0.216\n",
            "[Epoch 34, Step   730] loss: 0.090\n",
            "[Epoch 34, Step   740] loss: 0.184\n",
            "[Epoch 34, Step   750] loss: 0.237\n",
            "[Epoch 34, Step   760] loss: 0.148\n",
            "[Epoch 34, Step   770] loss: 0.177\n",
            "[Epoch 34, Step   780] loss: 0.224\n",
            "[Epoch 34, Step   790] loss: 0.233\n",
            "[Epoch 34, Step   800] loss: 0.211\n",
            "[Epoch 34, Step   810] loss: 0.672\n",
            "[Epoch 34, Step   820] loss: 0.054\n",
            "[Epoch 34, Step   830] loss: 0.074\n",
            "[Epoch 34, Step   840] loss: 0.460\n",
            "[Epoch 34, Step   850] loss: 0.152\n",
            "[Epoch 34, Step   860] loss: 0.183\n",
            "[Epoch 34, Step   870] loss: 0.556\n",
            "[Epoch 34, Step   880] loss: 0.088\n",
            "[Epoch 34, Step   890] loss: 0.082\n",
            "[Epoch 34, Step   900] loss: 0.219\n",
            "[Epoch 34, Step   910] loss: 0.322\n",
            "[Epoch 34, Step   920] loss: 0.240\n",
            "[Epoch 34, Step   930] loss: 0.256\n",
            "[Epoch 34, Step   940] loss: 0.155\n",
            "[Epoch 34, Step   950] loss: 0.067\n",
            "[Epoch 34, Step   960] loss: 0.126\n",
            "[Epoch 34, Step   970] loss: 0.311\n",
            "[Epoch 34, Step   980] loss: 0.205\n",
            "[Epoch 34, Step   990] loss: 0.666\n",
            "[Epoch 34, Step  1000] loss: 0.155\n",
            "[Epoch 34, Step  1010] loss: 0.104\n",
            "[Epoch 34, Step  1020] loss: 0.367\n",
            "[Epoch 34, Step  1030] loss: 0.130\n",
            "[Epoch 34, Step  1040] loss: 0.627\n",
            "[Epoch 34, Step  1050] loss: 0.339\n",
            "[Epoch 34, Step  1060] loss: 0.131\n",
            "[Epoch 34, Step  1070] loss: 0.186\n",
            "[Epoch 34, Step  1080] loss: 0.298\n",
            "[Epoch 34, Step  1090] loss: 0.337\n",
            "[Epoch 34, Step  1100] loss: 0.233\n",
            "[Epoch 34, Step  1110] loss: 0.482\n",
            "[Epoch 34, Step  1120] loss: 0.832\n",
            "[Epoch 34, Step  1130] loss: 0.337\n",
            "[Epoch 34, Step  1140] loss: 0.490\n",
            "[Epoch 34, Step  1150] loss: 0.037\n",
            "[Epoch 34, Step  1160] loss: 0.270\n",
            "[Epoch 34, Step  1170] loss: 0.125\n",
            "[Epoch 34, Step  1180] loss: 0.193\n",
            "[Epoch 34, Step  1190] loss: 0.158\n",
            "[Epoch 34, Step  1200] loss: 0.299\n",
            "[Epoch 34, Step  1210] loss: 0.158\n",
            "[Epoch 34, Step  1220] loss: 0.078\n",
            "[Epoch 34, Step  1230] loss: 0.298\n",
            "[Epoch 34, Step  1240] loss: 0.282\n",
            "[Epoch 34, Step  1250] loss: 0.252\n",
            "[Epoch 34, Step  1260] loss: 0.170\n",
            "[Epoch 34, Step  1270] loss: 0.299\n",
            "[Epoch 34, Step  1280] loss: 0.445\n",
            "[Epoch 34, Step  1290] loss: 0.163\n",
            "[Epoch 34, Step  1300] loss: 0.191\n",
            "[Epoch 34, Step  1310] loss: 0.404\n",
            "[Epoch 34, Step  1320] loss: 0.235\n",
            "[Epoch 34, Step  1330] loss: 0.198\n",
            "[Epoch 34, Step  1340] loss: 0.143\n",
            "[Epoch 34, Step  1350] loss: 0.392\n",
            "[Epoch 34, Step  1360] loss: 0.221\n",
            "[Epoch 34, Step  1370] loss: 0.135\n",
            "[Epoch 34, Step  1380] loss: 0.332\n",
            "[Epoch 34, Step  1390] loss: 0.262\n",
            "[Epoch 34, Step  1400] loss: 0.522\n",
            "[Epoch 34, Step  1410] loss: 0.341\n",
            "[Epoch 34, Step  1420] loss: 0.245\n",
            "[Epoch 34, Step  1430] loss: 0.221\n",
            "[Epoch 34, Step  1440] loss: 0.264\n",
            "[Epoch 34, Step  1450] loss: 0.244\n",
            "[Epoch 34, Step  1460] loss: 0.186\n",
            "[Epoch 34, Step  1470] loss: 0.390\n",
            "[Epoch 34, Step  1480] loss: 0.144\n",
            "[Epoch 34, Step  1490] loss: 0.553\n",
            "[Epoch 34, Step  1500] loss: 0.107\n",
            "[Epoch 34, Step  1510] loss: 0.317\n",
            "[Epoch 34, Step  1520] loss: 0.029\n",
            "[Epoch 34, Step  1530] loss: 0.263\n",
            "[Epoch 34, Step  1540] loss: 0.237\n",
            "[Epoch 34, Step  1550] loss: 0.223\n",
            "[Epoch 34, Step  1560] loss: 0.326\n",
            "[Epoch 34, Step  1570] loss: 0.165\n",
            "[Epoch 34, Step  1580] loss: 0.251\n",
            "[Epoch 34, Step  1590] loss: 0.137\n",
            "[Epoch 34, Step  1600] loss: 0.258\n",
            "[Epoch 35, Step    10] loss: 0.203\n",
            "[Epoch 35, Step    20] loss: 0.419\n",
            "[Epoch 35, Step    30] loss: 0.018\n",
            "[Epoch 35, Step    40] loss: 0.258\n",
            "[Epoch 35, Step    50] loss: 0.151\n",
            "[Epoch 35, Step    60] loss: 0.252\n",
            "[Epoch 35, Step    70] loss: 0.189\n",
            "[Epoch 35, Step    80] loss: 0.188\n",
            "[Epoch 35, Step    90] loss: 0.411\n",
            "[Epoch 35, Step   100] loss: 0.073\n",
            "[Epoch 35, Step   110] loss: 0.288\n",
            "[Epoch 35, Step   120] loss: 0.077\n",
            "[Epoch 35, Step   130] loss: 0.445\n",
            "[Epoch 35, Step   140] loss: 0.140\n",
            "[Epoch 35, Step   150] loss: 0.398\n",
            "[Epoch 35, Step   160] loss: 0.079\n",
            "[Epoch 35, Step   170] loss: 0.347\n",
            "[Epoch 35, Step   180] loss: 0.123\n",
            "[Epoch 35, Step   190] loss: 0.207\n",
            "[Epoch 35, Step   200] loss: 0.164\n",
            "[Epoch 35, Step   210] loss: 0.267\n",
            "[Epoch 35, Step   220] loss: 0.160\n",
            "[Epoch 35, Step   230] loss: 0.225\n",
            "[Epoch 35, Step   240] loss: 0.044\n",
            "[Epoch 35, Step   250] loss: 0.121\n",
            "[Epoch 35, Step   260] loss: 0.014\n",
            "[Epoch 35, Step   270] loss: 0.095\n",
            "[Epoch 35, Step   280] loss: 0.180\n",
            "[Epoch 35, Step   290] loss: 0.314\n",
            "[Epoch 35, Step   300] loss: 0.084\n",
            "[Epoch 35, Step   310] loss: 0.252\n",
            "[Epoch 35, Step   320] loss: 0.262\n",
            "[Epoch 35, Step   330] loss: 0.241\n",
            "[Epoch 35, Step   340] loss: 0.307\n",
            "[Epoch 35, Step   350] loss: 0.106\n",
            "[Epoch 35, Step   360] loss: 0.160\n",
            "[Epoch 35, Step   370] loss: 0.127\n",
            "[Epoch 35, Step   380] loss: 0.221\n",
            "[Epoch 35, Step   390] loss: 0.162\n",
            "[Epoch 35, Step   400] loss: 0.254\n",
            "[Epoch 35, Step   410] loss: 0.058\n",
            "[Epoch 35, Step   420] loss: 0.336\n",
            "[Epoch 35, Step   430] loss: 0.206\n",
            "[Epoch 35, Step   440] loss: 0.273\n",
            "[Epoch 35, Step   450] loss: 0.395\n",
            "[Epoch 35, Step   460] loss: 0.124\n",
            "[Epoch 35, Step   470] loss: 0.129\n",
            "[Epoch 35, Step   480] loss: 0.645\n",
            "[Epoch 35, Step   490] loss: 0.121\n",
            "[Epoch 35, Step   500] loss: 0.369\n",
            "[Epoch 35, Step   510] loss: 0.277\n",
            "[Epoch 35, Step   520] loss: 0.592\n",
            "[Epoch 35, Step   530] loss: 0.188\n",
            "[Epoch 35, Step   540] loss: 0.413\n",
            "[Epoch 35, Step   550] loss: 0.367\n",
            "[Epoch 35, Step   560] loss: 0.132\n",
            "[Epoch 35, Step   570] loss: 0.377\n",
            "[Epoch 35, Step   580] loss: 0.075\n",
            "[Epoch 35, Step   590] loss: 0.043\n",
            "[Epoch 35, Step   600] loss: 0.174\n",
            "[Epoch 35, Step   610] loss: 0.286\n",
            "[Epoch 35, Step   620] loss: 0.412\n",
            "[Epoch 35, Step   630] loss: 0.249\n",
            "[Epoch 35, Step   640] loss: 0.193\n",
            "[Epoch 35, Step   650] loss: 0.650\n",
            "[Epoch 35, Step   660] loss: 0.430\n",
            "[Epoch 35, Step   670] loss: 0.033\n",
            "[Epoch 35, Step   680] loss: 0.296\n",
            "[Epoch 35, Step   690] loss: 0.121\n",
            "[Epoch 35, Step   700] loss: 0.197\n",
            "[Epoch 35, Step   710] loss: 0.388\n",
            "[Epoch 35, Step   720] loss: 0.429\n",
            "[Epoch 35, Step   730] loss: 0.082\n",
            "[Epoch 35, Step   740] loss: 0.112\n",
            "[Epoch 35, Step   750] loss: 0.826\n",
            "[Epoch 35, Step   760] loss: 0.235\n",
            "[Epoch 35, Step   770] loss: 0.032\n",
            "[Epoch 35, Step   780] loss: 0.068\n",
            "[Epoch 35, Step   790] loss: 0.471\n",
            "[Epoch 35, Step   800] loss: 0.096\n",
            "[Epoch 35, Step   810] loss: 0.181\n",
            "[Epoch 35, Step   820] loss: 0.136\n",
            "[Epoch 35, Step   830] loss: 0.158\n",
            "[Epoch 35, Step   840] loss: 0.172\n",
            "[Epoch 35, Step   850] loss: 0.617\n",
            "[Epoch 35, Step   860] loss: 0.760\n",
            "[Epoch 35, Step   870] loss: 0.253\n",
            "[Epoch 35, Step   880] loss: 0.196\n",
            "[Epoch 35, Step   890] loss: 0.120\n",
            "[Epoch 35, Step   900] loss: 0.322\n",
            "[Epoch 35, Step   910] loss: 0.512\n",
            "[Epoch 35, Step   920] loss: 0.364\n",
            "[Epoch 35, Step   930] loss: 0.156\n",
            "[Epoch 35, Step   940] loss: 0.405\n",
            "[Epoch 35, Step   950] loss: 0.250\n",
            "[Epoch 35, Step   960] loss: 0.087\n",
            "[Epoch 35, Step   970] loss: 0.187\n",
            "[Epoch 35, Step   980] loss: 0.098\n",
            "[Epoch 35, Step   990] loss: 0.689\n",
            "[Epoch 35, Step  1000] loss: 0.249\n",
            "[Epoch 35, Step  1010] loss: 0.403\n",
            "[Epoch 35, Step  1020] loss: 0.244\n",
            "[Epoch 35, Step  1030] loss: 0.300\n",
            "[Epoch 35, Step  1040] loss: 0.350\n",
            "[Epoch 35, Step  1050] loss: 0.335\n",
            "[Epoch 35, Step  1060] loss: 0.217\n",
            "[Epoch 35, Step  1070] loss: 0.151\n",
            "[Epoch 35, Step  1080] loss: 0.185\n",
            "[Epoch 35, Step  1090] loss: 0.152\n",
            "[Epoch 35, Step  1100] loss: 0.197\n",
            "[Epoch 35, Step  1110] loss: 0.411\n",
            "[Epoch 35, Step  1120] loss: 0.315\n",
            "[Epoch 35, Step  1130] loss: 0.310\n",
            "[Epoch 35, Step  1140] loss: 0.402\n",
            "[Epoch 35, Step  1150] loss: 0.506\n",
            "[Epoch 35, Step  1160] loss: 0.137\n",
            "[Epoch 35, Step  1170] loss: 0.097\n",
            "[Epoch 35, Step  1180] loss: 0.320\n",
            "[Epoch 35, Step  1190] loss: 0.125\n",
            "[Epoch 35, Step  1200] loss: 0.318\n",
            "[Epoch 35, Step  1210] loss: 0.144\n",
            "[Epoch 35, Step  1220] loss: 0.320\n",
            "[Epoch 35, Step  1230] loss: 0.266\n",
            "[Epoch 35, Step  1240] loss: 0.183\n",
            "[Epoch 35, Step  1250] loss: 0.155\n",
            "[Epoch 35, Step  1260] loss: 0.379\n",
            "[Epoch 35, Step  1270] loss: 0.115\n",
            "[Epoch 35, Step  1280] loss: 0.576\n",
            "[Epoch 35, Step  1290] loss: 0.175\n",
            "[Epoch 35, Step  1300] loss: 0.254\n",
            "[Epoch 35, Step  1310] loss: 0.410\n",
            "[Epoch 35, Step  1320] loss: 0.443\n",
            "[Epoch 35, Step  1330] loss: 0.298\n",
            "[Epoch 35, Step  1340] loss: 0.524\n",
            "[Epoch 35, Step  1350] loss: 0.240\n",
            "[Epoch 35, Step  1360] loss: 0.211\n",
            "[Epoch 35, Step  1370] loss: 0.094\n",
            "[Epoch 35, Step  1380] loss: 0.215\n",
            "[Epoch 35, Step  1390] loss: 0.239\n",
            "[Epoch 35, Step  1400] loss: 0.238\n",
            "[Epoch 35, Step  1410] loss: 0.158\n",
            "[Epoch 35, Step  1420] loss: 0.250\n",
            "[Epoch 35, Step  1430] loss: 0.153\n",
            "[Epoch 35, Step  1440] loss: 0.123\n",
            "[Epoch 35, Step  1450] loss: 0.188\n",
            "[Epoch 35, Step  1460] loss: 0.180\n",
            "[Epoch 35, Step  1470] loss: 0.205\n",
            "[Epoch 35, Step  1480] loss: 0.389\n",
            "[Epoch 35, Step  1490] loss: 0.129\n",
            "[Epoch 35, Step  1500] loss: 0.058\n",
            "[Epoch 35, Step  1510] loss: 0.244\n",
            "[Epoch 35, Step  1520] loss: 0.067\n",
            "[Epoch 35, Step  1530] loss: 0.110\n",
            "[Epoch 35, Step  1540] loss: 0.353\n",
            "[Epoch 35, Step  1550] loss: 0.154\n",
            "[Epoch 35, Step  1560] loss: 0.208\n",
            "[Epoch 35, Step  1570] loss: 0.448\n",
            "[Epoch 35, Step  1580] loss: 0.108\n",
            "[Epoch 35, Step  1590] loss: 0.202\n",
            "[Epoch 35, Step  1600] loss: 0.616\n",
            "[Epoch 36, Step    10] loss: 0.525\n",
            "[Epoch 36, Step    20] loss: 0.598\n",
            "[Epoch 36, Step    30] loss: 0.077\n",
            "[Epoch 36, Step    40] loss: 0.236\n",
            "[Epoch 36, Step    50] loss: 0.230\n",
            "[Epoch 36, Step    60] loss: 0.323\n",
            "[Epoch 36, Step    70] loss: 0.276\n",
            "[Epoch 36, Step    80] loss: 0.463\n",
            "[Epoch 36, Step    90] loss: 0.279\n",
            "[Epoch 36, Step   100] loss: 0.071\n",
            "[Epoch 36, Step   110] loss: 0.303\n",
            "[Epoch 36, Step   120] loss: 0.237\n",
            "[Epoch 36, Step   130] loss: 0.339\n",
            "[Epoch 36, Step   140] loss: 0.148\n",
            "[Epoch 36, Step   150] loss: 0.277\n",
            "[Epoch 36, Step   160] loss: 0.301\n",
            "[Epoch 36, Step   170] loss: 0.282\n",
            "[Epoch 36, Step   180] loss: 0.356\n",
            "[Epoch 36, Step   190] loss: 0.522\n",
            "[Epoch 36, Step   200] loss: 0.099\n",
            "[Epoch 36, Step   210] loss: 0.106\n",
            "[Epoch 36, Step   220] loss: 0.210\n",
            "[Epoch 36, Step   230] loss: 0.102\n",
            "[Epoch 36, Step   240] loss: 0.749\n",
            "[Epoch 36, Step   250] loss: 0.485\n",
            "[Epoch 36, Step   260] loss: 0.396\n",
            "[Epoch 36, Step   270] loss: 0.774\n",
            "[Epoch 36, Step   280] loss: 0.302\n",
            "[Epoch 36, Step   290] loss: 0.177\n",
            "[Epoch 36, Step   300] loss: 0.216\n",
            "[Epoch 36, Step   310] loss: 0.081\n",
            "[Epoch 36, Step   320] loss: 0.180\n",
            "[Epoch 36, Step   330] loss: 0.124\n",
            "[Epoch 36, Step   340] loss: 0.114\n",
            "[Epoch 36, Step   350] loss: 0.097\n",
            "[Epoch 36, Step   360] loss: 0.459\n",
            "[Epoch 36, Step   370] loss: 0.124\n",
            "[Epoch 36, Step   380] loss: 0.112\n",
            "[Epoch 36, Step   390] loss: 0.317\n",
            "[Epoch 36, Step   400] loss: 0.338\n",
            "[Epoch 36, Step   410] loss: 0.283\n",
            "[Epoch 36, Step   420] loss: 0.139\n",
            "[Epoch 36, Step   430] loss: 0.212\n",
            "[Epoch 36, Step   440] loss: 0.065\n",
            "[Epoch 36, Step   450] loss: 0.247\n",
            "[Epoch 36, Step   460] loss: 0.086\n",
            "[Epoch 36, Step   470] loss: 0.248\n",
            "[Epoch 36, Step   480] loss: 0.316\n",
            "[Epoch 36, Step   490] loss: 0.056\n",
            "[Epoch 36, Step   500] loss: 0.302\n",
            "[Epoch 36, Step   510] loss: 0.225\n",
            "[Epoch 36, Step   520] loss: 0.221\n",
            "[Epoch 36, Step   530] loss: 0.233\n",
            "[Epoch 36, Step   540] loss: 0.150\n",
            "[Epoch 36, Step   550] loss: 0.093\n",
            "[Epoch 36, Step   560] loss: 0.173\n",
            "[Epoch 36, Step   570] loss: 0.353\n",
            "[Epoch 36, Step   580] loss: 0.279\n",
            "[Epoch 36, Step   590] loss: 0.089\n",
            "[Epoch 36, Step   600] loss: 0.250\n",
            "[Epoch 36, Step   610] loss: 0.309\n",
            "[Epoch 36, Step   620] loss: 0.313\n",
            "[Epoch 36, Step   630] loss: 0.254\n",
            "[Epoch 36, Step   640] loss: 0.189\n",
            "[Epoch 36, Step   650] loss: 0.206\n",
            "[Epoch 36, Step   660] loss: 0.196\n",
            "[Epoch 36, Step   670] loss: 0.636\n",
            "[Epoch 36, Step   680] loss: 0.153\n",
            "[Epoch 36, Step   690] loss: 0.206\n",
            "[Epoch 36, Step   700] loss: 0.360\n",
            "[Epoch 36, Step   710] loss: 0.389\n",
            "[Epoch 36, Step   720] loss: 0.186\n",
            "[Epoch 36, Step   730] loss: 0.049\n",
            "[Epoch 36, Step   740] loss: 0.047\n",
            "[Epoch 36, Step   750] loss: 0.046\n",
            "[Epoch 36, Step   760] loss: 0.103\n",
            "[Epoch 36, Step   770] loss: 0.375\n",
            "[Epoch 36, Step   780] loss: 0.033\n",
            "[Epoch 36, Step   790] loss: 0.138\n",
            "[Epoch 36, Step   800] loss: 0.324\n",
            "[Epoch 36, Step   810] loss: 0.445\n",
            "[Epoch 36, Step   820] loss: 0.352\n",
            "[Epoch 36, Step   830] loss: 0.099\n",
            "[Epoch 36, Step   840] loss: 0.147\n",
            "[Epoch 36, Step   850] loss: 0.054\n",
            "[Epoch 36, Step   860] loss: 0.258\n",
            "[Epoch 36, Step   870] loss: 0.368\n",
            "[Epoch 36, Step   880] loss: 0.606\n",
            "[Epoch 36, Step   890] loss: 0.307\n",
            "[Epoch 36, Step   900] loss: 0.211\n",
            "[Epoch 36, Step   910] loss: 0.097\n",
            "[Epoch 36, Step   920] loss: 0.343\n",
            "[Epoch 36, Step   930] loss: 0.489\n",
            "[Epoch 36, Step   940] loss: 0.073\n",
            "[Epoch 36, Step   950] loss: 0.172\n",
            "[Epoch 36, Step   960] loss: 0.101\n",
            "[Epoch 36, Step   970] loss: 0.051\n",
            "[Epoch 36, Step   980] loss: 0.173\n",
            "[Epoch 36, Step   990] loss: 0.118\n",
            "[Epoch 36, Step  1000] loss: 0.018\n",
            "[Epoch 36, Step  1010] loss: 0.612\n",
            "[Epoch 36, Step  1020] loss: 0.436\n",
            "[Epoch 36, Step  1030] loss: 0.397\n",
            "[Epoch 36, Step  1040] loss: 0.190\n",
            "[Epoch 36, Step  1050] loss: 0.274\n",
            "[Epoch 36, Step  1060] loss: 0.335\n",
            "[Epoch 36, Step  1070] loss: 0.070\n",
            "[Epoch 36, Step  1080] loss: 0.077\n",
            "[Epoch 36, Step  1090] loss: 0.641\n",
            "[Epoch 36, Step  1100] loss: 0.289\n",
            "[Epoch 36, Step  1110] loss: 0.205\n",
            "[Epoch 36, Step  1120] loss: 0.306\n",
            "[Epoch 36, Step  1130] loss: 0.135\n",
            "[Epoch 36, Step  1140] loss: 0.098\n",
            "[Epoch 36, Step  1150] loss: 0.091\n",
            "[Epoch 36, Step  1160] loss: 0.352\n",
            "[Epoch 36, Step  1170] loss: 0.243\n",
            "[Epoch 36, Step  1180] loss: 0.437\n",
            "[Epoch 36, Step  1190] loss: 0.134\n",
            "[Epoch 36, Step  1200] loss: 0.271\n",
            "[Epoch 36, Step  1210] loss: 0.192\n",
            "[Epoch 36, Step  1220] loss: 0.771\n",
            "[Epoch 36, Step  1230] loss: 0.100\n",
            "[Epoch 36, Step  1240] loss: 0.128\n",
            "[Epoch 36, Step  1250] loss: 0.108\n",
            "[Epoch 36, Step  1260] loss: 0.079\n",
            "[Epoch 36, Step  1270] loss: 0.420\n",
            "[Epoch 36, Step  1280] loss: 0.151\n",
            "[Epoch 36, Step  1290] loss: 0.337\n",
            "[Epoch 36, Step  1300] loss: 0.488\n",
            "[Epoch 36, Step  1310] loss: 0.284\n",
            "[Epoch 36, Step  1320] loss: 0.524\n",
            "[Epoch 36, Step  1330] loss: 0.052\n",
            "[Epoch 36, Step  1340] loss: 0.247\n",
            "[Epoch 36, Step  1350] loss: 0.025\n",
            "[Epoch 36, Step  1360] loss: 0.268\n",
            "[Epoch 36, Step  1370] loss: 0.448\n",
            "[Epoch 36, Step  1380] loss: 0.105\n",
            "[Epoch 36, Step  1390] loss: 0.070\n",
            "[Epoch 36, Step  1400] loss: 0.275\n",
            "[Epoch 36, Step  1410] loss: 0.135\n",
            "[Epoch 36, Step  1420] loss: 0.376\n",
            "[Epoch 36, Step  1430] loss: 0.426\n",
            "[Epoch 36, Step  1440] loss: 0.218\n",
            "[Epoch 36, Step  1450] loss: 0.225\n",
            "[Epoch 36, Step  1460] loss: 0.613\n",
            "[Epoch 36, Step  1470] loss: 0.132\n",
            "[Epoch 36, Step  1480] loss: 0.178\n",
            "[Epoch 36, Step  1490] loss: 0.023\n",
            "[Epoch 36, Step  1500] loss: 0.425\n",
            "[Epoch 36, Step  1510] loss: 0.196\n",
            "[Epoch 36, Step  1520] loss: 0.066\n",
            "[Epoch 36, Step  1530] loss: 0.599\n",
            "[Epoch 36, Step  1540] loss: 0.074\n",
            "[Epoch 36, Step  1550] loss: 0.371\n",
            "[Epoch 36, Step  1560] loss: 0.290\n",
            "[Epoch 36, Step  1570] loss: 0.036\n",
            "[Epoch 36, Step  1580] loss: 0.308\n",
            "[Epoch 36, Step  1590] loss: 0.254\n",
            "[Epoch 36, Step  1600] loss: 0.100\n",
            "[Epoch 37, Step    10] loss: 0.616\n",
            "[Epoch 37, Step    20] loss: 0.175\n",
            "[Epoch 37, Step    30] loss: 0.257\n",
            "[Epoch 37, Step    40] loss: 0.396\n",
            "[Epoch 37, Step    50] loss: 0.213\n",
            "[Epoch 37, Step    60] loss: 0.478\n",
            "[Epoch 37, Step    70] loss: 0.170\n",
            "[Epoch 37, Step    80] loss: 0.275\n",
            "[Epoch 37, Step    90] loss: 0.098\n",
            "[Epoch 37, Step   100] loss: 0.037\n",
            "[Epoch 37, Step   110] loss: 0.189\n",
            "[Epoch 37, Step   120] loss: 0.213\n",
            "[Epoch 37, Step   130] loss: 0.613\n",
            "[Epoch 37, Step   140] loss: 0.148\n",
            "[Epoch 37, Step   150] loss: 0.167\n",
            "[Epoch 37, Step   160] loss: 0.229\n",
            "[Epoch 37, Step   170] loss: 0.291\n",
            "[Epoch 37, Step   180] loss: 0.414\n",
            "[Epoch 37, Step   190] loss: 0.374\n",
            "[Epoch 37, Step   200] loss: 0.121\n",
            "[Epoch 37, Step   210] loss: 0.284\n",
            "[Epoch 37, Step   220] loss: 0.230\n",
            "[Epoch 37, Step   230] loss: 0.344\n",
            "[Epoch 37, Step   240] loss: 0.361\n",
            "[Epoch 37, Step   250] loss: 0.164\n",
            "[Epoch 37, Step   260] loss: 0.233\n",
            "[Epoch 37, Step   270] loss: 0.139\n",
            "[Epoch 37, Step   280] loss: 0.608\n",
            "[Epoch 37, Step   290] loss: 0.094\n",
            "[Epoch 37, Step   300] loss: 0.283\n",
            "[Epoch 37, Step   310] loss: 0.281\n",
            "[Epoch 37, Step   320] loss: 0.153\n",
            "[Epoch 37, Step   330] loss: 0.222\n",
            "[Epoch 37, Step   340] loss: 0.214\n",
            "[Epoch 37, Step   350] loss: 0.096\n",
            "[Epoch 37, Step   360] loss: 0.119\n",
            "[Epoch 37, Step   370] loss: 0.192\n",
            "[Epoch 37, Step   380] loss: 0.265\n",
            "[Epoch 37, Step   390] loss: 0.234\n",
            "[Epoch 37, Step   400] loss: 0.343\n",
            "[Epoch 37, Step   410] loss: 0.147\n",
            "[Epoch 37, Step   420] loss: 0.248\n",
            "[Epoch 37, Step   430] loss: 0.179\n",
            "[Epoch 37, Step   440] loss: 0.462\n",
            "[Epoch 37, Step   450] loss: 0.320\n",
            "[Epoch 37, Step   460] loss: 0.227\n",
            "[Epoch 37, Step   470] loss: 0.083\n",
            "[Epoch 37, Step   480] loss: 0.174\n",
            "[Epoch 37, Step   490] loss: 0.155\n",
            "[Epoch 37, Step   500] loss: 0.782\n",
            "[Epoch 37, Step   510] loss: 0.288\n",
            "[Epoch 37, Step   520] loss: 0.269\n",
            "[Epoch 37, Step   530] loss: 0.447\n",
            "[Epoch 37, Step   540] loss: 0.096\n",
            "[Epoch 37, Step   550] loss: 0.389\n",
            "[Epoch 37, Step   560] loss: 0.613\n",
            "[Epoch 37, Step   570] loss: 0.142\n",
            "[Epoch 37, Step   580] loss: 0.102\n",
            "[Epoch 37, Step   590] loss: 0.414\n",
            "[Epoch 37, Step   600] loss: 0.261\n",
            "[Epoch 37, Step   610] loss: 0.111\n",
            "[Epoch 37, Step   620] loss: 0.186\n",
            "[Epoch 37, Step   630] loss: 0.197\n",
            "[Epoch 37, Step   640] loss: 0.318\n",
            "[Epoch 37, Step   650] loss: 0.362\n",
            "[Epoch 37, Step   660] loss: 0.363\n",
            "[Epoch 37, Step   670] loss: 0.258\n",
            "[Epoch 37, Step   680] loss: 0.107\n",
            "[Epoch 37, Step   690] loss: 0.083\n",
            "[Epoch 37, Step   700] loss: 0.257\n",
            "[Epoch 37, Step   710] loss: 0.115\n",
            "[Epoch 37, Step   720] loss: 0.048\n",
            "[Epoch 37, Step   730] loss: 0.534\n",
            "[Epoch 37, Step   740] loss: 0.067\n",
            "[Epoch 37, Step   750] loss: 0.198\n",
            "[Epoch 37, Step   760] loss: 0.488\n",
            "[Epoch 37, Step   770] loss: 0.414\n",
            "[Epoch 37, Step   780] loss: 0.227\n",
            "[Epoch 37, Step   790] loss: 0.151\n",
            "[Epoch 37, Step   800] loss: 0.139\n",
            "[Epoch 37, Step   810] loss: 0.145\n",
            "[Epoch 37, Step   820] loss: 0.184\n",
            "[Epoch 37, Step   830] loss: 0.097\n",
            "[Epoch 37, Step   840] loss: 0.273\n",
            "[Epoch 37, Step   850] loss: 0.307\n",
            "[Epoch 37, Step   860] loss: 0.023\n",
            "[Epoch 37, Step   870] loss: 0.077\n",
            "[Epoch 37, Step   880] loss: 0.149\n",
            "[Epoch 37, Step   890] loss: 0.128\n",
            "[Epoch 37, Step   900] loss: 0.135\n",
            "[Epoch 37, Step   910] loss: 0.100\n",
            "[Epoch 37, Step   920] loss: 0.221\n",
            "[Epoch 37, Step   930] loss: 0.419\n",
            "[Epoch 37, Step   940] loss: 0.291\n",
            "[Epoch 37, Step   950] loss: 0.266\n",
            "[Epoch 37, Step   960] loss: 0.181\n",
            "[Epoch 37, Step   970] loss: 0.499\n",
            "[Epoch 37, Step   980] loss: 0.073\n",
            "[Epoch 37, Step   990] loss: 0.115\n",
            "[Epoch 37, Step  1000] loss: 0.297\n",
            "[Epoch 37, Step  1010] loss: 0.121\n",
            "[Epoch 37, Step  1020] loss: 0.292\n",
            "[Epoch 37, Step  1030] loss: 0.313\n",
            "[Epoch 37, Step  1040] loss: 0.383\n",
            "[Epoch 37, Step  1050] loss: 0.195\n",
            "[Epoch 37, Step  1060] loss: 0.172\n",
            "[Epoch 37, Step  1070] loss: 0.284\n",
            "[Epoch 37, Step  1080] loss: 0.359\n",
            "[Epoch 37, Step  1090] loss: 0.190\n",
            "[Epoch 37, Step  1100] loss: 0.050\n",
            "[Epoch 37, Step  1110] loss: 0.176\n",
            "[Epoch 37, Step  1120] loss: 0.306\n",
            "[Epoch 37, Step  1130] loss: 0.145\n",
            "[Epoch 37, Step  1140] loss: 0.249\n",
            "[Epoch 37, Step  1150] loss: 0.125\n",
            "[Epoch 37, Step  1160] loss: 0.381\n",
            "[Epoch 37, Step  1170] loss: 0.235\n",
            "[Epoch 37, Step  1180] loss: 0.094\n",
            "[Epoch 37, Step  1190] loss: 0.093\n",
            "[Epoch 37, Step  1200] loss: 0.226\n",
            "[Epoch 37, Step  1210] loss: 0.424\n",
            "[Epoch 37, Step  1220] loss: 0.172\n",
            "[Epoch 37, Step  1230] loss: 0.072\n",
            "[Epoch 37, Step  1240] loss: 0.180\n",
            "[Epoch 37, Step  1250] loss: 0.114\n",
            "[Epoch 37, Step  1260] loss: 0.198\n",
            "[Epoch 37, Step  1270] loss: 0.054\n",
            "[Epoch 37, Step  1280] loss: 0.489\n",
            "[Epoch 37, Step  1290] loss: 0.239\n",
            "[Epoch 37, Step  1300] loss: 0.076\n",
            "[Epoch 37, Step  1310] loss: 0.228\n",
            "[Epoch 37, Step  1320] loss: 0.113\n",
            "[Epoch 37, Step  1330] loss: 0.287\n",
            "[Epoch 37, Step  1340] loss: 0.347\n",
            "[Epoch 37, Step  1350] loss: 0.255\n",
            "[Epoch 37, Step  1360] loss: 0.082\n",
            "[Epoch 37, Step  1370] loss: 0.061\n",
            "[Epoch 37, Step  1380] loss: 0.267\n",
            "[Epoch 37, Step  1390] loss: 0.515\n",
            "[Epoch 37, Step  1400] loss: 0.412\n",
            "[Epoch 37, Step  1410] loss: 0.373\n",
            "[Epoch 37, Step  1420] loss: 0.294\n",
            "[Epoch 37, Step  1430] loss: 0.150\n",
            "[Epoch 37, Step  1440] loss: 0.101\n",
            "[Epoch 37, Step  1450] loss: 0.251\n",
            "[Epoch 37, Step  1460] loss: 0.269\n",
            "[Epoch 37, Step  1470] loss: 0.292\n",
            "[Epoch 37, Step  1480] loss: 0.258\n",
            "[Epoch 37, Step  1490] loss: 0.868\n",
            "[Epoch 37, Step  1500] loss: 0.164\n",
            "[Epoch 37, Step  1510] loss: 0.118\n",
            "[Epoch 37, Step  1520] loss: 0.170\n",
            "[Epoch 37, Step  1530] loss: 0.509\n",
            "[Epoch 37, Step  1540] loss: 0.075\n",
            "[Epoch 37, Step  1550] loss: 0.429\n",
            "[Epoch 37, Step  1560] loss: 0.238\n",
            "[Epoch 37, Step  1570] loss: 0.265\n",
            "[Epoch 37, Step  1580] loss: 0.243\n",
            "[Epoch 37, Step  1590] loss: 0.153\n",
            "[Epoch 37, Step  1600] loss: 0.461\n",
            "[Epoch 38, Step    10] loss: 0.654\n",
            "[Epoch 38, Step    20] loss: 0.162\n",
            "[Epoch 38, Step    30] loss: 0.253\n",
            "[Epoch 38, Step    40] loss: 0.130\n",
            "[Epoch 38, Step    50] loss: 0.294\n",
            "[Epoch 38, Step    60] loss: 0.119\n",
            "[Epoch 38, Step    70] loss: 0.192\n",
            "[Epoch 38, Step    80] loss: 0.321\n",
            "[Epoch 38, Step    90] loss: 0.046\n",
            "[Epoch 38, Step   100] loss: 0.341\n",
            "[Epoch 38, Step   110] loss: 0.360\n",
            "[Epoch 38, Step   120] loss: 0.423\n",
            "[Epoch 38, Step   130] loss: 0.275\n",
            "[Epoch 38, Step   140] loss: 0.231\n",
            "[Epoch 38, Step   150] loss: 0.188\n",
            "[Epoch 38, Step   160] loss: 0.083\n",
            "[Epoch 38, Step   170] loss: 0.030\n",
            "[Epoch 38, Step   180] loss: 0.366\n",
            "[Epoch 38, Step   190] loss: 0.073\n",
            "[Epoch 38, Step   200] loss: 0.124\n",
            "[Epoch 38, Step   210] loss: 0.237\n",
            "[Epoch 38, Step   220] loss: 0.587\n",
            "[Epoch 38, Step   230] loss: 0.400\n",
            "[Epoch 38, Step   240] loss: 0.189\n",
            "[Epoch 38, Step   250] loss: 0.428\n",
            "[Epoch 38, Step   260] loss: 0.065\n",
            "[Epoch 38, Step   270] loss: 0.290\n",
            "[Epoch 38, Step   280] loss: 0.214\n",
            "[Epoch 38, Step   290] loss: 0.232\n",
            "[Epoch 38, Step   300] loss: 0.228\n",
            "[Epoch 38, Step   310] loss: 0.140\n",
            "[Epoch 38, Step   320] loss: 0.415\n",
            "[Epoch 38, Step   330] loss: 0.255\n",
            "[Epoch 38, Step   340] loss: 0.326\n",
            "[Epoch 38, Step   350] loss: 0.083\n",
            "[Epoch 38, Step   360] loss: 0.685\n",
            "[Epoch 38, Step   370] loss: 0.159\n",
            "[Epoch 38, Step   380] loss: 0.265\n",
            "[Epoch 38, Step   390] loss: 0.227\n",
            "[Epoch 38, Step   400] loss: 0.148\n",
            "[Epoch 38, Step   410] loss: 0.130\n",
            "[Epoch 38, Step   420] loss: 0.159\n",
            "[Epoch 38, Step   430] loss: 0.661\n",
            "[Epoch 38, Step   440] loss: 0.373\n",
            "[Epoch 38, Step   450] loss: 0.332\n",
            "[Epoch 38, Step   460] loss: 0.053\n",
            "[Epoch 38, Step   470] loss: 0.220\n",
            "[Epoch 38, Step   480] loss: 0.156\n",
            "[Epoch 38, Step   490] loss: 0.715\n",
            "[Epoch 38, Step   500] loss: 0.391\n",
            "[Epoch 38, Step   510] loss: 0.254\n",
            "[Epoch 38, Step   520] loss: 0.391\n",
            "[Epoch 38, Step   530] loss: 0.095\n",
            "[Epoch 38, Step   540] loss: 0.317\n",
            "[Epoch 38, Step   550] loss: 0.114\n",
            "[Epoch 38, Step   560] loss: 0.207\n",
            "[Epoch 38, Step   570] loss: 0.164\n",
            "[Epoch 38, Step   580] loss: 0.229\n",
            "[Epoch 38, Step   590] loss: 0.322\n",
            "[Epoch 38, Step   600] loss: 0.318\n",
            "[Epoch 38, Step   610] loss: 0.382\n",
            "[Epoch 38, Step   620] loss: 0.194\n",
            "[Epoch 38, Step   630] loss: 0.195\n",
            "[Epoch 38, Step   640] loss: 0.026\n",
            "[Epoch 38, Step   650] loss: 0.226\n",
            "[Epoch 38, Step   660] loss: 0.096\n",
            "[Epoch 38, Step   670] loss: 0.136\n",
            "[Epoch 38, Step   680] loss: 0.270\n",
            "[Epoch 38, Step   690] loss: 0.185\n",
            "[Epoch 38, Step   700] loss: 0.045\n",
            "[Epoch 38, Step   710] loss: 0.334\n",
            "[Epoch 38, Step   720] loss: 0.140\n",
            "[Epoch 38, Step   730] loss: 0.364\n",
            "[Epoch 38, Step   740] loss: 0.194\n",
            "[Epoch 38, Step   750] loss: 0.544\n",
            "[Epoch 38, Step   760] loss: 0.100\n",
            "[Epoch 38, Step   770] loss: 0.306\n",
            "[Epoch 38, Step   780] loss: 0.365\n",
            "[Epoch 38, Step   790] loss: 0.228\n",
            "[Epoch 38, Step   800] loss: 0.281\n",
            "[Epoch 38, Step   810] loss: 0.165\n",
            "[Epoch 38, Step   820] loss: 0.112\n",
            "[Epoch 38, Step   830] loss: 0.132\n",
            "[Epoch 38, Step   840] loss: 0.112\n",
            "[Epoch 38, Step   850] loss: 0.089\n",
            "[Epoch 38, Step   860] loss: 0.254\n",
            "[Epoch 38, Step   870] loss: 0.648\n",
            "[Epoch 38, Step   880] loss: 0.091\n",
            "[Epoch 38, Step   890] loss: 0.261\n",
            "[Epoch 38, Step   900] loss: 0.083\n",
            "[Epoch 38, Step   910] loss: 0.242\n",
            "[Epoch 38, Step   920] loss: 0.140\n",
            "[Epoch 38, Step   930] loss: 0.080\n",
            "[Epoch 38, Step   940] loss: 0.539\n",
            "[Epoch 38, Step   950] loss: 0.264\n",
            "[Epoch 38, Step   960] loss: 0.121\n",
            "[Epoch 38, Step   970] loss: 0.116\n",
            "[Epoch 38, Step   980] loss: 0.377\n",
            "[Epoch 38, Step   990] loss: 0.314\n",
            "[Epoch 38, Step  1000] loss: 0.069\n",
            "[Epoch 38, Step  1010] loss: 0.345\n",
            "[Epoch 38, Step  1020] loss: 0.214\n",
            "[Epoch 38, Step  1030] loss: 0.352\n",
            "[Epoch 38, Step  1040] loss: 0.262\n",
            "[Epoch 38, Step  1050] loss: 0.190\n",
            "[Epoch 38, Step  1060] loss: 0.369\n",
            "[Epoch 38, Step  1070] loss: 0.107\n",
            "[Epoch 38, Step  1080] loss: 0.291\n",
            "[Epoch 38, Step  1090] loss: 0.080\n",
            "[Epoch 38, Step  1100] loss: 0.048\n",
            "[Epoch 38, Step  1110] loss: 0.438\n",
            "[Epoch 38, Step  1120] loss: 0.360\n",
            "[Epoch 38, Step  1130] loss: 0.207\n",
            "[Epoch 38, Step  1140] loss: 0.302\n",
            "[Epoch 38, Step  1150] loss: 0.186\n",
            "[Epoch 38, Step  1160] loss: 0.228\n",
            "[Epoch 38, Step  1170] loss: 0.393\n",
            "[Epoch 38, Step  1180] loss: 0.201\n",
            "[Epoch 38, Step  1190] loss: 0.150\n",
            "[Epoch 38, Step  1200] loss: 0.127\n",
            "[Epoch 38, Step  1210] loss: 0.208\n",
            "[Epoch 38, Step  1220] loss: 0.511\n",
            "[Epoch 38, Step  1230] loss: 0.185\n",
            "[Epoch 38, Step  1240] loss: 0.236\n",
            "[Epoch 38, Step  1250] loss: 0.237\n",
            "[Epoch 38, Step  1260] loss: 0.272\n",
            "[Epoch 38, Step  1270] loss: 0.251\n",
            "[Epoch 38, Step  1280] loss: 0.229\n",
            "[Epoch 38, Step  1290] loss: 0.301\n",
            "[Epoch 38, Step  1300] loss: 0.385\n",
            "[Epoch 38, Step  1310] loss: 0.226\n",
            "[Epoch 38, Step  1320] loss: 0.057\n",
            "[Epoch 38, Step  1330] loss: 0.295\n",
            "[Epoch 38, Step  1340] loss: 0.105\n",
            "[Epoch 38, Step  1350] loss: 0.150\n",
            "[Epoch 38, Step  1360] loss: 0.046\n",
            "[Epoch 38, Step  1370] loss: 0.606\n",
            "[Epoch 38, Step  1380] loss: 0.313\n",
            "[Epoch 38, Step  1390] loss: 0.316\n",
            "[Epoch 38, Step  1400] loss: 0.385\n",
            "[Epoch 38, Step  1410] loss: 0.079\n",
            "[Epoch 38, Step  1420] loss: 0.141\n",
            "[Epoch 38, Step  1430] loss: 0.101\n",
            "[Epoch 38, Step  1440] loss: 0.073\n",
            "[Epoch 38, Step  1450] loss: 0.275\n",
            "[Epoch 38, Step  1460] loss: 0.217\n",
            "[Epoch 38, Step  1470] loss: 0.183\n",
            "[Epoch 38, Step  1480] loss: 0.113\n",
            "[Epoch 38, Step  1490] loss: 0.179\n",
            "[Epoch 38, Step  1500] loss: 0.341\n",
            "[Epoch 38, Step  1510] loss: 0.257\n",
            "[Epoch 38, Step  1520] loss: 0.186\n",
            "[Epoch 38, Step  1530] loss: 0.322\n",
            "[Epoch 38, Step  1540] loss: 0.217\n",
            "[Epoch 38, Step  1550] loss: 0.262\n",
            "[Epoch 38, Step  1560] loss: 0.582\n",
            "[Epoch 38, Step  1570] loss: 0.601\n",
            "[Epoch 38, Step  1580] loss: 0.369\n",
            "[Epoch 38, Step  1590] loss: 0.128\n",
            "[Epoch 38, Step  1600] loss: 0.065\n",
            "[Epoch 39, Step    10] loss: 0.160\n",
            "[Epoch 39, Step    20] loss: 0.145\n",
            "[Epoch 39, Step    30] loss: 0.394\n",
            "[Epoch 39, Step    40] loss: 0.098\n",
            "[Epoch 39, Step    50] loss: 0.119\n",
            "[Epoch 39, Step    60] loss: 0.487\n",
            "[Epoch 39, Step    70] loss: 0.128\n",
            "[Epoch 39, Step    80] loss: 0.143\n",
            "[Epoch 39, Step    90] loss: 0.342\n",
            "[Epoch 39, Step   100] loss: 0.165\n",
            "[Epoch 39, Step   110] loss: 0.157\n",
            "[Epoch 39, Step   120] loss: 0.031\n",
            "[Epoch 39, Step   130] loss: 0.266\n",
            "[Epoch 39, Step   140] loss: 0.072\n",
            "[Epoch 39, Step   150] loss: 0.134\n",
            "[Epoch 39, Step   160] loss: 0.193\n",
            "[Epoch 39, Step   170] loss: 0.191\n",
            "[Epoch 39, Step   180] loss: 0.136\n",
            "[Epoch 39, Step   190] loss: 0.139\n",
            "[Epoch 39, Step   200] loss: 0.287\n",
            "[Epoch 39, Step   210] loss: 0.111\n",
            "[Epoch 39, Step   220] loss: 0.074\n",
            "[Epoch 39, Step   230] loss: 0.060\n",
            "[Epoch 39, Step   240] loss: 0.635\n",
            "[Epoch 39, Step   250] loss: 0.171\n",
            "[Epoch 39, Step   260] loss: 0.270\n",
            "[Epoch 39, Step   270] loss: 0.180\n",
            "[Epoch 39, Step   280] loss: 0.219\n",
            "[Epoch 39, Step   290] loss: 0.166\n",
            "[Epoch 39, Step   300] loss: 0.343\n",
            "[Epoch 39, Step   310] loss: 0.190\n",
            "[Epoch 39, Step   320] loss: 0.078\n",
            "[Epoch 39, Step   330] loss: 0.169\n",
            "[Epoch 39, Step   340] loss: 0.123\n",
            "[Epoch 39, Step   350] loss: 0.174\n",
            "[Epoch 39, Step   360] loss: 0.278\n",
            "[Epoch 39, Step   370] loss: 0.250\n",
            "[Epoch 39, Step   380] loss: 0.546\n",
            "[Epoch 39, Step   390] loss: 0.119\n",
            "[Epoch 39, Step   400] loss: 0.375\n",
            "[Epoch 39, Step   410] loss: 0.302\n",
            "[Epoch 39, Step   420] loss: 0.581\n",
            "[Epoch 39, Step   430] loss: 0.182\n",
            "[Epoch 39, Step   440] loss: 0.164\n",
            "[Epoch 39, Step   450] loss: 0.094\n",
            "[Epoch 39, Step   460] loss: 0.048\n",
            "[Epoch 39, Step   470] loss: 0.324\n",
            "[Epoch 39, Step   480] loss: 0.056\n",
            "[Epoch 39, Step   490] loss: 0.244\n",
            "[Epoch 39, Step   500] loss: 0.297\n",
            "[Epoch 39, Step   510] loss: 0.393\n",
            "[Epoch 39, Step   520] loss: 0.145\n",
            "[Epoch 39, Step   530] loss: 0.146\n",
            "[Epoch 39, Step   540] loss: 0.341\n",
            "[Epoch 39, Step   550] loss: 0.132\n",
            "[Epoch 39, Step   560] loss: 0.337\n",
            "[Epoch 39, Step   570] loss: 0.507\n",
            "[Epoch 39, Step   580] loss: 0.628\n",
            "[Epoch 39, Step   590] loss: 0.159\n",
            "[Epoch 39, Step   600] loss: 0.220\n",
            "[Epoch 39, Step   610] loss: 0.111\n",
            "[Epoch 39, Step   620] loss: 0.222\n",
            "[Epoch 39, Step   630] loss: 0.293\n",
            "[Epoch 39, Step   640] loss: 0.208\n",
            "[Epoch 39, Step   650] loss: 0.023\n",
            "[Epoch 39, Step   660] loss: 0.261\n",
            "[Epoch 39, Step   670] loss: 0.132\n",
            "[Epoch 39, Step   680] loss: 0.391\n",
            "[Epoch 39, Step   690] loss: 0.217\n",
            "[Epoch 39, Step   700] loss: 0.654\n",
            "[Epoch 39, Step   710] loss: 0.125\n",
            "[Epoch 39, Step   720] loss: 0.205\n",
            "[Epoch 39, Step   730] loss: 0.153\n",
            "[Epoch 39, Step   740] loss: 0.245\n",
            "[Epoch 39, Step   750] loss: 0.158\n",
            "[Epoch 39, Step   760] loss: 0.152\n",
            "[Epoch 39, Step   770] loss: 0.087\n",
            "[Epoch 39, Step   780] loss: 0.235\n",
            "[Epoch 39, Step   790] loss: 0.186\n",
            "[Epoch 39, Step   800] loss: 0.415\n",
            "[Epoch 39, Step   810] loss: 0.412\n",
            "[Epoch 39, Step   820] loss: 0.298\n",
            "[Epoch 39, Step   830] loss: 0.139\n",
            "[Epoch 39, Step   840] loss: 0.150\n",
            "[Epoch 39, Step   850] loss: 0.385\n",
            "[Epoch 39, Step   860] loss: 0.194\n",
            "[Epoch 39, Step   870] loss: 0.588\n",
            "[Epoch 39, Step   880] loss: 0.241\n",
            "[Epoch 39, Step   890] loss: 0.090\n",
            "[Epoch 39, Step   900] loss: 0.113\n",
            "[Epoch 39, Step   910] loss: 0.151\n",
            "[Epoch 39, Step   920] loss: 0.075\n",
            "[Epoch 39, Step   930] loss: 0.469\n",
            "[Epoch 39, Step   940] loss: 0.170\n",
            "[Epoch 39, Step   950] loss: 0.195\n",
            "[Epoch 39, Step   960] loss: 0.142\n",
            "[Epoch 39, Step   970] loss: 0.144\n",
            "[Epoch 39, Step   980] loss: 0.109\n",
            "[Epoch 39, Step   990] loss: 0.414\n",
            "[Epoch 39, Step  1000] loss: 0.437\n",
            "[Epoch 39, Step  1010] loss: 0.035\n",
            "[Epoch 39, Step  1020] loss: 0.201\n",
            "[Epoch 39, Step  1030] loss: 0.159\n",
            "[Epoch 39, Step  1040] loss: 0.319\n",
            "[Epoch 39, Step  1050] loss: 0.224\n",
            "[Epoch 39, Step  1060] loss: 0.460\n",
            "[Epoch 39, Step  1070] loss: 0.602\n",
            "[Epoch 39, Step  1080] loss: 0.280\n",
            "[Epoch 39, Step  1090] loss: 0.160\n",
            "[Epoch 39, Step  1100] loss: 0.170\n",
            "[Epoch 39, Step  1110] loss: 0.190\n",
            "[Epoch 39, Step  1120] loss: 0.091\n",
            "[Epoch 39, Step  1130] loss: 0.843\n",
            "[Epoch 39, Step  1140] loss: 0.098\n",
            "[Epoch 39, Step  1150] loss: 0.204\n",
            "[Epoch 39, Step  1160] loss: 0.539\n",
            "[Epoch 39, Step  1170] loss: 0.127\n",
            "[Epoch 39, Step  1180] loss: 0.208\n",
            "[Epoch 39, Step  1190] loss: 0.181\n",
            "[Epoch 39, Step  1200] loss: 0.319\n",
            "[Epoch 39, Step  1210] loss: 0.237\n",
            "[Epoch 39, Step  1220] loss: 0.243\n",
            "[Epoch 39, Step  1230] loss: 0.188\n",
            "[Epoch 39, Step  1240] loss: 0.149\n",
            "[Epoch 39, Step  1250] loss: 0.323\n",
            "[Epoch 39, Step  1260] loss: 0.069\n",
            "[Epoch 39, Step  1270] loss: 0.303\n",
            "[Epoch 39, Step  1280] loss: 0.403\n",
            "[Epoch 39, Step  1290] loss: 0.091\n",
            "[Epoch 39, Step  1300] loss: 0.178\n",
            "[Epoch 39, Step  1310] loss: 0.778\n",
            "[Epoch 39, Step  1320] loss: 0.497\n",
            "[Epoch 39, Step  1330] loss: 0.466\n",
            "[Epoch 39, Step  1340] loss: 0.223\n",
            "[Epoch 39, Step  1350] loss: 0.219\n",
            "[Epoch 39, Step  1360] loss: 0.215\n",
            "[Epoch 39, Step  1370] loss: 0.494\n",
            "[Epoch 39, Step  1380] loss: 0.140\n",
            "[Epoch 39, Step  1390] loss: 0.327\n",
            "[Epoch 39, Step  1400] loss: 0.078\n",
            "[Epoch 39, Step  1410] loss: 0.177\n",
            "[Epoch 39, Step  1420] loss: 0.326\n",
            "[Epoch 39, Step  1430] loss: 0.194\n",
            "[Epoch 39, Step  1440] loss: 0.066\n",
            "[Epoch 39, Step  1450] loss: 0.172\n",
            "[Epoch 39, Step  1460] loss: 0.346\n",
            "[Epoch 39, Step  1470] loss: 0.177\n",
            "[Epoch 39, Step  1480] loss: 0.118\n",
            "[Epoch 39, Step  1490] loss: 0.547\n",
            "[Epoch 39, Step  1500] loss: 0.153\n",
            "[Epoch 39, Step  1510] loss: 0.139\n",
            "[Epoch 39, Step  1520] loss: 0.391\n",
            "[Epoch 39, Step  1530] loss: 0.198\n",
            "[Epoch 39, Step  1540] loss: 0.234\n",
            "[Epoch 39, Step  1550] loss: 0.135\n",
            "[Epoch 39, Step  1560] loss: 0.391\n",
            "[Epoch 39, Step  1570] loss: 0.472\n",
            "[Epoch 39, Step  1580] loss: 0.215\n",
            "[Epoch 39, Step  1590] loss: 0.216\n",
            "[Epoch 39, Step  1600] loss: 0.096\n",
            "[Epoch 40, Step    10] loss: 0.159\n",
            "[Epoch 40, Step    20] loss: 0.068\n",
            "[Epoch 40, Step    30] loss: 0.043\n",
            "[Epoch 40, Step    40] loss: 0.299\n",
            "[Epoch 40, Step    50] loss: 0.082\n",
            "[Epoch 40, Step    60] loss: 0.371\n",
            "[Epoch 40, Step    70] loss: 0.156\n",
            "[Epoch 40, Step    80] loss: 0.283\n",
            "[Epoch 40, Step    90] loss: 0.174\n",
            "[Epoch 40, Step   100] loss: 0.407\n",
            "[Epoch 40, Step   110] loss: 0.168\n",
            "[Epoch 40, Step   120] loss: 0.199\n",
            "[Epoch 40, Step   130] loss: 0.164\n",
            "[Epoch 40, Step   140] loss: 0.341\n",
            "[Epoch 40, Step   150] loss: 0.559\n",
            "[Epoch 40, Step   160] loss: 0.209\n",
            "[Epoch 40, Step   170] loss: 0.057\n",
            "[Epoch 40, Step   180] loss: 0.402\n",
            "[Epoch 40, Step   190] loss: 0.232\n",
            "[Epoch 40, Step   200] loss: 0.683\n",
            "[Epoch 40, Step   210] loss: 0.116\n",
            "[Epoch 40, Step   220] loss: 0.512\n",
            "[Epoch 40, Step   230] loss: 0.506\n",
            "[Epoch 40, Step   240] loss: 0.066\n",
            "[Epoch 40, Step   250] loss: 0.160\n",
            "[Epoch 40, Step   260] loss: 0.185\n",
            "[Epoch 40, Step   270] loss: 0.207\n",
            "[Epoch 40, Step   280] loss: 0.166\n",
            "[Epoch 40, Step   290] loss: 0.161\n",
            "[Epoch 40, Step   300] loss: 0.230\n",
            "[Epoch 40, Step   310] loss: 0.314\n",
            "[Epoch 40, Step   320] loss: 0.052\n",
            "[Epoch 40, Step   330] loss: 0.205\n",
            "[Epoch 40, Step   340] loss: 0.529\n",
            "[Epoch 40, Step   350] loss: 0.122\n",
            "[Epoch 40, Step   360] loss: 0.546\n",
            "[Epoch 40, Step   370] loss: 0.388\n",
            "[Epoch 40, Step   380] loss: 0.225\n",
            "[Epoch 40, Step   390] loss: 0.171\n",
            "[Epoch 40, Step   400] loss: 0.254\n",
            "[Epoch 40, Step   410] loss: 0.071\n",
            "[Epoch 40, Step   420] loss: 0.215\n",
            "[Epoch 40, Step   430] loss: 0.169\n",
            "[Epoch 40, Step   440] loss: 0.216\n",
            "[Epoch 40, Step   450] loss: 0.176\n",
            "[Epoch 40, Step   460] loss: 0.196\n",
            "[Epoch 40, Step   470] loss: 0.098\n",
            "[Epoch 40, Step   480] loss: 0.267\n",
            "[Epoch 40, Step   490] loss: 0.129\n",
            "[Epoch 40, Step   500] loss: 0.247\n",
            "[Epoch 40, Step   510] loss: 0.682\n",
            "[Epoch 40, Step   520] loss: 0.101\n",
            "[Epoch 40, Step   530] loss: 0.160\n",
            "[Epoch 40, Step   540] loss: 0.174\n",
            "[Epoch 40, Step   550] loss: 0.235\n",
            "[Epoch 40, Step   560] loss: 0.279\n",
            "[Epoch 40, Step   570] loss: 0.333\n",
            "[Epoch 40, Step   580] loss: 0.080\n",
            "[Epoch 40, Step   590] loss: 0.147\n",
            "[Epoch 40, Step   600] loss: 0.238\n",
            "[Epoch 40, Step   610] loss: 0.287\n",
            "[Epoch 40, Step   620] loss: 0.035\n",
            "[Epoch 40, Step   630] loss: 0.037\n",
            "[Epoch 40, Step   640] loss: 0.281\n",
            "[Epoch 40, Step   650] loss: 0.289\n",
            "[Epoch 40, Step   660] loss: 0.247\n",
            "[Epoch 40, Step   670] loss: 0.132\n",
            "[Epoch 40, Step   680] loss: 0.327\n",
            "[Epoch 40, Step   690] loss: 0.186\n",
            "[Epoch 40, Step   700] loss: 0.054\n",
            "[Epoch 40, Step   710] loss: 0.229\n",
            "[Epoch 40, Step   720] loss: 0.246\n",
            "[Epoch 40, Step   730] loss: 0.376\n",
            "[Epoch 40, Step   740] loss: 0.163\n",
            "[Epoch 40, Step   750] loss: 0.052\n",
            "[Epoch 40, Step   760] loss: 0.176\n",
            "[Epoch 40, Step   770] loss: 0.347\n",
            "[Epoch 40, Step   780] loss: 0.255\n",
            "[Epoch 40, Step   790] loss: 0.131\n",
            "[Epoch 40, Step   800] loss: 0.252\n",
            "[Epoch 40, Step   810] loss: 0.029\n",
            "[Epoch 40, Step   820] loss: 0.419\n",
            "[Epoch 40, Step   830] loss: 0.186\n",
            "[Epoch 40, Step   840] loss: 0.370\n",
            "[Epoch 40, Step   850] loss: 0.089\n",
            "[Epoch 40, Step   860] loss: 0.044\n",
            "[Epoch 40, Step   870] loss: 0.184\n",
            "[Epoch 40, Step   880] loss: 0.158\n",
            "[Epoch 40, Step   890] loss: 0.233\n",
            "[Epoch 40, Step   900] loss: 0.523\n",
            "[Epoch 40, Step   910] loss: 0.577\n",
            "[Epoch 40, Step   920] loss: 0.356\n",
            "[Epoch 40, Step   930] loss: 0.126\n",
            "[Epoch 40, Step   940] loss: 0.151\n",
            "[Epoch 40, Step   950] loss: 0.493\n",
            "[Epoch 40, Step   960] loss: 0.413\n",
            "[Epoch 40, Step   970] loss: 0.390\n",
            "[Epoch 40, Step   980] loss: 0.170\n",
            "[Epoch 40, Step   990] loss: 0.282\n",
            "[Epoch 40, Step  1000] loss: 0.113\n",
            "[Epoch 40, Step  1010] loss: 0.272\n",
            "[Epoch 40, Step  1020] loss: 0.197\n",
            "[Epoch 40, Step  1030] loss: 0.507\n",
            "[Epoch 40, Step  1040] loss: 0.105\n",
            "[Epoch 40, Step  1050] loss: 0.323\n",
            "[Epoch 40, Step  1060] loss: 0.339\n",
            "[Epoch 40, Step  1070] loss: 0.319\n",
            "[Epoch 40, Step  1080] loss: 0.290\n",
            "[Epoch 40, Step  1090] loss: 0.317\n",
            "[Epoch 40, Step  1100] loss: 0.160\n",
            "[Epoch 40, Step  1110] loss: 0.026\n",
            "[Epoch 40, Step  1120] loss: 0.288\n",
            "[Epoch 40, Step  1130] loss: 0.196\n",
            "[Epoch 40, Step  1140] loss: 0.098\n",
            "[Epoch 40, Step  1150] loss: 0.098\n",
            "[Epoch 40, Step  1160] loss: 0.213\n",
            "[Epoch 40, Step  1170] loss: 0.321\n",
            "[Epoch 40, Step  1180] loss: 0.322\n",
            "[Epoch 40, Step  1190] loss: 0.105\n",
            "[Epoch 40, Step  1200] loss: 0.241\n",
            "[Epoch 40, Step  1210] loss: 0.067\n",
            "[Epoch 40, Step  1220] loss: 0.111\n",
            "[Epoch 40, Step  1230] loss: 0.319\n",
            "[Epoch 40, Step  1240] loss: 0.141\n",
            "[Epoch 40, Step  1250] loss: 0.225\n",
            "[Epoch 40, Step  1260] loss: 0.088\n",
            "[Epoch 40, Step  1270] loss: 0.119\n",
            "[Epoch 40, Step  1280] loss: 0.292\n",
            "[Epoch 40, Step  1290] loss: 0.107\n",
            "[Epoch 40, Step  1300] loss: 0.412\n",
            "[Epoch 40, Step  1310] loss: 0.285\n",
            "[Epoch 40, Step  1320] loss: 0.108\n",
            "[Epoch 40, Step  1330] loss: 0.267\n",
            "[Epoch 40, Step  1340] loss: 0.037\n",
            "[Epoch 40, Step  1350] loss: 0.096\n",
            "[Epoch 40, Step  1360] loss: 0.281\n",
            "[Epoch 40, Step  1370] loss: 0.188\n",
            "[Epoch 40, Step  1380] loss: 0.350\n",
            "[Epoch 40, Step  1390] loss: 0.125\n",
            "[Epoch 40, Step  1400] loss: 0.139\n",
            "[Epoch 40, Step  1410] loss: 0.264\n",
            "[Epoch 40, Step  1420] loss: 0.324\n",
            "[Epoch 40, Step  1430] loss: 0.464\n",
            "[Epoch 40, Step  1440] loss: 0.100\n",
            "[Epoch 40, Step  1450] loss: 0.344\n",
            "[Epoch 40, Step  1460] loss: 0.096\n",
            "[Epoch 40, Step  1470] loss: 0.181\n",
            "[Epoch 40, Step  1480] loss: 0.363\n",
            "[Epoch 40, Step  1490] loss: 0.530\n",
            "[Epoch 40, Step  1500] loss: 0.699\n",
            "[Epoch 40, Step  1510] loss: 0.156\n",
            "[Epoch 40, Step  1520] loss: 0.290\n",
            "[Epoch 40, Step  1530] loss: 0.298\n",
            "[Epoch 40, Step  1540] loss: 0.037\n",
            "[Epoch 40, Step  1550] loss: 0.224\n",
            "[Epoch 40, Step  1560] loss: 0.121\n",
            "[Epoch 40, Step  1570] loss: 0.328\n",
            "[Epoch 40, Step  1580] loss: 0.597\n",
            "[Epoch 40, Step  1590] loss: 0.222\n",
            "[Epoch 40, Step  1600] loss: 0.273\n",
            "[Epoch 41, Step    10] loss: 0.129\n",
            "[Epoch 41, Step    20] loss: 0.249\n",
            "[Epoch 41, Step    30] loss: 0.082\n",
            "[Epoch 41, Step    40] loss: 0.206\n",
            "[Epoch 41, Step    50] loss: 0.168\n",
            "[Epoch 41, Step    60] loss: 0.265\n",
            "[Epoch 41, Step    70] loss: 0.189\n",
            "[Epoch 41, Step    80] loss: 0.024\n",
            "[Epoch 41, Step    90] loss: 0.200\n",
            "[Epoch 41, Step   100] loss: 0.315\n",
            "[Epoch 41, Step   110] loss: 0.225\n",
            "[Epoch 41, Step   120] loss: 0.820\n",
            "[Epoch 41, Step   130] loss: 0.148\n",
            "[Epoch 41, Step   140] loss: 0.238\n",
            "[Epoch 41, Step   150] loss: 0.302\n",
            "[Epoch 41, Step   160] loss: 0.121\n",
            "[Epoch 41, Step   170] loss: 0.092\n",
            "[Epoch 41, Step   180] loss: 0.120\n",
            "[Epoch 41, Step   190] loss: 0.175\n",
            "[Epoch 41, Step   200] loss: 0.145\n",
            "[Epoch 41, Step   210] loss: 0.397\n",
            "[Epoch 41, Step   220] loss: 0.120\n",
            "[Epoch 41, Step   230] loss: 0.298\n",
            "[Epoch 41, Step   240] loss: 0.100\n",
            "[Epoch 41, Step   250] loss: 0.320\n",
            "[Epoch 41, Step   260] loss: 0.208\n",
            "[Epoch 41, Step   270] loss: 0.431\n",
            "[Epoch 41, Step   280] loss: 0.223\n",
            "[Epoch 41, Step   290] loss: 0.095\n",
            "[Epoch 41, Step   300] loss: 0.192\n",
            "[Epoch 41, Step   310] loss: 0.225\n",
            "[Epoch 41, Step   320] loss: 0.144\n",
            "[Epoch 41, Step   330] loss: 0.419\n",
            "[Epoch 41, Step   340] loss: 0.124\n",
            "[Epoch 41, Step   350] loss: 0.681\n",
            "[Epoch 41, Step   360] loss: 0.700\n",
            "[Epoch 41, Step   370] loss: 0.307\n",
            "[Epoch 41, Step   380] loss: 0.232\n",
            "[Epoch 41, Step   390] loss: 0.272\n",
            "[Epoch 41, Step   400] loss: 0.157\n",
            "[Epoch 41, Step   410] loss: 0.067\n",
            "[Epoch 41, Step   420] loss: 0.175\n",
            "[Epoch 41, Step   430] loss: 0.435\n",
            "[Epoch 41, Step   440] loss: 0.252\n",
            "[Epoch 41, Step   450] loss: 0.208\n",
            "[Epoch 41, Step   460] loss: 0.053\n",
            "[Epoch 41, Step   470] loss: 0.128\n",
            "[Epoch 41, Step   480] loss: 0.115\n",
            "[Epoch 41, Step   490] loss: 0.139\n",
            "[Epoch 41, Step   500] loss: 0.282\n",
            "[Epoch 41, Step   510] loss: 0.160\n",
            "[Epoch 41, Step   520] loss: 0.313\n",
            "[Epoch 41, Step   530] loss: 0.080\n",
            "[Epoch 41, Step   540] loss: 0.461\n",
            "[Epoch 41, Step   550] loss: 0.204\n",
            "[Epoch 41, Step   560] loss: 0.147\n",
            "[Epoch 41, Step   570] loss: 0.120\n",
            "[Epoch 41, Step   580] loss: 0.046\n",
            "[Epoch 41, Step   590] loss: 0.292\n",
            "[Epoch 41, Step   600] loss: 0.085\n",
            "[Epoch 41, Step   610] loss: 0.099\n",
            "[Epoch 41, Step   620] loss: 0.112\n",
            "[Epoch 41, Step   630] loss: 0.180\n",
            "[Epoch 41, Step   640] loss: 0.208\n",
            "[Epoch 41, Step   650] loss: 0.392\n",
            "[Epoch 41, Step   660] loss: 0.149\n",
            "[Epoch 41, Step   670] loss: 0.310\n",
            "[Epoch 41, Step   680] loss: 0.103\n",
            "[Epoch 41, Step   690] loss: 0.071\n",
            "[Epoch 41, Step   700] loss: 0.693\n",
            "[Epoch 41, Step   710] loss: 0.450\n",
            "[Epoch 41, Step   720] loss: 0.492\n",
            "[Epoch 41, Step   730] loss: 0.216\n",
            "[Epoch 41, Step   740] loss: 0.161\n",
            "[Epoch 41, Step   750] loss: 0.103\n",
            "[Epoch 41, Step   760] loss: 0.145\n",
            "[Epoch 41, Step   770] loss: 0.214\n",
            "[Epoch 41, Step   780] loss: 0.183\n",
            "[Epoch 41, Step   790] loss: 0.108\n",
            "[Epoch 41, Step   800] loss: 0.264\n",
            "[Epoch 41, Step   810] loss: 0.250\n",
            "[Epoch 41, Step   820] loss: 0.137\n",
            "[Epoch 41, Step   830] loss: 0.251\n",
            "[Epoch 41, Step   840] loss: 0.165\n",
            "[Epoch 41, Step   850] loss: 0.314\n",
            "[Epoch 41, Step   860] loss: 0.101\n",
            "[Epoch 41, Step   870] loss: 0.409\n",
            "[Epoch 41, Step   880] loss: 0.211\n",
            "[Epoch 41, Step   890] loss: 0.265\n",
            "[Epoch 41, Step   900] loss: 0.182\n",
            "[Epoch 41, Step   910] loss: 0.329\n",
            "[Epoch 41, Step   920] loss: 0.115\n",
            "[Epoch 41, Step   930] loss: 0.107\n",
            "[Epoch 41, Step   940] loss: 0.789\n",
            "[Epoch 41, Step   950] loss: 0.067\n",
            "[Epoch 41, Step   960] loss: 0.173\n",
            "[Epoch 41, Step   970] loss: 0.298\n",
            "[Epoch 41, Step   980] loss: 0.900\n",
            "[Epoch 41, Step   990] loss: 0.191\n",
            "[Epoch 41, Step  1000] loss: 0.088\n",
            "[Epoch 41, Step  1010] loss: 0.212\n",
            "[Epoch 41, Step  1020] loss: 0.097\n",
            "[Epoch 41, Step  1030] loss: 0.179\n",
            "[Epoch 41, Step  1040] loss: 0.281\n",
            "[Epoch 41, Step  1050] loss: 0.201\n",
            "[Epoch 41, Step  1060] loss: 0.162\n",
            "[Epoch 41, Step  1070] loss: 0.203\n",
            "[Epoch 41, Step  1080] loss: 0.255\n",
            "[Epoch 41, Step  1090] loss: 0.123\n",
            "[Epoch 41, Step  1100] loss: 0.107\n",
            "[Epoch 41, Step  1110] loss: 0.676\n",
            "[Epoch 41, Step  1120] loss: 0.226\n",
            "[Epoch 41, Step  1130] loss: 0.179\n",
            "[Epoch 41, Step  1140] loss: 0.085\n",
            "[Epoch 41, Step  1150] loss: 0.403\n",
            "[Epoch 41, Step  1160] loss: 0.313\n",
            "[Epoch 41, Step  1170] loss: 0.141\n",
            "[Epoch 41, Step  1180] loss: 0.097\n",
            "[Epoch 41, Step  1190] loss: 0.735\n",
            "[Epoch 41, Step  1200] loss: 0.355\n",
            "[Epoch 41, Step  1210] loss: 0.215\n",
            "[Epoch 41, Step  1220] loss: 0.194\n",
            "[Epoch 41, Step  1230] loss: 0.037\n",
            "[Epoch 41, Step  1240] loss: 0.128\n",
            "[Epoch 41, Step  1250] loss: 0.255\n",
            "[Epoch 41, Step  1260] loss: 0.455\n",
            "[Epoch 41, Step  1270] loss: 0.258\n",
            "[Epoch 41, Step  1280] loss: 0.045\n",
            "[Epoch 41, Step  1290] loss: 0.128\n",
            "[Epoch 41, Step  1300] loss: 0.094\n",
            "[Epoch 41, Step  1310] loss: 0.137\n",
            "[Epoch 41, Step  1320] loss: 0.301\n",
            "[Epoch 41, Step  1330] loss: 0.207\n",
            "[Epoch 41, Step  1340] loss: 0.409\n",
            "[Epoch 41, Step  1350] loss: 0.139\n",
            "[Epoch 41, Step  1360] loss: 0.456\n",
            "[Epoch 41, Step  1370] loss: 0.213\n",
            "[Epoch 41, Step  1380] loss: 0.292\n",
            "[Epoch 41, Step  1390] loss: 0.229\n",
            "[Epoch 41, Step  1400] loss: 0.348\n",
            "[Epoch 41, Step  1410] loss: 0.094\n",
            "[Epoch 41, Step  1420] loss: 0.049\n",
            "[Epoch 41, Step  1430] loss: 0.234\n",
            "[Epoch 41, Step  1440] loss: 0.054\n",
            "[Epoch 41, Step  1450] loss: 0.407\n",
            "[Epoch 41, Step  1460] loss: 0.412\n",
            "[Epoch 41, Step  1470] loss: 0.279\n",
            "[Epoch 41, Step  1480] loss: 0.384\n",
            "[Epoch 41, Step  1490] loss: 0.037\n",
            "[Epoch 41, Step  1500] loss: 0.295\n",
            "[Epoch 41, Step  1510] loss: 0.194\n",
            "[Epoch 41, Step  1520] loss: 0.233\n",
            "[Epoch 41, Step  1530] loss: 0.090\n",
            "[Epoch 41, Step  1540] loss: 0.263\n",
            "[Epoch 41, Step  1550] loss: 0.057\n",
            "[Epoch 41, Step  1560] loss: 0.240\n",
            "[Epoch 41, Step  1570] loss: 0.087\n",
            "[Epoch 41, Step  1580] loss: 0.203\n",
            "[Epoch 41, Step  1590] loss: 0.111\n",
            "[Epoch 41, Step  1600] loss: 0.180\n",
            "[Epoch 42, Step    10] loss: 0.319\n",
            "[Epoch 42, Step    20] loss: 0.148\n",
            "[Epoch 42, Step    30] loss: 0.399\n",
            "[Epoch 42, Step    40] loss: 0.182\n",
            "[Epoch 42, Step    50] loss: 0.183\n",
            "[Epoch 42, Step    60] loss: 0.176\n",
            "[Epoch 42, Step    70] loss: 0.071\n",
            "[Epoch 42, Step    80] loss: 0.209\n",
            "[Epoch 42, Step    90] loss: 0.132\n",
            "[Epoch 42, Step   100] loss: 0.176\n",
            "[Epoch 42, Step   110] loss: 0.047\n",
            "[Epoch 42, Step   120] loss: 0.332\n",
            "[Epoch 42, Step   130] loss: 0.135\n",
            "[Epoch 42, Step   140] loss: 0.187\n",
            "[Epoch 42, Step   150] loss: 0.065\n",
            "[Epoch 42, Step   160] loss: 0.249\n",
            "[Epoch 42, Step   170] loss: 0.123\n",
            "[Epoch 42, Step   180] loss: 0.470\n",
            "[Epoch 42, Step   190] loss: 0.070\n",
            "[Epoch 42, Step   200] loss: 0.087\n",
            "[Epoch 42, Step   210] loss: 0.395\n",
            "[Epoch 42, Step   220] loss: 0.188\n",
            "[Epoch 42, Step   230] loss: 0.273\n",
            "[Epoch 42, Step   240] loss: 0.059\n",
            "[Epoch 42, Step   250] loss: 0.152\n",
            "[Epoch 42, Step   260] loss: 0.587\n",
            "[Epoch 42, Step   270] loss: 0.529\n",
            "[Epoch 42, Step   280] loss: 0.282\n",
            "[Epoch 42, Step   290] loss: 0.155\n",
            "[Epoch 42, Step   300] loss: 0.052\n",
            "[Epoch 42, Step   310] loss: 0.571\n",
            "[Epoch 42, Step   320] loss: 0.528\n",
            "[Epoch 42, Step   330] loss: 0.373\n",
            "[Epoch 42, Step   340] loss: 0.399\n",
            "[Epoch 42, Step   350] loss: 0.204\n",
            "[Epoch 42, Step   360] loss: 0.253\n",
            "[Epoch 42, Step   370] loss: 0.424\n",
            "[Epoch 42, Step   380] loss: 0.089\n",
            "[Epoch 42, Step   390] loss: 0.073\n",
            "[Epoch 42, Step   400] loss: 0.313\n",
            "[Epoch 42, Step   410] loss: 0.118\n",
            "[Epoch 42, Step   420] loss: 0.126\n",
            "[Epoch 42, Step   430] loss: 0.176\n",
            "[Epoch 42, Step   440] loss: 0.239\n",
            "[Epoch 42, Step   450] loss: 0.075\n",
            "[Epoch 42, Step   460] loss: 0.251\n",
            "[Epoch 42, Step   470] loss: 0.265\n",
            "[Epoch 42, Step   480] loss: 0.162\n",
            "[Epoch 42, Step   490] loss: 0.164\n",
            "[Epoch 42, Step   500] loss: 0.241\n",
            "[Epoch 42, Step   510] loss: 0.088\n",
            "[Epoch 42, Step   520] loss: 0.277\n",
            "[Epoch 42, Step   530] loss: 0.231\n",
            "[Epoch 42, Step   540] loss: 0.301\n",
            "[Epoch 42, Step   550] loss: 0.315\n",
            "[Epoch 42, Step   560] loss: 0.271\n",
            "[Epoch 42, Step   570] loss: 0.209\n",
            "[Epoch 42, Step   580] loss: 0.345\n",
            "[Epoch 42, Step   590] loss: 0.355\n",
            "[Epoch 42, Step   600] loss: 0.283\n",
            "[Epoch 42, Step   610] loss: 0.139\n",
            "[Epoch 42, Step   620] loss: 0.137\n",
            "[Epoch 42, Step   630] loss: 0.239\n",
            "[Epoch 42, Step   640] loss: 0.311\n",
            "[Epoch 42, Step   650] loss: 0.370\n",
            "[Epoch 42, Step   660] loss: 0.089\n",
            "[Epoch 42, Step   670] loss: 0.330\n",
            "[Epoch 42, Step   680] loss: 0.257\n",
            "[Epoch 42, Step   690] loss: 0.711\n",
            "[Epoch 42, Step   700] loss: 0.147\n",
            "[Epoch 42, Step   710] loss: 0.206\n",
            "[Epoch 42, Step   720] loss: 0.369\n",
            "[Epoch 42, Step   730] loss: 0.086\n",
            "[Epoch 42, Step   740] loss: 0.205\n",
            "[Epoch 42, Step   750] loss: 0.158\n",
            "[Epoch 42, Step   760] loss: 0.624\n",
            "[Epoch 42, Step   770] loss: 0.363\n",
            "[Epoch 42, Step   780] loss: 0.090\n",
            "[Epoch 42, Step   790] loss: 0.245\n",
            "[Epoch 42, Step   800] loss: 0.350\n",
            "[Epoch 42, Step   810] loss: 0.185\n",
            "[Epoch 42, Step   820] loss: 0.371\n",
            "[Epoch 42, Step   830] loss: 0.479\n",
            "[Epoch 42, Step   840] loss: 0.109\n",
            "[Epoch 42, Step   850] loss: 0.156\n",
            "[Epoch 42, Step   860] loss: 0.184\n",
            "[Epoch 42, Step   870] loss: 0.343\n",
            "[Epoch 42, Step   880] loss: 0.324\n",
            "[Epoch 42, Step   890] loss: 0.301\n",
            "[Epoch 42, Step   900] loss: 0.481\n",
            "[Epoch 42, Step   910] loss: 0.359\n",
            "[Epoch 42, Step   920] loss: 0.273\n",
            "[Epoch 42, Step   930] loss: 0.134\n",
            "[Epoch 42, Step   940] loss: 0.335\n",
            "[Epoch 42, Step   950] loss: 0.105\n",
            "[Epoch 42, Step   960] loss: 0.068\n",
            "[Epoch 42, Step   970] loss: 0.515\n",
            "[Epoch 42, Step   980] loss: 0.092\n",
            "[Epoch 42, Step   990] loss: 0.537\n",
            "[Epoch 42, Step  1000] loss: 0.199\n",
            "[Epoch 42, Step  1010] loss: 0.097\n",
            "[Epoch 42, Step  1020] loss: 0.244\n",
            "[Epoch 42, Step  1030] loss: 0.207\n",
            "[Epoch 42, Step  1040] loss: 0.214\n",
            "[Epoch 42, Step  1050] loss: 0.062\n",
            "[Epoch 42, Step  1060] loss: 0.169\n",
            "[Epoch 42, Step  1070] loss: 0.099\n",
            "[Epoch 42, Step  1080] loss: 0.755\n",
            "[Epoch 42, Step  1090] loss: 0.237\n",
            "[Epoch 42, Step  1100] loss: 0.080\n",
            "[Epoch 42, Step  1110] loss: 0.208\n",
            "[Epoch 42, Step  1120] loss: 0.196\n",
            "[Epoch 42, Step  1130] loss: 0.129\n",
            "[Epoch 42, Step  1140] loss: 0.117\n",
            "[Epoch 42, Step  1150] loss: 0.071\n",
            "[Epoch 42, Step  1160] loss: 0.130\n",
            "[Epoch 42, Step  1170] loss: 0.174\n",
            "[Epoch 42, Step  1180] loss: 0.250\n",
            "[Epoch 42, Step  1190] loss: 0.593\n",
            "[Epoch 42, Step  1200] loss: 0.371\n",
            "[Epoch 42, Step  1210] loss: 0.249\n",
            "[Epoch 42, Step  1220] loss: 0.069\n",
            "[Epoch 42, Step  1230] loss: 0.103\n",
            "[Epoch 42, Step  1240] loss: 0.197\n",
            "[Epoch 42, Step  1250] loss: 0.022\n",
            "[Epoch 42, Step  1260] loss: 0.477\n",
            "[Epoch 42, Step  1270] loss: 0.130\n",
            "[Epoch 42, Step  1280] loss: 0.469\n",
            "[Epoch 42, Step  1290] loss: 0.052\n",
            "[Epoch 42, Step  1300] loss: 0.161\n",
            "[Epoch 42, Step  1310] loss: 0.149\n",
            "[Epoch 42, Step  1320] loss: 0.439\n",
            "[Epoch 42, Step  1330] loss: 0.086\n",
            "[Epoch 42, Step  1340] loss: 0.128\n",
            "[Epoch 42, Step  1350] loss: 0.356\n",
            "[Epoch 42, Step  1360] loss: 0.345\n",
            "[Epoch 42, Step  1370] loss: 0.228\n",
            "[Epoch 42, Step  1380] loss: 0.297\n",
            "[Epoch 42, Step  1390] loss: 0.195\n",
            "[Epoch 42, Step  1400] loss: 0.046\n",
            "[Epoch 42, Step  1410] loss: 0.059\n",
            "[Epoch 42, Step  1420] loss: 0.035\n",
            "[Epoch 42, Step  1430] loss: 0.056\n",
            "[Epoch 42, Step  1440] loss: 0.090\n",
            "[Epoch 42, Step  1450] loss: 0.183\n",
            "[Epoch 42, Step  1460] loss: 0.094\n",
            "[Epoch 42, Step  1470] loss: 0.381\n",
            "[Epoch 42, Step  1480] loss: 0.386\n",
            "[Epoch 42, Step  1490] loss: 0.020\n",
            "[Epoch 42, Step  1500] loss: 0.134\n",
            "[Epoch 42, Step  1510] loss: 0.291\n",
            "[Epoch 42, Step  1520] loss: 0.472\n",
            "[Epoch 42, Step  1530] loss: 0.179\n",
            "[Epoch 42, Step  1540] loss: 0.033\n",
            "[Epoch 42, Step  1550] loss: 0.027\n",
            "[Epoch 42, Step  1560] loss: 0.203\n",
            "[Epoch 42, Step  1570] loss: 0.110\n",
            "[Epoch 42, Step  1580] loss: 0.237\n",
            "[Epoch 42, Step  1590] loss: 0.468\n",
            "[Epoch 42, Step  1600] loss: 0.511\n",
            "[Epoch 43, Step    10] loss: 0.206\n",
            "[Epoch 43, Step    20] loss: 0.230\n",
            "[Epoch 43, Step    30] loss: 0.249\n",
            "[Epoch 43, Step    40] loss: 0.376\n",
            "[Epoch 43, Step    50] loss: 0.339\n",
            "[Epoch 43, Step    60] loss: 0.018\n",
            "[Epoch 43, Step    70] loss: 0.128\n",
            "[Epoch 43, Step    80] loss: 0.516\n",
            "[Epoch 43, Step    90] loss: 0.227\n",
            "[Epoch 43, Step   100] loss: 0.345\n",
            "[Epoch 43, Step   110] loss: 0.403\n",
            "[Epoch 43, Step   120] loss: 0.125\n",
            "[Epoch 43, Step   130] loss: 0.212\n",
            "[Epoch 43, Step   140] loss: 0.053\n",
            "[Epoch 43, Step   150] loss: 0.272\n",
            "[Epoch 43, Step   160] loss: 0.203\n",
            "[Epoch 43, Step   170] loss: 0.054\n",
            "[Epoch 43, Step   180] loss: 0.044\n",
            "[Epoch 43, Step   190] loss: 0.060\n",
            "[Epoch 43, Step   200] loss: 0.157\n",
            "[Epoch 43, Step   210] loss: 0.260\n",
            "[Epoch 43, Step   220] loss: 0.075\n",
            "[Epoch 43, Step   230] loss: 0.048\n",
            "[Epoch 43, Step   240] loss: 0.229\n",
            "[Epoch 43, Step   250] loss: 0.223\n",
            "[Epoch 43, Step   260] loss: 0.373\n",
            "[Epoch 43, Step   270] loss: 0.132\n",
            "[Epoch 43, Step   280] loss: 0.196\n",
            "[Epoch 43, Step   290] loss: 0.175\n",
            "[Epoch 43, Step   300] loss: 0.140\n",
            "[Epoch 43, Step   310] loss: 0.352\n",
            "[Epoch 43, Step   320] loss: 0.111\n",
            "[Epoch 43, Step   330] loss: 0.186\n",
            "[Epoch 43, Step   340] loss: 0.189\n",
            "[Epoch 43, Step   350] loss: 0.298\n",
            "[Epoch 43, Step   360] loss: 0.402\n",
            "[Epoch 43, Step   370] loss: 0.304\n",
            "[Epoch 43, Step   380] loss: 0.404\n",
            "[Epoch 43, Step   390] loss: 0.615\n",
            "[Epoch 43, Step   400] loss: 0.075\n",
            "[Epoch 43, Step   410] loss: 0.175\n",
            "[Epoch 43, Step   420] loss: 0.286\n",
            "[Epoch 43, Step   430] loss: 0.210\n",
            "[Epoch 43, Step   440] loss: 0.165\n",
            "[Epoch 43, Step   450] loss: 0.138\n",
            "[Epoch 43, Step   460] loss: 0.186\n",
            "[Epoch 43, Step   470] loss: 0.142\n",
            "[Epoch 43, Step   480] loss: 0.241\n",
            "[Epoch 43, Step   490] loss: 0.128\n",
            "[Epoch 43, Step   500] loss: 0.076\n",
            "[Epoch 43, Step   510] loss: 0.049\n",
            "[Epoch 43, Step   520] loss: 0.192\n",
            "[Epoch 43, Step   530] loss: 0.368\n",
            "[Epoch 43, Step   540] loss: 0.222\n",
            "[Epoch 43, Step   550] loss: 0.372\n",
            "[Epoch 43, Step   560] loss: 0.152\n",
            "[Epoch 43, Step   570] loss: 0.149\n",
            "[Epoch 43, Step   580] loss: 0.044\n",
            "[Epoch 43, Step   590] loss: 0.235\n",
            "[Epoch 43, Step   600] loss: 0.302\n",
            "[Epoch 43, Step   610] loss: 0.588\n",
            "[Epoch 43, Step   620] loss: 0.267\n",
            "[Epoch 43, Step   630] loss: 0.557\n",
            "[Epoch 43, Step   640] loss: 0.668\n",
            "[Epoch 43, Step   650] loss: 0.399\n",
            "[Epoch 43, Step   660] loss: 0.348\n",
            "[Epoch 43, Step   670] loss: 0.113\n",
            "[Epoch 43, Step   680] loss: 0.479\n",
            "[Epoch 43, Step   690] loss: 0.422\n",
            "[Epoch 43, Step   700] loss: 0.069\n",
            "[Epoch 43, Step   710] loss: 0.121\n",
            "[Epoch 43, Step   720] loss: 0.334\n",
            "[Epoch 43, Step   730] loss: 0.149\n",
            "[Epoch 43, Step   740] loss: 0.155\n",
            "[Epoch 43, Step   750] loss: 0.361\n",
            "[Epoch 43, Step   760] loss: 0.107\n",
            "[Epoch 43, Step   770] loss: 0.135\n",
            "[Epoch 43, Step   780] loss: 0.202\n",
            "[Epoch 43, Step   790] loss: 0.552\n",
            "[Epoch 43, Step   800] loss: 0.171\n",
            "[Epoch 43, Step   810] loss: 0.097\n",
            "[Epoch 43, Step   820] loss: 0.230\n",
            "[Epoch 43, Step   830] loss: 0.013\n",
            "[Epoch 43, Step   840] loss: 0.168\n",
            "[Epoch 43, Step   850] loss: 0.200\n",
            "[Epoch 43, Step   860] loss: 0.193\n",
            "[Epoch 43, Step   870] loss: 0.208\n",
            "[Epoch 43, Step   880] loss: 0.126\n",
            "[Epoch 43, Step   890] loss: 0.123\n",
            "[Epoch 43, Step   900] loss: 0.136\n",
            "[Epoch 43, Step   910] loss: 0.164\n",
            "[Epoch 43, Step   920] loss: 0.137\n",
            "[Epoch 43, Step   930] loss: 0.354\n",
            "[Epoch 43, Step   940] loss: 0.154\n",
            "[Epoch 43, Step   950] loss: 0.249\n",
            "[Epoch 43, Step   960] loss: 0.326\n",
            "[Epoch 43, Step   970] loss: 0.233\n",
            "[Epoch 43, Step   980] loss: 0.324\n",
            "[Epoch 43, Step   990] loss: 0.314\n",
            "[Epoch 43, Step  1000] loss: 0.258\n",
            "[Epoch 43, Step  1010] loss: 0.278\n",
            "[Epoch 43, Step  1020] loss: 0.274\n",
            "[Epoch 43, Step  1030] loss: 0.105\n",
            "[Epoch 43, Step  1040] loss: 0.239\n",
            "[Epoch 43, Step  1050] loss: 0.741\n",
            "[Epoch 43, Step  1060] loss: 0.188\n",
            "[Epoch 43, Step  1070] loss: 0.055\n",
            "[Epoch 43, Step  1080] loss: 0.137\n",
            "[Epoch 43, Step  1090] loss: 0.100\n",
            "[Epoch 43, Step  1100] loss: 0.143\n",
            "[Epoch 43, Step  1110] loss: 0.172\n",
            "[Epoch 43, Step  1120] loss: 0.116\n",
            "[Epoch 43, Step  1130] loss: 0.089\n",
            "[Epoch 43, Step  1140] loss: 0.377\n",
            "[Epoch 43, Step  1150] loss: 0.067\n",
            "[Epoch 43, Step  1160] loss: 0.421\n",
            "[Epoch 43, Step  1170] loss: 0.253\n",
            "[Epoch 43, Step  1180] loss: 0.538\n",
            "[Epoch 43, Step  1190] loss: 0.322\n",
            "[Epoch 43, Step  1200] loss: 0.197\n",
            "[Epoch 43, Step  1210] loss: 0.120\n",
            "[Epoch 43, Step  1220] loss: 0.163\n",
            "[Epoch 43, Step  1230] loss: 0.163\n",
            "[Epoch 43, Step  1240] loss: 0.158\n",
            "[Epoch 43, Step  1250] loss: 0.352\n",
            "[Epoch 43, Step  1260] loss: 0.218\n",
            "[Epoch 43, Step  1270] loss: 0.080\n",
            "[Epoch 43, Step  1280] loss: 0.345\n",
            "[Epoch 43, Step  1290] loss: 0.299\n",
            "[Epoch 43, Step  1300] loss: 0.106\n",
            "[Epoch 43, Step  1310] loss: 0.360\n",
            "[Epoch 43, Step  1320] loss: 0.269\n",
            "[Epoch 43, Step  1330] loss: 0.340\n",
            "[Epoch 43, Step  1340] loss: 0.304\n",
            "[Epoch 43, Step  1350] loss: 0.220\n",
            "[Epoch 43, Step  1360] loss: 0.185\n",
            "[Epoch 43, Step  1370] loss: 0.181\n",
            "[Epoch 43, Step  1380] loss: 0.543\n",
            "[Epoch 43, Step  1390] loss: 0.380\n",
            "[Epoch 43, Step  1400] loss: 0.174\n",
            "[Epoch 43, Step  1410] loss: 0.308\n",
            "[Epoch 43, Step  1420] loss: 0.349\n",
            "[Epoch 43, Step  1430] loss: 0.414\n",
            "[Epoch 43, Step  1440] loss: 0.271\n",
            "[Epoch 43, Step  1450] loss: 0.122\n",
            "[Epoch 43, Step  1460] loss: 0.286\n",
            "[Epoch 43, Step  1470] loss: 0.098\n",
            "[Epoch 43, Step  1480] loss: 0.143\n",
            "[Epoch 43, Step  1490] loss: 0.385\n",
            "[Epoch 43, Step  1500] loss: 0.256\n",
            "[Epoch 43, Step  1510] loss: 0.031\n",
            "[Epoch 43, Step  1520] loss: 0.177\n",
            "[Epoch 43, Step  1530] loss: 0.273\n",
            "[Epoch 43, Step  1540] loss: 0.120\n",
            "[Epoch 43, Step  1550] loss: 0.076\n",
            "[Epoch 43, Step  1560] loss: 0.326\n",
            "[Epoch 43, Step  1570] loss: 0.400\n",
            "[Epoch 43, Step  1580] loss: 0.116\n",
            "[Epoch 43, Step  1590] loss: 0.155\n",
            "[Epoch 43, Step  1600] loss: 0.115\n",
            "[Epoch 44, Step    10] loss: 0.067\n",
            "[Epoch 44, Step    20] loss: 0.127\n",
            "[Epoch 44, Step    30] loss: 0.355\n",
            "[Epoch 44, Step    40] loss: 0.126\n",
            "[Epoch 44, Step    50] loss: 0.377\n",
            "[Epoch 44, Step    60] loss: 0.155\n",
            "[Epoch 44, Step    70] loss: 0.451\n",
            "[Epoch 44, Step    80] loss: 0.334\n",
            "[Epoch 44, Step    90] loss: 0.234\n",
            "[Epoch 44, Step   100] loss: 0.238\n",
            "[Epoch 44, Step   110] loss: 0.277\n",
            "[Epoch 44, Step   120] loss: 0.172\n",
            "[Epoch 44, Step   130] loss: 0.081\n",
            "[Epoch 44, Step   140] loss: 0.147\n",
            "[Epoch 44, Step   150] loss: 0.802\n",
            "[Epoch 44, Step   160] loss: 0.214\n",
            "[Epoch 44, Step   170] loss: 0.318\n",
            "[Epoch 44, Step   180] loss: 0.036\n",
            "[Epoch 44, Step   190] loss: 0.102\n",
            "[Epoch 44, Step   200] loss: 0.422\n",
            "[Epoch 44, Step   210] loss: 0.082\n",
            "[Epoch 44, Step   220] loss: 0.193\n",
            "[Epoch 44, Step   230] loss: 0.140\n",
            "[Epoch 44, Step   240] loss: 0.208\n",
            "[Epoch 44, Step   250] loss: 0.041\n",
            "[Epoch 44, Step   260] loss: 0.534\n",
            "[Epoch 44, Step   270] loss: 0.156\n",
            "[Epoch 44, Step   280] loss: 0.395\n",
            "[Epoch 44, Step   290] loss: 0.516\n",
            "[Epoch 44, Step   300] loss: 0.217\n",
            "[Epoch 44, Step   310] loss: 0.259\n",
            "[Epoch 44, Step   320] loss: 0.366\n",
            "[Epoch 44, Step   330] loss: 0.273\n",
            "[Epoch 44, Step   340] loss: 0.436\n",
            "[Epoch 44, Step   350] loss: 0.147\n",
            "[Epoch 44, Step   360] loss: 0.116\n",
            "[Epoch 44, Step   370] loss: 0.133\n",
            "[Epoch 44, Step   380] loss: 0.161\n",
            "[Epoch 44, Step   390] loss: 0.174\n",
            "[Epoch 44, Step   400] loss: 0.035\n",
            "[Epoch 44, Step   410] loss: 0.162\n",
            "[Epoch 44, Step   420] loss: 0.160\n",
            "[Epoch 44, Step   430] loss: 0.236\n",
            "[Epoch 44, Step   440] loss: 0.167\n",
            "[Epoch 44, Step   450] loss: 0.179\n",
            "[Epoch 44, Step   460] loss: 0.237\n",
            "[Epoch 44, Step   470] loss: 0.047\n",
            "[Epoch 44, Step   480] loss: 0.124\n",
            "[Epoch 44, Step   490] loss: 0.343\n",
            "[Epoch 44, Step   500] loss: 0.069\n",
            "[Epoch 44, Step   510] loss: 0.073\n",
            "[Epoch 44, Step   520] loss: 0.084\n",
            "[Epoch 44, Step   530] loss: 0.270\n",
            "[Epoch 44, Step   540] loss: 0.199\n",
            "[Epoch 44, Step   550] loss: 0.075\n",
            "[Epoch 44, Step   560] loss: 0.345\n",
            "[Epoch 44, Step   570] loss: 0.393\n",
            "[Epoch 44, Step   580] loss: 0.114\n",
            "[Epoch 44, Step   590] loss: 0.223\n",
            "[Epoch 44, Step   600] loss: 0.045\n",
            "[Epoch 44, Step   610] loss: 0.117\n",
            "[Epoch 44, Step   620] loss: 0.099\n",
            "[Epoch 44, Step   630] loss: 0.139\n",
            "[Epoch 44, Step   640] loss: 0.553\n",
            "[Epoch 44, Step   650] loss: 0.093\n",
            "[Epoch 44, Step   660] loss: 0.332\n",
            "[Epoch 44, Step   670] loss: 0.067\n",
            "[Epoch 44, Step   680] loss: 0.091\n",
            "[Epoch 44, Step   690] loss: 0.269\n",
            "[Epoch 44, Step   700] loss: 0.499\n",
            "[Epoch 44, Step   710] loss: 0.095\n",
            "[Epoch 44, Step   720] loss: 0.241\n",
            "[Epoch 44, Step   730] loss: 0.216\n",
            "[Epoch 44, Step   740] loss: 0.178\n",
            "[Epoch 44, Step   750] loss: 0.135\n",
            "[Epoch 44, Step   760] loss: 0.194\n",
            "[Epoch 44, Step   770] loss: 0.055\n",
            "[Epoch 44, Step   780] loss: 0.101\n",
            "[Epoch 44, Step   790] loss: 0.228\n",
            "[Epoch 44, Step   800] loss: 0.329\n",
            "[Epoch 44, Step   810] loss: 0.146\n",
            "[Epoch 44, Step   820] loss: 0.135\n",
            "[Epoch 44, Step   830] loss: 0.479\n",
            "[Epoch 44, Step   840] loss: 0.265\n",
            "[Epoch 44, Step   850] loss: 0.037\n",
            "[Epoch 44, Step   860] loss: 0.386\n",
            "[Epoch 44, Step   870] loss: 0.283\n",
            "[Epoch 44, Step   880] loss: 0.254\n",
            "[Epoch 44, Step   890] loss: 0.235\n",
            "[Epoch 44, Step   900] loss: 0.207\n",
            "[Epoch 44, Step   910] loss: 0.167\n",
            "[Epoch 44, Step   920] loss: 0.068\n",
            "[Epoch 44, Step   930] loss: 0.208\n",
            "[Epoch 44, Step   940] loss: 0.224\n",
            "[Epoch 44, Step   950] loss: 0.234\n",
            "[Epoch 44, Step   960] loss: 0.076\n",
            "[Epoch 44, Step   970] loss: 0.232\n",
            "[Epoch 44, Step   980] loss: 0.506\n",
            "[Epoch 44, Step   990] loss: 0.055\n",
            "[Epoch 44, Step  1000] loss: 0.143\n",
            "[Epoch 44, Step  1010] loss: 0.225\n",
            "[Epoch 44, Step  1020] loss: 0.273\n",
            "[Epoch 44, Step  1030] loss: 0.250\n",
            "[Epoch 44, Step  1040] loss: 0.293\n",
            "[Epoch 44, Step  1050] loss: 0.298\n",
            "[Epoch 44, Step  1060] loss: 0.407\n",
            "[Epoch 44, Step  1070] loss: 0.206\n",
            "[Epoch 44, Step  1080] loss: 0.079\n",
            "[Epoch 44, Step  1090] loss: 0.391\n",
            "[Epoch 44, Step  1100] loss: 0.527\n",
            "[Epoch 44, Step  1110] loss: 0.256\n",
            "[Epoch 44, Step  1120] loss: 0.419\n",
            "[Epoch 44, Step  1130] loss: 0.506\n",
            "[Epoch 44, Step  1140] loss: 0.300\n",
            "[Epoch 44, Step  1150] loss: 0.262\n",
            "[Epoch 44, Step  1160] loss: 0.312\n",
            "[Epoch 44, Step  1170] loss: 0.190\n",
            "[Epoch 44, Step  1180] loss: 0.493\n",
            "[Epoch 44, Step  1190] loss: 0.249\n",
            "[Epoch 44, Step  1200] loss: 0.152\n",
            "[Epoch 44, Step  1210] loss: 0.153\n",
            "[Epoch 44, Step  1220] loss: 0.373\n",
            "[Epoch 44, Step  1230] loss: 0.199\n",
            "[Epoch 44, Step  1240] loss: 0.043\n",
            "[Epoch 44, Step  1250] loss: 0.085\n",
            "[Epoch 44, Step  1260] loss: 0.253\n",
            "[Epoch 44, Step  1270] loss: 0.098\n",
            "[Epoch 44, Step  1280] loss: 0.280\n",
            "[Epoch 44, Step  1290] loss: 0.031\n",
            "[Epoch 44, Step  1300] loss: 0.196\n",
            "[Epoch 44, Step  1310] loss: 0.055\n",
            "[Epoch 44, Step  1320] loss: 0.388\n",
            "[Epoch 44, Step  1330] loss: 0.292\n",
            "[Epoch 44, Step  1340] loss: 0.117\n",
            "[Epoch 44, Step  1350] loss: 0.189\n",
            "[Epoch 44, Step  1360] loss: 0.394\n",
            "[Epoch 44, Step  1370] loss: 0.138\n",
            "[Epoch 44, Step  1380] loss: 0.803\n",
            "[Epoch 44, Step  1390] loss: 0.267\n",
            "[Epoch 44, Step  1400] loss: 0.047\n",
            "[Epoch 44, Step  1410] loss: 0.403\n",
            "[Epoch 44, Step  1420] loss: 0.221\n",
            "[Epoch 44, Step  1430] loss: 0.142\n",
            "[Epoch 44, Step  1440] loss: 0.113\n",
            "[Epoch 44, Step  1450] loss: 1.113\n",
            "[Epoch 44, Step  1460] loss: 0.146\n",
            "[Epoch 44, Step  1470] loss: 0.266\n",
            "[Epoch 44, Step  1480] loss: 0.112\n",
            "[Epoch 44, Step  1490] loss: 0.074\n",
            "[Epoch 44, Step  1500] loss: 0.402\n",
            "[Epoch 44, Step  1510] loss: 0.085\n",
            "[Epoch 44, Step  1520] loss: 0.153\n",
            "[Epoch 44, Step  1530] loss: 0.170\n",
            "[Epoch 44, Step  1540] loss: 0.118\n",
            "[Epoch 44, Step  1550] loss: 0.250\n",
            "[Epoch 44, Step  1560] loss: 0.168\n",
            "[Epoch 44, Step  1570] loss: 0.209\n",
            "[Epoch 44, Step  1580] loss: 0.195\n",
            "[Epoch 44, Step  1590] loss: 0.172\n",
            "[Epoch 44, Step  1600] loss: 0.211\n",
            "[Epoch 45, Step    10] loss: 0.401\n",
            "[Epoch 45, Step    20] loss: 0.039\n",
            "[Epoch 45, Step    30] loss: 0.123\n",
            "[Epoch 45, Step    40] loss: 0.437\n",
            "[Epoch 45, Step    50] loss: 0.308\n",
            "[Epoch 45, Step    60] loss: 0.265\n",
            "[Epoch 45, Step    70] loss: 0.405\n",
            "[Epoch 45, Step    80] loss: 0.152\n",
            "[Epoch 45, Step    90] loss: 0.063\n",
            "[Epoch 45, Step   100] loss: 0.222\n",
            "[Epoch 45, Step   110] loss: 0.334\n",
            "[Epoch 45, Step   120] loss: 0.061\n",
            "[Epoch 45, Step   130] loss: 0.202\n",
            "[Epoch 45, Step   140] loss: 0.284\n",
            "[Epoch 45, Step   150] loss: 0.263\n",
            "[Epoch 45, Step   160] loss: 0.388\n",
            "[Epoch 45, Step   170] loss: 0.243\n",
            "[Epoch 45, Step   180] loss: 0.128\n",
            "[Epoch 45, Step   190] loss: 0.242\n",
            "[Epoch 45, Step   200] loss: 0.285\n",
            "[Epoch 45, Step   210] loss: 0.182\n",
            "[Epoch 45, Step   220] loss: 0.283\n",
            "[Epoch 45, Step   230] loss: 0.066\n",
            "[Epoch 45, Step   240] loss: 0.211\n",
            "[Epoch 45, Step   250] loss: 0.125\n",
            "[Epoch 45, Step   260] loss: 0.087\n",
            "[Epoch 45, Step   270] loss: 0.264\n",
            "[Epoch 45, Step   280] loss: 0.256\n",
            "[Epoch 45, Step   290] loss: 0.278\n",
            "[Epoch 45, Step   300] loss: 0.363\n",
            "[Epoch 45, Step   310] loss: 0.331\n",
            "[Epoch 45, Step   320] loss: 0.330\n",
            "[Epoch 45, Step   330] loss: 0.220\n",
            "[Epoch 45, Step   340] loss: 0.178\n",
            "[Epoch 45, Step   350] loss: 0.406\n",
            "[Epoch 45, Step   360] loss: 0.776\n",
            "[Epoch 45, Step   370] loss: 0.226\n",
            "[Epoch 45, Step   380] loss: 0.157\n",
            "[Epoch 45, Step   390] loss: 0.137\n",
            "[Epoch 45, Step   400] loss: 0.089\n",
            "[Epoch 45, Step   410] loss: 0.040\n",
            "[Epoch 45, Step   420] loss: 0.654\n",
            "[Epoch 45, Step   430] loss: 0.071\n",
            "[Epoch 45, Step   440] loss: 0.146\n",
            "[Epoch 45, Step   450] loss: 0.384\n",
            "[Epoch 45, Step   460] loss: 0.472\n",
            "[Epoch 45, Step   470] loss: 0.333\n",
            "[Epoch 45, Step   480] loss: 0.037\n",
            "[Epoch 45, Step   490] loss: 0.048\n",
            "[Epoch 45, Step   500] loss: 0.046\n",
            "[Epoch 45, Step   510] loss: 0.659\n",
            "[Epoch 45, Step   520] loss: 0.205\n",
            "[Epoch 45, Step   530] loss: 0.070\n",
            "[Epoch 45, Step   540] loss: 0.171\n",
            "[Epoch 45, Step   550] loss: 0.240\n",
            "[Epoch 45, Step   560] loss: 0.393\n",
            "[Epoch 45, Step   570] loss: 0.192\n",
            "[Epoch 45, Step   580] loss: 0.277\n",
            "[Epoch 45, Step   590] loss: 0.130\n",
            "[Epoch 45, Step   600] loss: 0.075\n",
            "[Epoch 45, Step   610] loss: 0.279\n",
            "[Epoch 45, Step   620] loss: 0.268\n",
            "[Epoch 45, Step   630] loss: 0.124\n",
            "[Epoch 45, Step   640] loss: 0.294\n",
            "[Epoch 45, Step   650] loss: 0.259\n",
            "[Epoch 45, Step   660] loss: 0.193\n",
            "[Epoch 45, Step   670] loss: 0.121\n",
            "[Epoch 45, Step   680] loss: 0.109\n",
            "[Epoch 45, Step   690] loss: 0.124\n",
            "[Epoch 45, Step   700] loss: 0.071\n",
            "[Epoch 45, Step   710] loss: 0.390\n",
            "[Epoch 45, Step   720] loss: 0.049\n",
            "[Epoch 45, Step   730] loss: 0.242\n",
            "[Epoch 45, Step   740] loss: 0.171\n",
            "[Epoch 45, Step   750] loss: 0.650\n",
            "[Epoch 45, Step   760] loss: 0.460\n",
            "[Epoch 45, Step   770] loss: 0.087\n",
            "[Epoch 45, Step   780] loss: 0.099\n",
            "[Epoch 45, Step   790] loss: 0.072\n",
            "[Epoch 45, Step   800] loss: 0.201\n",
            "[Epoch 45, Step   810] loss: 0.121\n",
            "[Epoch 45, Step   820] loss: 0.120\n",
            "[Epoch 45, Step   830] loss: 0.239\n",
            "[Epoch 45, Step   840] loss: 0.141\n",
            "[Epoch 45, Step   850] loss: 0.209\n",
            "[Epoch 45, Step   860] loss: 0.385\n",
            "[Epoch 45, Step   870] loss: 0.303\n",
            "[Epoch 45, Step   880] loss: 0.226\n",
            "[Epoch 45, Step   890] loss: 0.251\n",
            "[Epoch 45, Step   900] loss: 0.144\n",
            "[Epoch 45, Step   910] loss: 0.382\n",
            "[Epoch 45, Step   920] loss: 0.314\n",
            "[Epoch 45, Step   930] loss: 0.125\n",
            "[Epoch 45, Step   940] loss: 0.118\n",
            "[Epoch 45, Step   950] loss: 0.167\n",
            "[Epoch 45, Step   960] loss: 0.055\n",
            "[Epoch 45, Step   970] loss: 0.024\n",
            "[Epoch 45, Step   980] loss: 0.194\n",
            "[Epoch 45, Step   990] loss: 0.146\n",
            "[Epoch 45, Step  1000] loss: 0.059\n",
            "[Epoch 45, Step  1010] loss: 0.175\n",
            "[Epoch 45, Step  1020] loss: 0.158\n",
            "[Epoch 45, Step  1030] loss: 0.195\n",
            "[Epoch 45, Step  1040] loss: 0.157\n",
            "[Epoch 45, Step  1050] loss: 0.149\n",
            "[Epoch 45, Step  1060] loss: 0.173\n",
            "[Epoch 45, Step  1070] loss: 0.189\n",
            "[Epoch 45, Step  1080] loss: 0.325\n",
            "[Epoch 45, Step  1090] loss: 0.266\n",
            "[Epoch 45, Step  1100] loss: 0.103\n",
            "[Epoch 45, Step  1110] loss: 0.031\n",
            "[Epoch 45, Step  1120] loss: 0.186\n",
            "[Epoch 45, Step  1130] loss: 0.081\n",
            "[Epoch 45, Step  1140] loss: 0.262\n",
            "[Epoch 45, Step  1150] loss: 0.125\n",
            "[Epoch 45, Step  1160] loss: 0.177\n",
            "[Epoch 45, Step  1170] loss: 0.396\n",
            "[Epoch 45, Step  1180] loss: 0.061\n",
            "[Epoch 45, Step  1190] loss: 0.156\n",
            "[Epoch 45, Step  1200] loss: 0.409\n",
            "[Epoch 45, Step  1210] loss: 0.238\n",
            "[Epoch 45, Step  1220] loss: 0.270\n",
            "[Epoch 45, Step  1230] loss: 0.110\n",
            "[Epoch 45, Step  1240] loss: 0.366\n",
            "[Epoch 45, Step  1250] loss: 0.047\n",
            "[Epoch 45, Step  1260] loss: 0.202\n",
            "[Epoch 45, Step  1270] loss: 0.567\n",
            "[Epoch 45, Step  1280] loss: 0.299\n",
            "[Epoch 45, Step  1290] loss: 0.248\n",
            "[Epoch 45, Step  1300] loss: 0.292\n",
            "[Epoch 45, Step  1310] loss: 0.225\n",
            "[Epoch 45, Step  1320] loss: 0.161\n",
            "[Epoch 45, Step  1330] loss: 0.183\n",
            "[Epoch 45, Step  1340] loss: 0.468\n",
            "[Epoch 45, Step  1350] loss: 0.462\n",
            "[Epoch 45, Step  1360] loss: 0.158\n",
            "[Epoch 45, Step  1370] loss: 0.492\n",
            "[Epoch 45, Step  1380] loss: 0.243\n",
            "[Epoch 45, Step  1390] loss: 0.033\n",
            "[Epoch 45, Step  1400] loss: 0.098\n",
            "[Epoch 45, Step  1410] loss: 0.396\n",
            "[Epoch 45, Step  1420] loss: 0.142\n",
            "[Epoch 45, Step  1430] loss: 0.076\n",
            "[Epoch 45, Step  1440] loss: 0.235\n",
            "[Epoch 45, Step  1450] loss: 0.290\n",
            "[Epoch 45, Step  1460] loss: 0.208\n",
            "[Epoch 45, Step  1470] loss: 0.150\n",
            "[Epoch 45, Step  1480] loss: 0.203\n",
            "[Epoch 45, Step  1490] loss: 0.103\n",
            "[Epoch 45, Step  1500] loss: 0.164\n",
            "[Epoch 45, Step  1510] loss: 0.169\n",
            "[Epoch 45, Step  1520] loss: 0.262\n",
            "[Epoch 45, Step  1530] loss: 0.111\n",
            "[Epoch 45, Step  1540] loss: 0.723\n",
            "[Epoch 45, Step  1550] loss: 0.611\n",
            "[Epoch 45, Step  1560] loss: 0.203\n",
            "[Epoch 45, Step  1570] loss: 0.208\n",
            "[Epoch 45, Step  1580] loss: 0.281\n",
            "[Epoch 45, Step  1590] loss: 0.094\n",
            "[Epoch 45, Step  1600] loss: 0.127\n",
            "[Epoch 46, Step    10] loss: 0.144\n",
            "[Epoch 46, Step    20] loss: 0.260\n",
            "[Epoch 46, Step    30] loss: 0.215\n",
            "[Epoch 46, Step    40] loss: 0.143\n",
            "[Epoch 46, Step    50] loss: 0.281\n",
            "[Epoch 46, Step    60] loss: 0.158\n",
            "[Epoch 46, Step    70] loss: 0.094\n",
            "[Epoch 46, Step    80] loss: 0.366\n",
            "[Epoch 46, Step    90] loss: 0.202\n",
            "[Epoch 46, Step   100] loss: 0.402\n",
            "[Epoch 46, Step   110] loss: 0.148\n",
            "[Epoch 46, Step   120] loss: 0.245\n",
            "[Epoch 46, Step   130] loss: 0.120\n",
            "[Epoch 46, Step   140] loss: 0.115\n",
            "[Epoch 46, Step   150] loss: 0.053\n",
            "[Epoch 46, Step   160] loss: 0.110\n",
            "[Epoch 46, Step   170] loss: 0.119\n",
            "[Epoch 46, Step   180] loss: 0.158\n",
            "[Epoch 46, Step   190] loss: 0.084\n",
            "[Epoch 46, Step   200] loss: 0.144\n",
            "[Epoch 46, Step   210] loss: 0.493\n",
            "[Epoch 46, Step   220] loss: 0.292\n",
            "[Epoch 46, Step   230] loss: 0.232\n",
            "[Epoch 46, Step   240] loss: 0.202\n",
            "[Epoch 46, Step   250] loss: 0.534\n",
            "[Epoch 46, Step   260] loss: 0.080\n",
            "[Epoch 46, Step   270] loss: 0.150\n",
            "[Epoch 46, Step   280] loss: 0.131\n",
            "[Epoch 46, Step   290] loss: 0.334\n",
            "[Epoch 46, Step   300] loss: 0.695\n",
            "[Epoch 46, Step   310] loss: 0.203\n",
            "[Epoch 46, Step   320] loss: 0.425\n",
            "[Epoch 46, Step   330] loss: 0.259\n",
            "[Epoch 46, Step   340] loss: 0.086\n",
            "[Epoch 46, Step   350] loss: 0.332\n",
            "[Epoch 46, Step   360] loss: 0.186\n",
            "[Epoch 46, Step   370] loss: 0.057\n",
            "[Epoch 46, Step   380] loss: 0.218\n",
            "[Epoch 46, Step   390] loss: 0.230\n",
            "[Epoch 46, Step   400] loss: 0.294\n",
            "[Epoch 46, Step   410] loss: 0.146\n",
            "[Epoch 46, Step   420] loss: 0.250\n",
            "[Epoch 46, Step   430] loss: 0.173\n",
            "[Epoch 46, Step   440] loss: 0.174\n",
            "[Epoch 46, Step   450] loss: 0.366\n",
            "[Epoch 46, Step   460] loss: 0.354\n",
            "[Epoch 46, Step   470] loss: 0.139\n",
            "[Epoch 46, Step   480] loss: 0.204\n",
            "[Epoch 46, Step   490] loss: 0.170\n",
            "[Epoch 46, Step   500] loss: 0.155\n",
            "[Epoch 46, Step   510] loss: 0.579\n",
            "[Epoch 46, Step   520] loss: 0.137\n",
            "[Epoch 46, Step   530] loss: 0.169\n",
            "[Epoch 46, Step   540] loss: 0.161\n",
            "[Epoch 46, Step   550] loss: 0.057\n",
            "[Epoch 46, Step   560] loss: 0.127\n",
            "[Epoch 46, Step   570] loss: 0.138\n",
            "[Epoch 46, Step   580] loss: 0.166\n",
            "[Epoch 46, Step   590] loss: 0.065\n",
            "[Epoch 46, Step   600] loss: 0.196\n",
            "[Epoch 46, Step   610] loss: 0.337\n",
            "[Epoch 46, Step   620] loss: 0.175\n",
            "[Epoch 46, Step   630] loss: 0.595\n",
            "[Epoch 46, Step   640] loss: 0.130\n",
            "[Epoch 46, Step   650] loss: 0.119\n",
            "[Epoch 46, Step   660] loss: 0.112\n",
            "[Epoch 46, Step   670] loss: 0.063\n",
            "[Epoch 46, Step   680] loss: 0.073\n",
            "[Epoch 46, Step   690] loss: 0.136\n",
            "[Epoch 46, Step   700] loss: 0.346\n",
            "[Epoch 46, Step   710] loss: 0.087\n",
            "[Epoch 46, Step   720] loss: 0.201\n",
            "[Epoch 46, Step   730] loss: 0.415\n",
            "[Epoch 46, Step   740] loss: 0.276\n",
            "[Epoch 46, Step   750] loss: 0.269\n",
            "[Epoch 46, Step   760] loss: 0.249\n",
            "[Epoch 46, Step   770] loss: 0.075\n",
            "[Epoch 46, Step   780] loss: 0.103\n",
            "[Epoch 46, Step   790] loss: 0.336\n",
            "[Epoch 46, Step   800] loss: 0.209\n",
            "[Epoch 46, Step   810] loss: 0.222\n",
            "[Epoch 46, Step   820] loss: 0.258\n",
            "[Epoch 46, Step   830] loss: 0.123\n",
            "[Epoch 46, Step   840] loss: 0.502\n",
            "[Epoch 46, Step   850] loss: 0.174\n",
            "[Epoch 46, Step   860] loss: 0.677\n",
            "[Epoch 46, Step   870] loss: 0.091\n",
            "[Epoch 46, Step   880] loss: 0.043\n",
            "[Epoch 46, Step   890] loss: 0.205\n",
            "[Epoch 46, Step   900] loss: 0.050\n",
            "[Epoch 46, Step   910] loss: 0.203\n",
            "[Epoch 46, Step   920] loss: 0.023\n",
            "[Epoch 46, Step   930] loss: 0.474\n",
            "[Epoch 46, Step   940] loss: 0.588\n",
            "[Epoch 46, Step   950] loss: 0.488\n",
            "[Epoch 46, Step   960] loss: 0.014\n",
            "[Epoch 46, Step   970] loss: 0.117\n",
            "[Epoch 46, Step   980] loss: 0.405\n",
            "[Epoch 46, Step   990] loss: 0.109\n",
            "[Epoch 46, Step  1000] loss: 0.250\n",
            "[Epoch 46, Step  1010] loss: 0.059\n",
            "[Epoch 46, Step  1020] loss: 0.239\n",
            "[Epoch 46, Step  1030] loss: 0.323\n",
            "[Epoch 46, Step  1040] loss: 0.193\n",
            "[Epoch 46, Step  1050] loss: 0.200\n",
            "[Epoch 46, Step  1060] loss: 0.581\n",
            "[Epoch 46, Step  1070] loss: 0.528\n",
            "[Epoch 46, Step  1080] loss: 0.061\n",
            "[Epoch 46, Step  1090] loss: 0.202\n",
            "[Epoch 46, Step  1100] loss: 0.265\n",
            "[Epoch 46, Step  1110] loss: 0.242\n",
            "[Epoch 46, Step  1120] loss: 0.202\n",
            "[Epoch 46, Step  1130] loss: 0.261\n",
            "[Epoch 46, Step  1140] loss: 0.366\n",
            "[Epoch 46, Step  1150] loss: 0.260\n",
            "[Epoch 46, Step  1160] loss: 0.194\n",
            "[Epoch 46, Step  1170] loss: 0.267\n",
            "[Epoch 46, Step  1180] loss: 0.224\n",
            "[Epoch 46, Step  1190] loss: 0.150\n",
            "[Epoch 46, Step  1200] loss: 0.132\n",
            "[Epoch 46, Step  1210] loss: 0.111\n",
            "[Epoch 46, Step  1220] loss: 0.230\n",
            "[Epoch 46, Step  1230] loss: 0.102\n",
            "[Epoch 46, Step  1240] loss: 0.094\n",
            "[Epoch 46, Step  1250] loss: 0.225\n",
            "[Epoch 46, Step  1260] loss: 0.115\n",
            "[Epoch 46, Step  1270] loss: 0.312\n",
            "[Epoch 46, Step  1280] loss: 0.550\n",
            "[Epoch 46, Step  1290] loss: 0.340\n",
            "[Epoch 46, Step  1300] loss: 0.134\n",
            "[Epoch 46, Step  1310] loss: 0.116\n",
            "[Epoch 46, Step  1320] loss: 0.151\n",
            "[Epoch 46, Step  1330] loss: 0.289\n",
            "[Epoch 46, Step  1340] loss: 0.213\n",
            "[Epoch 46, Step  1350] loss: 0.029\n",
            "[Epoch 46, Step  1360] loss: 0.091\n",
            "[Epoch 46, Step  1370] loss: 0.338\n",
            "[Epoch 46, Step  1380] loss: 0.327\n",
            "[Epoch 46, Step  1390] loss: 0.091\n",
            "[Epoch 46, Step  1400] loss: 0.202\n",
            "[Epoch 46, Step  1410] loss: 0.191\n",
            "[Epoch 46, Step  1420] loss: 0.433\n",
            "[Epoch 46, Step  1430] loss: 0.222\n",
            "[Epoch 46, Step  1440] loss: 0.046\n",
            "[Epoch 46, Step  1450] loss: 0.244\n",
            "[Epoch 46, Step  1460] loss: 0.519\n",
            "[Epoch 46, Step  1470] loss: 0.122\n",
            "[Epoch 46, Step  1480] loss: 0.135\n",
            "[Epoch 46, Step  1490] loss: 0.172\n",
            "[Epoch 46, Step  1500] loss: 0.276\n",
            "[Epoch 46, Step  1510] loss: 0.261\n",
            "[Epoch 46, Step  1520] loss: 0.128\n",
            "[Epoch 46, Step  1530] loss: 0.381\n",
            "[Epoch 46, Step  1540] loss: 0.239\n",
            "[Epoch 46, Step  1550] loss: 0.176\n",
            "[Epoch 46, Step  1560] loss: 0.203\n",
            "[Epoch 46, Step  1570] loss: 0.471\n",
            "[Epoch 46, Step  1580] loss: 0.104\n",
            "[Epoch 46, Step  1590] loss: 0.286\n",
            "[Epoch 46, Step  1600] loss: 0.180\n",
            "[Epoch 47, Step    10] loss: 0.130\n",
            "[Epoch 47, Step    20] loss: 0.244\n",
            "[Epoch 47, Step    30] loss: 0.065\n",
            "[Epoch 47, Step    40] loss: 0.032\n",
            "[Epoch 47, Step    50] loss: 0.466\n",
            "[Epoch 47, Step    60] loss: 0.156\n",
            "[Epoch 47, Step    70] loss: 0.110\n",
            "[Epoch 47, Step    80] loss: 0.165\n",
            "[Epoch 47, Step    90] loss: 0.285\n",
            "[Epoch 47, Step   100] loss: 0.083\n",
            "[Epoch 47, Step   110] loss: 0.285\n",
            "[Epoch 47, Step   120] loss: 0.408\n",
            "[Epoch 47, Step   130] loss: 0.173\n",
            "[Epoch 47, Step   140] loss: 0.305\n",
            "[Epoch 47, Step   150] loss: 0.094\n",
            "[Epoch 47, Step   160] loss: 0.112\n",
            "[Epoch 47, Step   170] loss: 0.299\n",
            "[Epoch 47, Step   180] loss: 0.062\n",
            "[Epoch 47, Step   190] loss: 0.349\n",
            "[Epoch 47, Step   200] loss: 0.337\n",
            "[Epoch 47, Step   210] loss: 0.181\n",
            "[Epoch 47, Step   220] loss: 0.086\n",
            "[Epoch 47, Step   230] loss: 0.232\n",
            "[Epoch 47, Step   240] loss: 0.406\n",
            "[Epoch 47, Step   250] loss: 0.409\n",
            "[Epoch 47, Step   260] loss: 0.108\n",
            "[Epoch 47, Step   270] loss: 0.236\n",
            "[Epoch 47, Step   280] loss: 0.073\n",
            "[Epoch 47, Step   290] loss: 0.298\n",
            "[Epoch 47, Step   300] loss: 0.247\n",
            "[Epoch 47, Step   310] loss: 0.136\n",
            "[Epoch 47, Step   320] loss: 0.388\n",
            "[Epoch 47, Step   330] loss: 0.384\n",
            "[Epoch 47, Step   340] loss: 0.402\n",
            "[Epoch 47, Step   350] loss: 0.119\n",
            "[Epoch 47, Step   360] loss: 0.067\n",
            "[Epoch 47, Step   370] loss: 0.152\n",
            "[Epoch 47, Step   380] loss: 0.368\n",
            "[Epoch 47, Step   390] loss: 0.193\n",
            "[Epoch 47, Step   400] loss: 0.109\n",
            "[Epoch 47, Step   410] loss: 0.380\n",
            "[Epoch 47, Step   420] loss: 0.601\n",
            "[Epoch 47, Step   430] loss: 0.214\n",
            "[Epoch 47, Step   440] loss: 0.410\n",
            "[Epoch 47, Step   450] loss: 0.148\n",
            "[Epoch 47, Step   460] loss: 0.044\n",
            "[Epoch 47, Step   470] loss: 0.241\n",
            "[Epoch 47, Step   480] loss: 0.354\n",
            "[Epoch 47, Step   490] loss: 0.179\n",
            "[Epoch 47, Step   500] loss: 0.139\n",
            "[Epoch 47, Step   510] loss: 0.056\n",
            "[Epoch 47, Step   520] loss: 0.148\n",
            "[Epoch 47, Step   530] loss: 0.382\n",
            "[Epoch 47, Step   540] loss: 0.107\n",
            "[Epoch 47, Step   550] loss: 0.064\n",
            "[Epoch 47, Step   560] loss: 0.372\n",
            "[Epoch 47, Step   570] loss: 0.313\n",
            "[Epoch 47, Step   580] loss: 0.169\n",
            "[Epoch 47, Step   590] loss: 0.187\n",
            "[Epoch 47, Step   600] loss: 0.236\n",
            "[Epoch 47, Step   610] loss: 0.100\n",
            "[Epoch 47, Step   620] loss: 0.455\n",
            "[Epoch 47, Step   630] loss: 0.245\n",
            "[Epoch 47, Step   640] loss: 0.166\n",
            "[Epoch 47, Step   650] loss: 0.212\n",
            "[Epoch 47, Step   660] loss: 0.401\n",
            "[Epoch 47, Step   670] loss: 0.202\n",
            "[Epoch 47, Step   680] loss: 0.122\n",
            "[Epoch 47, Step   690] loss: 0.342\n",
            "[Epoch 47, Step   700] loss: 0.252\n",
            "[Epoch 47, Step   710] loss: 0.241\n",
            "[Epoch 47, Step   720] loss: 0.283\n",
            "[Epoch 47, Step   730] loss: 0.079\n",
            "[Epoch 47, Step   740] loss: 0.071\n",
            "[Epoch 47, Step   750] loss: 0.119\n",
            "[Epoch 47, Step   760] loss: 0.388\n",
            "[Epoch 47, Step   770] loss: 0.322\n",
            "[Epoch 47, Step   780] loss: 0.293\n",
            "[Epoch 47, Step   790] loss: 0.105\n",
            "[Epoch 47, Step   800] loss: 0.395\n",
            "[Epoch 47, Step   810] loss: 0.154\n",
            "[Epoch 47, Step   820] loss: 0.101\n",
            "[Epoch 47, Step   830] loss: 0.252\n",
            "[Epoch 47, Step   840] loss: 0.361\n",
            "[Epoch 47, Step   850] loss: 0.470\n",
            "[Epoch 47, Step   860] loss: 0.231\n",
            "[Epoch 47, Step   870] loss: 0.154\n",
            "[Epoch 47, Step   880] loss: 0.233\n",
            "[Epoch 47, Step   890] loss: 0.145\n",
            "[Epoch 47, Step   900] loss: 0.547\n",
            "[Epoch 47, Step   910] loss: 0.178\n",
            "[Epoch 47, Step   920] loss: 0.604\n",
            "[Epoch 47, Step   930] loss: 0.020\n",
            "[Epoch 47, Step   940] loss: 0.275\n",
            "[Epoch 47, Step   950] loss: 0.076\n",
            "[Epoch 47, Step   960] loss: 0.585\n",
            "[Epoch 47, Step   970] loss: 0.191\n",
            "[Epoch 47, Step   980] loss: 0.457\n",
            "[Epoch 47, Step   990] loss: 0.121\n",
            "[Epoch 47, Step  1000] loss: 0.037\n",
            "[Epoch 47, Step  1010] loss: 0.140\n",
            "[Epoch 47, Step  1020] loss: 0.407\n",
            "[Epoch 47, Step  1030] loss: 0.217\n",
            "[Epoch 47, Step  1040] loss: 0.155\n",
            "[Epoch 47, Step  1050] loss: 0.314\n",
            "[Epoch 47, Step  1060] loss: 0.129\n",
            "[Epoch 47, Step  1070] loss: 0.077\n",
            "[Epoch 47, Step  1080] loss: 0.195\n",
            "[Epoch 47, Step  1090] loss: 0.082\n",
            "[Epoch 47, Step  1100] loss: 0.498\n",
            "[Epoch 47, Step  1110] loss: 0.080\n",
            "[Epoch 47, Step  1120] loss: 0.228\n",
            "[Epoch 47, Step  1130] loss: 0.098\n",
            "[Epoch 47, Step  1140] loss: 0.123\n",
            "[Epoch 47, Step  1150] loss: 0.117\n",
            "[Epoch 47, Step  1160] loss: 0.433\n",
            "[Epoch 47, Step  1170] loss: 0.225\n",
            "[Epoch 47, Step  1180] loss: 0.032\n",
            "[Epoch 47, Step  1190] loss: 0.243\n",
            "[Epoch 47, Step  1200] loss: 0.119\n",
            "[Epoch 47, Step  1210] loss: 0.079\n",
            "[Epoch 47, Step  1220] loss: 0.286\n",
            "[Epoch 47, Step  1230] loss: 0.233\n",
            "[Epoch 47, Step  1240] loss: 0.067\n",
            "[Epoch 47, Step  1250] loss: 0.295\n",
            "[Epoch 47, Step  1260] loss: 0.246\n",
            "[Epoch 47, Step  1270] loss: 0.088\n",
            "[Epoch 47, Step  1280] loss: 0.273\n",
            "[Epoch 47, Step  1290] loss: 0.096\n",
            "[Epoch 47, Step  1300] loss: 0.254\n",
            "[Epoch 47, Step  1310] loss: 0.139\n",
            "[Epoch 47, Step  1320] loss: 0.239\n",
            "[Epoch 47, Step  1330] loss: 0.626\n",
            "[Epoch 47, Step  1340] loss: 0.291\n",
            "[Epoch 47, Step  1350] loss: 0.248\n",
            "[Epoch 47, Step  1360] loss: 0.067\n",
            "[Epoch 47, Step  1370] loss: 0.089\n",
            "[Epoch 47, Step  1380] loss: 0.228\n",
            "[Epoch 47, Step  1390] loss: 0.123\n",
            "[Epoch 47, Step  1400] loss: 0.367\n",
            "[Epoch 47, Step  1410] loss: 0.323\n",
            "[Epoch 47, Step  1420] loss: 0.220\n",
            "[Epoch 47, Step  1430] loss: 0.198\n",
            "[Epoch 47, Step  1440] loss: 0.159\n",
            "[Epoch 47, Step  1450] loss: 0.225\n",
            "[Epoch 47, Step  1460] loss: 0.206\n",
            "[Epoch 47, Step  1470] loss: 0.098\n",
            "[Epoch 47, Step  1480] loss: 0.078\n",
            "[Epoch 47, Step  1490] loss: 0.086\n",
            "[Epoch 47, Step  1500] loss: 0.065\n",
            "[Epoch 47, Step  1510] loss: 0.445\n",
            "[Epoch 47, Step  1520] loss: 0.064\n",
            "[Epoch 47, Step  1530] loss: 0.220\n",
            "[Epoch 47, Step  1540] loss: 0.190\n",
            "[Epoch 47, Step  1550] loss: 0.181\n",
            "[Epoch 47, Step  1560] loss: 0.136\n",
            "[Epoch 47, Step  1570] loss: 0.319\n",
            "[Epoch 47, Step  1580] loss: 0.313\n",
            "[Epoch 47, Step  1590] loss: 0.185\n",
            "[Epoch 47, Step  1600] loss: 0.340\n",
            "[Epoch 48, Step    10] loss: 0.237\n",
            "[Epoch 48, Step    20] loss: 0.417\n",
            "[Epoch 48, Step    30] loss: 0.145\n",
            "[Epoch 48, Step    40] loss: 0.306\n",
            "[Epoch 48, Step    50] loss: 0.247\n",
            "[Epoch 48, Step    60] loss: 0.205\n",
            "[Epoch 48, Step    70] loss: 0.184\n",
            "[Epoch 48, Step    80] loss: 0.204\n",
            "[Epoch 48, Step    90] loss: 0.298\n",
            "[Epoch 48, Step   100] loss: 0.244\n",
            "[Epoch 48, Step   110] loss: 0.314\n",
            "[Epoch 48, Step   120] loss: 0.194\n",
            "[Epoch 48, Step   130] loss: 0.362\n",
            "[Epoch 48, Step   140] loss: 0.321\n",
            "[Epoch 48, Step   150] loss: 0.211\n",
            "[Epoch 48, Step   160] loss: 0.218\n",
            "[Epoch 48, Step   170] loss: 0.093\n",
            "[Epoch 48, Step   180] loss: 0.328\n",
            "[Epoch 48, Step   190] loss: 0.500\n",
            "[Epoch 48, Step   200] loss: 0.063\n",
            "[Epoch 48, Step   210] loss: 0.623\n",
            "[Epoch 48, Step   220] loss: 0.150\n",
            "[Epoch 48, Step   230] loss: 0.224\n",
            "[Epoch 48, Step   240] loss: 0.188\n",
            "[Epoch 48, Step   250] loss: 0.117\n",
            "[Epoch 48, Step   260] loss: 0.292\n",
            "[Epoch 48, Step   270] loss: 0.041\n",
            "[Epoch 48, Step   280] loss: 0.271\n",
            "[Epoch 48, Step   290] loss: 0.497\n",
            "[Epoch 48, Step   300] loss: 0.486\n",
            "[Epoch 48, Step   310] loss: 0.094\n",
            "[Epoch 48, Step   320] loss: 0.159\n",
            "[Epoch 48, Step   330] loss: 0.263\n",
            "[Epoch 48, Step   340] loss: 0.077\n",
            "[Epoch 48, Step   350] loss: 0.135\n",
            "[Epoch 48, Step   360] loss: 0.348\n",
            "[Epoch 48, Step   370] loss: 0.241\n",
            "[Epoch 48, Step   380] loss: 0.219\n",
            "[Epoch 48, Step   390] loss: 0.342\n",
            "[Epoch 48, Step   400] loss: 0.111\n",
            "[Epoch 48, Step   410] loss: 0.140\n",
            "[Epoch 48, Step   420] loss: 0.402\n",
            "[Epoch 48, Step   430] loss: 0.259\n",
            "[Epoch 48, Step   440] loss: 0.054\n",
            "[Epoch 48, Step   450] loss: 0.088\n",
            "[Epoch 48, Step   460] loss: 0.218\n",
            "[Epoch 48, Step   470] loss: 0.051\n",
            "[Epoch 48, Step   480] loss: 0.168\n",
            "[Epoch 48, Step   490] loss: 0.207\n",
            "[Epoch 48, Step   500] loss: 0.061\n",
            "[Epoch 48, Step   510] loss: 0.190\n",
            "[Epoch 48, Step   520] loss: 0.244\n",
            "[Epoch 48, Step   530] loss: 0.332\n",
            "[Epoch 48, Step   540] loss: 0.073\n",
            "[Epoch 48, Step   550] loss: 0.477\n",
            "[Epoch 48, Step   560] loss: 0.721\n",
            "[Epoch 48, Step   570] loss: 0.335\n",
            "[Epoch 48, Step   580] loss: 0.186\n",
            "[Epoch 48, Step   590] loss: 0.297\n",
            "[Epoch 48, Step   600] loss: 0.417\n",
            "[Epoch 48, Step   610] loss: 0.056\n",
            "[Epoch 48, Step   620] loss: 0.316\n",
            "[Epoch 48, Step   630] loss: 0.104\n",
            "[Epoch 48, Step   640] loss: 0.649\n",
            "[Epoch 48, Step   650] loss: 0.181\n",
            "[Epoch 48, Step   660] loss: 0.054\n",
            "[Epoch 48, Step   670] loss: 0.415\n",
            "[Epoch 48, Step   680] loss: 0.259\n",
            "[Epoch 48, Step   690] loss: 0.098\n",
            "[Epoch 48, Step   700] loss: 0.374\n",
            "[Epoch 48, Step   710] loss: 0.286\n",
            "[Epoch 48, Step   720] loss: 0.048\n",
            "[Epoch 48, Step   730] loss: 0.236\n",
            "[Epoch 48, Step   740] loss: 0.259\n",
            "[Epoch 48, Step   750] loss: 0.183\n",
            "[Epoch 48, Step   760] loss: 0.234\n",
            "[Epoch 48, Step   770] loss: 0.244\n",
            "[Epoch 48, Step   780] loss: 0.072\n",
            "[Epoch 48, Step   790] loss: 0.104\n",
            "[Epoch 48, Step   800] loss: 0.378\n",
            "[Epoch 48, Step   810] loss: 0.256\n",
            "[Epoch 48, Step   820] loss: 0.222\n",
            "[Epoch 48, Step   830] loss: 0.058\n",
            "[Epoch 48, Step   840] loss: 0.027\n",
            "[Epoch 48, Step   850] loss: 0.183\n",
            "[Epoch 48, Step   860] loss: 0.239\n",
            "[Epoch 48, Step   870] loss: 0.057\n",
            "[Epoch 48, Step   880] loss: 0.041\n",
            "[Epoch 48, Step   890] loss: 0.308\n",
            "[Epoch 48, Step   900] loss: 0.053\n",
            "[Epoch 48, Step   910] loss: 0.284\n",
            "[Epoch 48, Step   920] loss: 0.351\n",
            "[Epoch 48, Step   930] loss: 0.089\n",
            "[Epoch 48, Step   940] loss: 0.215\n",
            "[Epoch 48, Step   950] loss: 0.190\n",
            "[Epoch 48, Step   960] loss: 0.302\n",
            "[Epoch 48, Step   970] loss: 0.208\n",
            "[Epoch 48, Step   980] loss: 0.101\n",
            "[Epoch 48, Step   990] loss: 0.181\n",
            "[Epoch 48, Step  1000] loss: 0.100\n",
            "[Epoch 48, Step  1010] loss: 0.133\n",
            "[Epoch 48, Step  1020] loss: 0.243\n",
            "[Epoch 48, Step  1030] loss: 0.306\n",
            "[Epoch 48, Step  1040] loss: 0.016\n",
            "[Epoch 48, Step  1050] loss: 0.114\n",
            "[Epoch 48, Step  1060] loss: 0.165\n",
            "[Epoch 48, Step  1070] loss: 0.146\n",
            "[Epoch 48, Step  1080] loss: 0.231\n",
            "[Epoch 48, Step  1090] loss: 0.177\n",
            "[Epoch 48, Step  1100] loss: 0.201\n",
            "[Epoch 48, Step  1110] loss: 0.057\n",
            "[Epoch 48, Step  1120] loss: 0.238\n",
            "[Epoch 48, Step  1130] loss: 0.117\n",
            "[Epoch 48, Step  1140] loss: 0.224\n",
            "[Epoch 48, Step  1150] loss: 0.054\n",
            "[Epoch 48, Step  1160] loss: 0.105\n",
            "[Epoch 48, Step  1170] loss: 0.250\n",
            "[Epoch 48, Step  1180] loss: 0.333\n",
            "[Epoch 48, Step  1190] loss: 0.115\n",
            "[Epoch 48, Step  1200] loss: 0.404\n",
            "[Epoch 48, Step  1210] loss: 0.387\n",
            "[Epoch 48, Step  1220] loss: 0.175\n",
            "[Epoch 48, Step  1230] loss: 0.032\n",
            "[Epoch 48, Step  1240] loss: 0.130\n",
            "[Epoch 48, Step  1250] loss: 0.150\n",
            "[Epoch 48, Step  1260] loss: 0.155\n",
            "[Epoch 48, Step  1270] loss: 0.259\n",
            "[Epoch 48, Step  1280] loss: 0.055\n",
            "[Epoch 48, Step  1290] loss: 0.303\n",
            "[Epoch 48, Step  1300] loss: 0.357\n",
            "[Epoch 48, Step  1310] loss: 0.159\n",
            "[Epoch 48, Step  1320] loss: 0.319\n",
            "[Epoch 48, Step  1330] loss: 0.022\n",
            "[Epoch 48, Step  1340] loss: 0.099\n",
            "[Epoch 48, Step  1350] loss: 0.156\n",
            "[Epoch 48, Step  1360] loss: 0.400\n",
            "[Epoch 48, Step  1370] loss: 0.394\n",
            "[Epoch 48, Step  1380] loss: 0.189\n",
            "[Epoch 48, Step  1390] loss: 0.121\n",
            "[Epoch 48, Step  1400] loss: 0.464\n",
            "[Epoch 48, Step  1410] loss: 0.109\n",
            "[Epoch 48, Step  1420] loss: 0.321\n",
            "[Epoch 48, Step  1430] loss: 0.185\n",
            "[Epoch 48, Step  1440] loss: 0.167\n",
            "[Epoch 48, Step  1450] loss: 0.570\n",
            "[Epoch 48, Step  1460] loss: 0.372\n",
            "[Epoch 48, Step  1470] loss: 0.144\n",
            "[Epoch 48, Step  1480] loss: 0.093\n",
            "[Epoch 48, Step  1490] loss: 0.534\n",
            "[Epoch 48, Step  1500] loss: 0.098\n",
            "[Epoch 48, Step  1510] loss: 0.376\n",
            "[Epoch 48, Step  1520] loss: 0.122\n",
            "[Epoch 48, Step  1530] loss: 0.104\n",
            "[Epoch 48, Step  1540] loss: 0.021\n",
            "[Epoch 48, Step  1550] loss: 0.199\n",
            "[Epoch 48, Step  1560] loss: 0.192\n",
            "[Epoch 48, Step  1570] loss: 0.377\n",
            "[Epoch 48, Step  1580] loss: 0.075\n",
            "[Epoch 48, Step  1590] loss: 0.330\n",
            "[Epoch 48, Step  1600] loss: 0.208\n",
            "[Epoch 49, Step    10] loss: 0.165\n",
            "[Epoch 49, Step    20] loss: 0.061\n",
            "[Epoch 49, Step    30] loss: 0.063\n",
            "[Epoch 49, Step    40] loss: 0.119\n",
            "[Epoch 49, Step    50] loss: 0.232\n",
            "[Epoch 49, Step    60] loss: 0.889\n",
            "[Epoch 49, Step    70] loss: 0.101\n",
            "[Epoch 49, Step    80] loss: 0.228\n",
            "[Epoch 49, Step    90] loss: 0.164\n",
            "[Epoch 49, Step   100] loss: 0.307\n",
            "[Epoch 49, Step   110] loss: 0.204\n",
            "[Epoch 49, Step   120] loss: 0.655\n",
            "[Epoch 49, Step   130] loss: 0.222\n",
            "[Epoch 49, Step   140] loss: 0.122\n",
            "[Epoch 49, Step   150] loss: 0.068\n",
            "[Epoch 49, Step   160] loss: 0.268\n",
            "[Epoch 49, Step   170] loss: 0.220\n",
            "[Epoch 49, Step   180] loss: 0.092\n",
            "[Epoch 49, Step   190] loss: 0.202\n",
            "[Epoch 49, Step   200] loss: 0.109\n",
            "[Epoch 49, Step   210] loss: 0.355\n",
            "[Epoch 49, Step   220] loss: 0.091\n",
            "[Epoch 49, Step   230] loss: 0.295\n",
            "[Epoch 49, Step   240] loss: 0.101\n",
            "[Epoch 49, Step   250] loss: 0.408\n",
            "[Epoch 49, Step   260] loss: 0.081\n",
            "[Epoch 49, Step   270] loss: 0.325\n",
            "[Epoch 49, Step   280] loss: 0.145\n",
            "[Epoch 49, Step   290] loss: 0.024\n",
            "[Epoch 49, Step   300] loss: 0.147\n",
            "[Epoch 49, Step   310] loss: 0.132\n",
            "[Epoch 49, Step   320] loss: 0.107\n",
            "[Epoch 49, Step   330] loss: 0.123\n",
            "[Epoch 49, Step   340] loss: 0.079\n",
            "[Epoch 49, Step   350] loss: 0.189\n",
            "[Epoch 49, Step   360] loss: 0.379\n",
            "[Epoch 49, Step   370] loss: 0.087\n",
            "[Epoch 49, Step   380] loss: 0.287\n",
            "[Epoch 49, Step   390] loss: 0.071\n",
            "[Epoch 49, Step   400] loss: 0.097\n",
            "[Epoch 49, Step   410] loss: 0.068\n",
            "[Epoch 49, Step   420] loss: 0.168\n",
            "[Epoch 49, Step   430] loss: 0.142\n",
            "[Epoch 49, Step   440] loss: 0.255\n",
            "[Epoch 49, Step   450] loss: 0.058\n",
            "[Epoch 49, Step   460] loss: 0.837\n",
            "[Epoch 49, Step   470] loss: 0.040\n",
            "[Epoch 49, Step   480] loss: 0.197\n",
            "[Epoch 49, Step   490] loss: 0.096\n",
            "[Epoch 49, Step   500] loss: 0.200\n",
            "[Epoch 49, Step   510] loss: 0.153\n",
            "[Epoch 49, Step   520] loss: 0.293\n",
            "[Epoch 49, Step   530] loss: 0.180\n",
            "[Epoch 49, Step   540] loss: 0.044\n",
            "[Epoch 49, Step   550] loss: 0.314\n",
            "[Epoch 49, Step   560] loss: 0.118\n",
            "[Epoch 49, Step   570] loss: 0.089\n",
            "[Epoch 49, Step   580] loss: 0.117\n",
            "[Epoch 49, Step   590] loss: 0.051\n",
            "[Epoch 49, Step   600] loss: 0.325\n",
            "[Epoch 49, Step   610] loss: 0.435\n",
            "[Epoch 49, Step   620] loss: 0.173\n",
            "[Epoch 49, Step   630] loss: 0.273\n",
            "[Epoch 49, Step   640] loss: 0.102\n",
            "[Epoch 49, Step   650] loss: 0.158\n",
            "[Epoch 49, Step   660] loss: 0.157\n",
            "[Epoch 49, Step   670] loss: 0.048\n",
            "[Epoch 49, Step   680] loss: 0.227\n",
            "[Epoch 49, Step   690] loss: 0.385\n",
            "[Epoch 49, Step   700] loss: 0.108\n",
            "[Epoch 49, Step   710] loss: 0.175\n",
            "[Epoch 49, Step   720] loss: 0.529\n",
            "[Epoch 49, Step   730] loss: 0.287\n",
            "[Epoch 49, Step   740] loss: 0.076\n",
            "[Epoch 49, Step   750] loss: 0.179\n",
            "[Epoch 49, Step   760] loss: 0.275\n",
            "[Epoch 49, Step   770] loss: 0.278\n",
            "[Epoch 49, Step   780] loss: 0.097\n",
            "[Epoch 49, Step   790] loss: 0.566\n",
            "[Epoch 49, Step   800] loss: 0.553\n",
            "[Epoch 49, Step   810] loss: 0.063\n",
            "[Epoch 49, Step   820] loss: 0.245\n",
            "[Epoch 49, Step   830] loss: 0.501\n",
            "[Epoch 49, Step   840] loss: 0.052\n",
            "[Epoch 49, Step   850] loss: 0.219\n",
            "[Epoch 49, Step   860] loss: 0.612\n",
            "[Epoch 49, Step   870] loss: 0.146\n",
            "[Epoch 49, Step   880] loss: 0.163\n",
            "[Epoch 49, Step   890] loss: 0.315\n",
            "[Epoch 49, Step   900] loss: 0.268\n",
            "[Epoch 49, Step   910] loss: 0.281\n",
            "[Epoch 49, Step   920] loss: 0.364\n",
            "[Epoch 49, Step   930] loss: 0.101\n",
            "[Epoch 49, Step   940] loss: 0.806\n",
            "[Epoch 49, Step   950] loss: 0.494\n",
            "[Epoch 49, Step   960] loss: 0.142\n",
            "[Epoch 49, Step   970] loss: 0.032\n",
            "[Epoch 49, Step   980] loss: 0.093\n",
            "[Epoch 49, Step   990] loss: 0.156\n",
            "[Epoch 49, Step  1000] loss: 0.240\n",
            "[Epoch 49, Step  1010] loss: 0.101\n",
            "[Epoch 49, Step  1020] loss: 0.302\n",
            "[Epoch 49, Step  1030] loss: 0.109\n",
            "[Epoch 49, Step  1040] loss: 0.135\n",
            "[Epoch 49, Step  1050] loss: 0.261\n",
            "[Epoch 49, Step  1060] loss: 0.094\n",
            "[Epoch 49, Step  1070] loss: 0.152\n",
            "[Epoch 49, Step  1080] loss: 0.247\n",
            "[Epoch 49, Step  1090] loss: 0.050\n",
            "[Epoch 49, Step  1100] loss: 0.112\n",
            "[Epoch 49, Step  1110] loss: 0.208\n",
            "[Epoch 49, Step  1120] loss: 0.293\n",
            "[Epoch 49, Step  1130] loss: 0.178\n",
            "[Epoch 49, Step  1140] loss: 0.108\n",
            "[Epoch 49, Step  1150] loss: 0.153\n",
            "[Epoch 49, Step  1160] loss: 0.150\n",
            "[Epoch 49, Step  1170] loss: 0.112\n",
            "[Epoch 49, Step  1180] loss: 0.158\n",
            "[Epoch 49, Step  1190] loss: 0.195\n",
            "[Epoch 49, Step  1200] loss: 0.606\n",
            "[Epoch 49, Step  1210] loss: 0.229\n",
            "[Epoch 49, Step  1220] loss: 0.260\n",
            "[Epoch 49, Step  1230] loss: 0.280\n",
            "[Epoch 49, Step  1240] loss: 0.651\n",
            "[Epoch 49, Step  1250] loss: 0.116\n",
            "[Epoch 49, Step  1260] loss: 0.221\n",
            "[Epoch 49, Step  1270] loss: 0.255\n",
            "[Epoch 49, Step  1280] loss: 0.251\n",
            "[Epoch 49, Step  1290] loss: 0.073\n",
            "[Epoch 49, Step  1300] loss: 0.199\n",
            "[Epoch 49, Step  1310] loss: 0.232\n",
            "[Epoch 49, Step  1320] loss: 0.198\n",
            "[Epoch 49, Step  1330] loss: 0.305\n",
            "[Epoch 49, Step  1340] loss: 0.203\n",
            "[Epoch 49, Step  1350] loss: 0.095\n",
            "[Epoch 49, Step  1360] loss: 0.246\n",
            "[Epoch 49, Step  1370] loss: 0.195\n",
            "[Epoch 49, Step  1380] loss: 0.058\n",
            "[Epoch 49, Step  1390] loss: 0.230\n",
            "[Epoch 49, Step  1400] loss: 0.106\n",
            "[Epoch 49, Step  1410] loss: 0.203\n",
            "[Epoch 49, Step  1420] loss: 0.240\n",
            "[Epoch 49, Step  1430] loss: 0.426\n",
            "[Epoch 49, Step  1440] loss: 0.186\n",
            "[Epoch 49, Step  1450] loss: 0.224\n",
            "[Epoch 49, Step  1460] loss: 0.034\n",
            "[Epoch 49, Step  1470] loss: 0.094\n",
            "[Epoch 49, Step  1480] loss: 0.186\n",
            "[Epoch 49, Step  1490] loss: 0.181\n",
            "[Epoch 49, Step  1500] loss: 0.104\n",
            "[Epoch 49, Step  1510] loss: 0.288\n",
            "[Epoch 49, Step  1520] loss: 0.084\n",
            "[Epoch 49, Step  1530] loss: 0.340\n",
            "[Epoch 49, Step  1540] loss: 0.456\n",
            "[Epoch 49, Step  1550] loss: 0.078\n",
            "[Epoch 49, Step  1560] loss: 0.219\n",
            "[Epoch 49, Step  1570] loss: 0.153\n",
            "[Epoch 49, Step  1580] loss: 0.109\n",
            "[Epoch 49, Step  1590] loss: 0.641\n",
            "[Epoch 49, Step  1600] loss: 0.284\n",
            "[Epoch 50, Step    10] loss: 0.289\n",
            "[Epoch 50, Step    20] loss: 0.434\n",
            "[Epoch 50, Step    30] loss: 0.288\n",
            "[Epoch 50, Step    40] loss: 0.279\n",
            "[Epoch 50, Step    50] loss: 0.089\n",
            "[Epoch 50, Step    60] loss: 0.020\n",
            "[Epoch 50, Step    70] loss: 0.319\n",
            "[Epoch 50, Step    80] loss: 0.049\n",
            "[Epoch 50, Step    90] loss: 0.047\n",
            "[Epoch 50, Step   100] loss: 0.710\n",
            "[Epoch 50, Step   110] loss: 0.114\n",
            "[Epoch 50, Step   120] loss: 0.271\n",
            "[Epoch 50, Step   130] loss: 0.281\n",
            "[Epoch 50, Step   140] loss: 0.312\n",
            "[Epoch 50, Step   150] loss: 0.280\n",
            "[Epoch 50, Step   160] loss: 0.121\n",
            "[Epoch 50, Step   170] loss: 0.248\n",
            "[Epoch 50, Step   180] loss: 0.230\n",
            "[Epoch 50, Step   190] loss: 0.290\n",
            "[Epoch 50, Step   200] loss: 0.043\n",
            "[Epoch 50, Step   210] loss: 0.159\n",
            "[Epoch 50, Step   220] loss: 0.255\n",
            "[Epoch 50, Step   230] loss: 0.060\n",
            "[Epoch 50, Step   240] loss: 0.277\n",
            "[Epoch 50, Step   250] loss: 0.154\n",
            "[Epoch 50, Step   260] loss: 0.117\n",
            "[Epoch 50, Step   270] loss: 0.039\n",
            "[Epoch 50, Step   280] loss: 0.249\n",
            "[Epoch 50, Step   290] loss: 0.072\n",
            "[Epoch 50, Step   300] loss: 0.172\n",
            "[Epoch 50, Step   310] loss: 0.134\n",
            "[Epoch 50, Step   320] loss: 0.173\n",
            "[Epoch 50, Step   330] loss: 0.275\n",
            "[Epoch 50, Step   340] loss: 0.158\n",
            "[Epoch 50, Step   350] loss: 0.276\n",
            "[Epoch 50, Step   360] loss: 0.183\n",
            "[Epoch 50, Step   370] loss: 0.236\n",
            "[Epoch 50, Step   380] loss: 0.404\n",
            "[Epoch 50, Step   390] loss: 0.447\n",
            "[Epoch 50, Step   400] loss: 0.258\n",
            "[Epoch 50, Step   410] loss: 0.230\n",
            "[Epoch 50, Step   420] loss: 0.054\n",
            "[Epoch 50, Step   430] loss: 0.047\n",
            "[Epoch 50, Step   440] loss: 0.298\n",
            "[Epoch 50, Step   450] loss: 0.042\n",
            "[Epoch 50, Step   460] loss: 0.192\n",
            "[Epoch 50, Step   470] loss: 0.310\n",
            "[Epoch 50, Step   480] loss: 0.370\n",
            "[Epoch 50, Step   490] loss: 0.374\n",
            "[Epoch 50, Step   500] loss: 0.096\n",
            "[Epoch 50, Step   510] loss: 0.141\n",
            "[Epoch 50, Step   520] loss: 0.166\n",
            "[Epoch 50, Step   530] loss: 0.372\n",
            "[Epoch 50, Step   540] loss: 0.214\n",
            "[Epoch 50, Step   550] loss: 0.393\n",
            "[Epoch 50, Step   560] loss: 0.115\n",
            "[Epoch 50, Step   570] loss: 0.113\n",
            "[Epoch 50, Step   580] loss: 0.049\n",
            "[Epoch 50, Step   590] loss: 0.221\n",
            "[Epoch 50, Step   600] loss: 0.304\n",
            "[Epoch 50, Step   610] loss: 0.092\n",
            "[Epoch 50, Step   620] loss: 0.280\n",
            "[Epoch 50, Step   630] loss: 0.188\n",
            "[Epoch 50, Step   640] loss: 0.069\n",
            "[Epoch 50, Step   650] loss: 0.038\n",
            "[Epoch 50, Step   660] loss: 0.035\n",
            "[Epoch 50, Step   670] loss: 0.408\n",
            "[Epoch 50, Step   680] loss: 0.369\n",
            "[Epoch 50, Step   690] loss: 0.101\n",
            "[Epoch 50, Step   700] loss: 0.247\n",
            "[Epoch 50, Step   710] loss: 0.103\n",
            "[Epoch 50, Step   720] loss: 0.210\n",
            "[Epoch 50, Step   730] loss: 0.318\n",
            "[Epoch 50, Step   740] loss: 0.106\n",
            "[Epoch 50, Step   750] loss: 0.149\n",
            "[Epoch 50, Step   760] loss: 0.168\n",
            "[Epoch 50, Step   770] loss: 0.179\n",
            "[Epoch 50, Step   780] loss: 0.052\n",
            "[Epoch 50, Step   790] loss: 0.179\n",
            "[Epoch 50, Step   800] loss: 0.130\n",
            "[Epoch 50, Step   810] loss: 0.203\n",
            "[Epoch 50, Step   820] loss: 0.077\n",
            "[Epoch 50, Step   830] loss: 0.266\n",
            "[Epoch 50, Step   840] loss: 0.202\n",
            "[Epoch 50, Step   850] loss: 0.268\n",
            "[Epoch 50, Step   860] loss: 0.558\n",
            "[Epoch 50, Step   870] loss: 0.607\n",
            "[Epoch 50, Step   880] loss: 0.201\n",
            "[Epoch 50, Step   890] loss: 0.139\n",
            "[Epoch 50, Step   900] loss: 0.269\n",
            "[Epoch 50, Step   910] loss: 0.218\n",
            "[Epoch 50, Step   920] loss: 0.205\n",
            "[Epoch 50, Step   930] loss: 0.062\n",
            "[Epoch 50, Step   940] loss: 0.533\n",
            "[Epoch 50, Step   950] loss: 0.051\n",
            "[Epoch 50, Step   960] loss: 0.221\n",
            "[Epoch 50, Step   970] loss: 0.177\n",
            "[Epoch 50, Step   980] loss: 0.251\n",
            "[Epoch 50, Step   990] loss: 0.433\n",
            "[Epoch 50, Step  1000] loss: 0.010\n",
            "[Epoch 50, Step  1010] loss: 0.502\n",
            "[Epoch 50, Step  1020] loss: 0.391\n",
            "[Epoch 50, Step  1030] loss: 0.612\n",
            "[Epoch 50, Step  1040] loss: 0.132\n",
            "[Epoch 50, Step  1050] loss: 0.088\n",
            "[Epoch 50, Step  1060] loss: 0.709\n",
            "[Epoch 50, Step  1070] loss: 0.191\n",
            "[Epoch 50, Step  1080] loss: 0.254\n",
            "[Epoch 50, Step  1090] loss: 0.419\n",
            "[Epoch 50, Step  1100] loss: 0.107\n",
            "[Epoch 50, Step  1110] loss: 0.122\n",
            "[Epoch 50, Step  1120] loss: 0.321\n",
            "[Epoch 50, Step  1130] loss: 0.258\n",
            "[Epoch 50, Step  1140] loss: 0.271\n",
            "[Epoch 50, Step  1150] loss: 0.293\n",
            "[Epoch 50, Step  1160] loss: 0.079\n",
            "[Epoch 50, Step  1170] loss: 0.040\n",
            "[Epoch 50, Step  1180] loss: 0.249\n",
            "[Epoch 50, Step  1190] loss: 0.121\n",
            "[Epoch 50, Step  1200] loss: 0.261\n",
            "[Epoch 50, Step  1210] loss: 0.472\n",
            "[Epoch 50, Step  1220] loss: 0.273\n",
            "[Epoch 50, Step  1230] loss: 0.267\n",
            "[Epoch 50, Step  1240] loss: 0.362\n",
            "[Epoch 50, Step  1250] loss: 0.308\n",
            "[Epoch 50, Step  1260] loss: 0.257\n",
            "[Epoch 50, Step  1270] loss: 0.206\n",
            "[Epoch 50, Step  1280] loss: 0.177\n",
            "[Epoch 50, Step  1290] loss: 0.128\n",
            "[Epoch 50, Step  1300] loss: 0.161\n",
            "[Epoch 50, Step  1310] loss: 0.229\n",
            "[Epoch 50, Step  1320] loss: 0.152\n",
            "[Epoch 50, Step  1330] loss: 0.122\n",
            "[Epoch 50, Step  1340] loss: 0.542\n",
            "[Epoch 50, Step  1350] loss: 0.048\n",
            "[Epoch 50, Step  1360] loss: 0.598\n",
            "[Epoch 50, Step  1370] loss: 0.212\n",
            "[Epoch 50, Step  1380] loss: 0.095\n",
            "[Epoch 50, Step  1390] loss: 0.281\n",
            "[Epoch 50, Step  1400] loss: 0.028\n",
            "[Epoch 50, Step  1410] loss: 0.167\n",
            "[Epoch 50, Step  1420] loss: 0.034\n",
            "[Epoch 50, Step  1430] loss: 0.057\n",
            "[Epoch 50, Step  1440] loss: 0.008\n",
            "[Epoch 50, Step  1450] loss: 0.375\n",
            "[Epoch 50, Step  1460] loss: 0.180\n",
            "[Epoch 50, Step  1470] loss: 0.126\n",
            "[Epoch 50, Step  1480] loss: 0.147\n",
            "[Epoch 50, Step  1490] loss: 0.348\n",
            "[Epoch 50, Step  1500] loss: 0.175\n",
            "[Epoch 50, Step  1510] loss: 0.380\n",
            "[Epoch 50, Step  1520] loss: 0.158\n",
            "[Epoch 50, Step  1530] loss: 0.065\n",
            "[Epoch 50, Step  1540] loss: 0.133\n",
            "[Epoch 50, Step  1550] loss: 0.063\n",
            "[Epoch 50, Step  1560] loss: 0.052\n",
            "[Epoch 50, Step  1570] loss: 0.140\n",
            "[Epoch 50, Step  1580] loss: 0.217\n",
            "[Epoch 50, Step  1590] loss: 0.056\n",
            "[Epoch 50, Step  1600] loss: 0.124\n",
            "Finished Training\n",
            "F1 Score: 0.87\n",
            "Classification Report:\n",
            "               precision    recall  f1-score   support\n",
            "\n",
            "         0.0       0.89      0.91      0.90       263\n",
            "         1.0       0.83      0.79      0.81       138\n",
            "\n",
            "    accuracy                           0.87       401\n",
            "   macro avg       0.86      0.85      0.85       401\n",
            "weighted avg       0.87      0.87      0.87       401\n",
            "\n",
            "Cross Val f1\n",
            "0.861494874801138\n",
            "Cross Val Accuracy\n",
            "0.8623441396508728\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Confusion matrix"
      ],
      "metadata": {
        "id": "hwnheI0u3mdf"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "from sklearn.metrics import confusion_matrix\n",
        "\n",
        "hidden_size = 10\n",
        "lr = 0.001\n",
        "epochs = 100\n",
        "criterion = nn.BCELoss()\n",
        "\n",
        "\n",
        "bestMLP = ShallowMLP(hidden_size)\n",
        "optimizer = torch.optim.Adam(bestMLP.parameters(), lr=lr)\n",
        "train(model = bestMLP, optimizer = optimizer, criterion = criterion ,learning_rate = lr, n_epochs = epochs, trainloader = ktrain_loader, device = device, printbool = True)\n",
        "\n",
        "_, _, conf_matrix_mlp = eval(model = bestMLP,testloader = testloader, device = device)\n",
        "\n",
        "#plot confusion\n",
        "labels = ['No Metabolic Syndrome', 'Has Metabolic Syndrome']\n",
        "plt.figure(figsize=(8, 6))\n",
        "sns.heatmap(conf_matrix_mlp, annot=True, fmt='g', cmap='Blues', xticklabels=labels, yticklabels=labels)\n",
        "plt.xlabel('Predicted labels')\n",
        "plt.ylabel('True labels')\n",
        "plt.title('Confusion Matrix')\n",
        "plt.show()\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "iKnEPIeEyTPW",
        "outputId": "88fd2fb9-a78b-4586-ee96-f102c67b63d3"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1;30;43mStreaming output truncated to the last 5000 lines.\u001b[0m\n",
            "[Epoch 69, Step  1330] loss: 0.349\n",
            "[Epoch 69, Step  1340] loss: 0.238\n",
            "[Epoch 69, Step  1350] loss: 0.214\n",
            "[Epoch 69, Step  1360] loss: 0.094\n",
            "[Epoch 69, Step  1370] loss: 0.098\n",
            "[Epoch 69, Step  1380] loss: 0.249\n",
            "[Epoch 69, Step  1390] loss: 0.247\n",
            "[Epoch 69, Step  1400] loss: 0.118\n",
            "[Epoch 69, Step  1410] loss: 0.271\n",
            "[Epoch 69, Step  1420] loss: 0.111\n",
            "[Epoch 69, Step  1430] loss: 0.411\n",
            "[Epoch 69, Step  1440] loss: 0.421\n",
            "[Epoch 69, Step  1450] loss: 0.081\n",
            "[Epoch 69, Step  1460] loss: 0.132\n",
            "[Epoch 69, Step  1470] loss: 0.370\n",
            "[Epoch 69, Step  1480] loss: 0.226\n",
            "[Epoch 69, Step  1490] loss: 0.233\n",
            "[Epoch 69, Step  1500] loss: 0.428\n",
            "[Epoch 69, Step  1510] loss: 0.494\n",
            "[Epoch 69, Step  1520] loss: 0.122\n",
            "[Epoch 69, Step  1530] loss: 0.019\n",
            "[Epoch 69, Step  1540] loss: 0.132\n",
            "[Epoch 69, Step  1550] loss: 0.237\n",
            "[Epoch 69, Step  1560] loss: 0.126\n",
            "[Epoch 69, Step  1570] loss: 0.209\n",
            "[Epoch 69, Step  1580] loss: 0.204\n",
            "[Epoch 69, Step  1590] loss: 0.209\n",
            "[Epoch 69, Step  1600] loss: 0.299\n",
            "[Epoch 70, Step    10] loss: 0.146\n",
            "[Epoch 70, Step    20] loss: 0.183\n",
            "[Epoch 70, Step    30] loss: 0.083\n",
            "[Epoch 70, Step    40] loss: 0.136\n",
            "[Epoch 70, Step    50] loss: 0.343\n",
            "[Epoch 70, Step    60] loss: 0.460\n",
            "[Epoch 70, Step    70] loss: 0.188\n",
            "[Epoch 70, Step    80] loss: 0.113\n",
            "[Epoch 70, Step    90] loss: 0.107\n",
            "[Epoch 70, Step   100] loss: 0.093\n",
            "[Epoch 70, Step   110] loss: 0.231\n",
            "[Epoch 70, Step   120] loss: 0.498\n",
            "[Epoch 70, Step   130] loss: 0.187\n",
            "[Epoch 70, Step   140] loss: 0.466\n",
            "[Epoch 70, Step   150] loss: 0.027\n",
            "[Epoch 70, Step   160] loss: 0.087\n",
            "[Epoch 70, Step   170] loss: 0.240\n",
            "[Epoch 70, Step   180] loss: 0.163\n",
            "[Epoch 70, Step   190] loss: 0.162\n",
            "[Epoch 70, Step   200] loss: 0.168\n",
            "[Epoch 70, Step   210] loss: 0.375\n",
            "[Epoch 70, Step   220] loss: 0.200\n",
            "[Epoch 70, Step   230] loss: 0.376\n",
            "[Epoch 70, Step   240] loss: 0.211\n",
            "[Epoch 70, Step   250] loss: 0.304\n",
            "[Epoch 70, Step   260] loss: 0.223\n",
            "[Epoch 70, Step   270] loss: 0.121\n",
            "[Epoch 70, Step   280] loss: 0.106\n",
            "[Epoch 70, Step   290] loss: 0.536\n",
            "[Epoch 70, Step   300] loss: 0.048\n",
            "[Epoch 70, Step   310] loss: 0.200\n",
            "[Epoch 70, Step   320] loss: 0.419\n",
            "[Epoch 70, Step   330] loss: 0.183\n",
            "[Epoch 70, Step   340] loss: 0.132\n",
            "[Epoch 70, Step   350] loss: 0.147\n",
            "[Epoch 70, Step   360] loss: 0.236\n",
            "[Epoch 70, Step   370] loss: 0.107\n",
            "[Epoch 70, Step   380] loss: 0.232\n",
            "[Epoch 70, Step   390] loss: 0.131\n",
            "[Epoch 70, Step   400] loss: 0.031\n",
            "[Epoch 70, Step   410] loss: 0.081\n",
            "[Epoch 70, Step   420] loss: 0.452\n",
            "[Epoch 70, Step   430] loss: 0.125\n",
            "[Epoch 70, Step   440] loss: 0.110\n",
            "[Epoch 70, Step   450] loss: 0.378\n",
            "[Epoch 70, Step   460] loss: 0.348\n",
            "[Epoch 70, Step   470] loss: 0.456\n",
            "[Epoch 70, Step   480] loss: 0.184\n",
            "[Epoch 70, Step   490] loss: 0.355\n",
            "[Epoch 70, Step   500] loss: 0.254\n",
            "[Epoch 70, Step   510] loss: 0.145\n",
            "[Epoch 70, Step   520] loss: 0.097\n",
            "[Epoch 70, Step   530] loss: 0.280\n",
            "[Epoch 70, Step   540] loss: 0.016\n",
            "[Epoch 70, Step   550] loss: 0.086\n",
            "[Epoch 70, Step   560] loss: 0.129\n",
            "[Epoch 70, Step   570] loss: 0.380\n",
            "[Epoch 70, Step   580] loss: 0.230\n",
            "[Epoch 70, Step   590] loss: 0.177\n",
            "[Epoch 70, Step   600] loss: 0.049\n",
            "[Epoch 70, Step   610] loss: 0.237\n",
            "[Epoch 70, Step   620] loss: 0.100\n",
            "[Epoch 70, Step   630] loss: 0.126\n",
            "[Epoch 70, Step   640] loss: 0.225\n",
            "[Epoch 70, Step   650] loss: 0.251\n",
            "[Epoch 70, Step   660] loss: 0.311\n",
            "[Epoch 70, Step   670] loss: 0.476\n",
            "[Epoch 70, Step   680] loss: 0.195\n",
            "[Epoch 70, Step   690] loss: 0.193\n",
            "[Epoch 70, Step   700] loss: 0.141\n",
            "[Epoch 70, Step   710] loss: 0.412\n",
            "[Epoch 70, Step   720] loss: 0.095\n",
            "[Epoch 70, Step   730] loss: 0.344\n",
            "[Epoch 70, Step   740] loss: 0.250\n",
            "[Epoch 70, Step   750] loss: 0.244\n",
            "[Epoch 70, Step   760] loss: 0.094\n",
            "[Epoch 70, Step   770] loss: 0.201\n",
            "[Epoch 70, Step   780] loss: 0.179\n",
            "[Epoch 70, Step   790] loss: 0.133\n",
            "[Epoch 70, Step   800] loss: 0.192\n",
            "[Epoch 70, Step   810] loss: 0.153\n",
            "[Epoch 70, Step   820] loss: 0.247\n",
            "[Epoch 70, Step   830] loss: 0.098\n",
            "[Epoch 70, Step   840] loss: 0.235\n",
            "[Epoch 70, Step   850] loss: 0.213\n",
            "[Epoch 70, Step   860] loss: 0.089\n",
            "[Epoch 70, Step   870] loss: 0.949\n",
            "[Epoch 70, Step   880] loss: 0.246\n",
            "[Epoch 70, Step   890] loss: 0.345\n",
            "[Epoch 70, Step   900] loss: 0.035\n",
            "[Epoch 70, Step   910] loss: 0.317\n",
            "[Epoch 70, Step   920] loss: 0.137\n",
            "[Epoch 70, Step   930] loss: 0.031\n",
            "[Epoch 70, Step   940] loss: 0.169\n",
            "[Epoch 70, Step   950] loss: 0.373\n",
            "[Epoch 70, Step   960] loss: 0.254\n",
            "[Epoch 70, Step   970] loss: 0.466\n",
            "[Epoch 70, Step   980] loss: 0.203\n",
            "[Epoch 70, Step   990] loss: 0.248\n",
            "[Epoch 70, Step  1000] loss: 0.026\n",
            "[Epoch 70, Step  1010] loss: 0.129\n",
            "[Epoch 70, Step  1020] loss: 0.219\n",
            "[Epoch 70, Step  1030] loss: 0.596\n",
            "[Epoch 70, Step  1040] loss: 0.369\n",
            "[Epoch 70, Step  1050] loss: 0.201\n",
            "[Epoch 70, Step  1060] loss: 0.053\n",
            "[Epoch 70, Step  1070] loss: 0.309\n",
            "[Epoch 70, Step  1080] loss: 0.054\n",
            "[Epoch 70, Step  1090] loss: 0.179\n",
            "[Epoch 70, Step  1100] loss: 0.232\n",
            "[Epoch 70, Step  1110] loss: 0.099\n",
            "[Epoch 70, Step  1120] loss: 0.512\n",
            "[Epoch 70, Step  1130] loss: 0.358\n",
            "[Epoch 70, Step  1140] loss: 0.367\n",
            "[Epoch 70, Step  1150] loss: 0.258\n",
            "[Epoch 70, Step  1160] loss: 0.484\n",
            "[Epoch 70, Step  1170] loss: 0.549\n",
            "[Epoch 70, Step  1180] loss: 0.143\n",
            "[Epoch 70, Step  1190] loss: 0.069\n",
            "[Epoch 70, Step  1200] loss: 0.265\n",
            "[Epoch 70, Step  1210] loss: 0.280\n",
            "[Epoch 70, Step  1220] loss: 0.205\n",
            "[Epoch 70, Step  1230] loss: 0.397\n",
            "[Epoch 70, Step  1240] loss: 0.227\n",
            "[Epoch 70, Step  1250] loss: 0.120\n",
            "[Epoch 70, Step  1260] loss: 0.324\n",
            "[Epoch 70, Step  1270] loss: 0.460\n",
            "[Epoch 70, Step  1280] loss: 0.113\n",
            "[Epoch 70, Step  1290] loss: 0.117\n",
            "[Epoch 70, Step  1300] loss: 0.537\n",
            "[Epoch 70, Step  1310] loss: 0.192\n",
            "[Epoch 70, Step  1320] loss: 0.411\n",
            "[Epoch 70, Step  1330] loss: 0.169\n",
            "[Epoch 70, Step  1340] loss: 0.144\n",
            "[Epoch 70, Step  1350] loss: 0.704\n",
            "[Epoch 70, Step  1360] loss: 0.181\n",
            "[Epoch 70, Step  1370] loss: 0.273\n",
            "[Epoch 70, Step  1380] loss: 0.314\n",
            "[Epoch 70, Step  1390] loss: 0.075\n",
            "[Epoch 70, Step  1400] loss: 0.367\n",
            "[Epoch 70, Step  1410] loss: 0.045\n",
            "[Epoch 70, Step  1420] loss: 0.267\n",
            "[Epoch 70, Step  1430] loss: 0.328\n",
            "[Epoch 70, Step  1440] loss: 0.167\n",
            "[Epoch 70, Step  1450] loss: 0.347\n",
            "[Epoch 70, Step  1460] loss: 0.260\n",
            "[Epoch 70, Step  1470] loss: 0.211\n",
            "[Epoch 70, Step  1480] loss: 0.050\n",
            "[Epoch 70, Step  1490] loss: 0.030\n",
            "[Epoch 70, Step  1500] loss: 0.393\n",
            "[Epoch 70, Step  1510] loss: 0.279\n",
            "[Epoch 70, Step  1520] loss: 0.131\n",
            "[Epoch 70, Step  1530] loss: 0.446\n",
            "[Epoch 70, Step  1540] loss: 0.176\n",
            "[Epoch 70, Step  1550] loss: 0.148\n",
            "[Epoch 70, Step  1560] loss: 0.248\n",
            "[Epoch 70, Step  1570] loss: 0.076\n",
            "[Epoch 70, Step  1580] loss: 0.136\n",
            "[Epoch 70, Step  1590] loss: 0.777\n",
            "[Epoch 70, Step  1600] loss: 0.458\n",
            "[Epoch 71, Step    10] loss: 0.146\n",
            "[Epoch 71, Step    20] loss: 0.310\n",
            "[Epoch 71, Step    30] loss: 0.076\n",
            "[Epoch 71, Step    40] loss: 0.194\n",
            "[Epoch 71, Step    50] loss: 0.349\n",
            "[Epoch 71, Step    60] loss: 0.068\n",
            "[Epoch 71, Step    70] loss: 0.074\n",
            "[Epoch 71, Step    80] loss: 0.116\n",
            "[Epoch 71, Step    90] loss: 0.129\n",
            "[Epoch 71, Step   100] loss: 0.111\n",
            "[Epoch 71, Step   110] loss: 0.304\n",
            "[Epoch 71, Step   120] loss: 0.274\n",
            "[Epoch 71, Step   130] loss: 0.409\n",
            "[Epoch 71, Step   140] loss: 0.149\n",
            "[Epoch 71, Step   150] loss: 0.141\n",
            "[Epoch 71, Step   160] loss: 0.113\n",
            "[Epoch 71, Step   170] loss: 0.264\n",
            "[Epoch 71, Step   180] loss: 0.104\n",
            "[Epoch 71, Step   190] loss: 0.100\n",
            "[Epoch 71, Step   200] loss: 0.128\n",
            "[Epoch 71, Step   210] loss: 0.062\n",
            "[Epoch 71, Step   220] loss: 0.322\n",
            "[Epoch 71, Step   230] loss: 0.640\n",
            "[Epoch 71, Step   240] loss: 0.078\n",
            "[Epoch 71, Step   250] loss: 0.341\n",
            "[Epoch 71, Step   260] loss: 0.129\n",
            "[Epoch 71, Step   270] loss: 0.631\n",
            "[Epoch 71, Step   280] loss: 0.497\n",
            "[Epoch 71, Step   290] loss: 0.327\n",
            "[Epoch 71, Step   300] loss: 0.242\n",
            "[Epoch 71, Step   310] loss: 0.273\n",
            "[Epoch 71, Step   320] loss: 0.471\n",
            "[Epoch 71, Step   330] loss: 0.282\n",
            "[Epoch 71, Step   340] loss: 0.199\n",
            "[Epoch 71, Step   350] loss: 0.325\n",
            "[Epoch 71, Step   360] loss: 0.041\n",
            "[Epoch 71, Step   370] loss: 0.323\n",
            "[Epoch 71, Step   380] loss: 0.144\n",
            "[Epoch 71, Step   390] loss: 0.707\n",
            "[Epoch 71, Step   400] loss: 0.277\n",
            "[Epoch 71, Step   410] loss: 0.117\n",
            "[Epoch 71, Step   420] loss: 0.141\n",
            "[Epoch 71, Step   430] loss: 0.632\n",
            "[Epoch 71, Step   440] loss: 0.234\n",
            "[Epoch 71, Step   450] loss: 0.234\n",
            "[Epoch 71, Step   460] loss: 0.087\n",
            "[Epoch 71, Step   470] loss: 0.162\n",
            "[Epoch 71, Step   480] loss: 0.218\n",
            "[Epoch 71, Step   490] loss: 0.160\n",
            "[Epoch 71, Step   500] loss: 0.170\n",
            "[Epoch 71, Step   510] loss: 0.320\n",
            "[Epoch 71, Step   520] loss: 0.183\n",
            "[Epoch 71, Step   530] loss: 0.264\n",
            "[Epoch 71, Step   540] loss: 0.155\n",
            "[Epoch 71, Step   550] loss: 0.134\n",
            "[Epoch 71, Step   560] loss: 0.177\n",
            "[Epoch 71, Step   570] loss: 0.099\n",
            "[Epoch 71, Step   580] loss: 0.238\n",
            "[Epoch 71, Step   590] loss: 0.327\n",
            "[Epoch 71, Step   600] loss: 0.174\n",
            "[Epoch 71, Step   610] loss: 0.153\n",
            "[Epoch 71, Step   620] loss: 0.228\n",
            "[Epoch 71, Step   630] loss: 0.276\n",
            "[Epoch 71, Step   640] loss: 0.095\n",
            "[Epoch 71, Step   650] loss: 0.339\n",
            "[Epoch 71, Step   660] loss: 0.301\n",
            "[Epoch 71, Step   670] loss: 0.202\n",
            "[Epoch 71, Step   680] loss: 0.225\n",
            "[Epoch 71, Step   690] loss: 0.230\n",
            "[Epoch 71, Step   700] loss: 0.655\n",
            "[Epoch 71, Step   710] loss: 0.045\n",
            "[Epoch 71, Step   720] loss: 0.153\n",
            "[Epoch 71, Step   730] loss: 0.126\n",
            "[Epoch 71, Step   740] loss: 0.104\n",
            "[Epoch 71, Step   750] loss: 0.101\n",
            "[Epoch 71, Step   760] loss: 0.135\n",
            "[Epoch 71, Step   770] loss: 0.305\n",
            "[Epoch 71, Step   780] loss: 0.183\n",
            "[Epoch 71, Step   790] loss: 0.187\n",
            "[Epoch 71, Step   800] loss: 0.479\n",
            "[Epoch 71, Step   810] loss: 0.343\n",
            "[Epoch 71, Step   820] loss: 0.153\n",
            "[Epoch 71, Step   830] loss: 0.174\n",
            "[Epoch 71, Step   840] loss: 0.038\n",
            "[Epoch 71, Step   850] loss: 0.049\n",
            "[Epoch 71, Step   860] loss: 0.067\n",
            "[Epoch 71, Step   870] loss: 0.269\n",
            "[Epoch 71, Step   880] loss: 0.169\n",
            "[Epoch 71, Step   890] loss: 0.210\n",
            "[Epoch 71, Step   900] loss: 0.329\n",
            "[Epoch 71, Step   910] loss: 0.165\n",
            "[Epoch 71, Step   920] loss: 0.342\n",
            "[Epoch 71, Step   930] loss: 0.239\n",
            "[Epoch 71, Step   940] loss: 0.097\n",
            "[Epoch 71, Step   950] loss: 0.086\n",
            "[Epoch 71, Step   960] loss: 0.350\n",
            "[Epoch 71, Step   970] loss: 0.193\n",
            "[Epoch 71, Step   980] loss: 0.122\n",
            "[Epoch 71, Step   990] loss: 0.020\n",
            "[Epoch 71, Step  1000] loss: 0.181\n",
            "[Epoch 71, Step  1010] loss: 0.327\n",
            "[Epoch 71, Step  1020] loss: 0.196\n",
            "[Epoch 71, Step  1030] loss: 0.208\n",
            "[Epoch 71, Step  1040] loss: 0.300\n",
            "[Epoch 71, Step  1050] loss: 0.867\n",
            "[Epoch 71, Step  1060] loss: 0.236\n",
            "[Epoch 71, Step  1070] loss: 0.174\n",
            "[Epoch 71, Step  1080] loss: 0.096\n",
            "[Epoch 71, Step  1090] loss: 0.142\n",
            "[Epoch 71, Step  1100] loss: 0.382\n",
            "[Epoch 71, Step  1110] loss: 0.112\n",
            "[Epoch 71, Step  1120] loss: 0.144\n",
            "[Epoch 71, Step  1130] loss: 0.500\n",
            "[Epoch 71, Step  1140] loss: 0.034\n",
            "[Epoch 71, Step  1150] loss: 0.453\n",
            "[Epoch 71, Step  1160] loss: 0.011\n",
            "[Epoch 71, Step  1170] loss: 0.090\n",
            "[Epoch 71, Step  1180] loss: 0.057\n",
            "[Epoch 71, Step  1190] loss: 0.212\n",
            "[Epoch 71, Step  1200] loss: 0.134\n",
            "[Epoch 71, Step  1210] loss: 0.116\n",
            "[Epoch 71, Step  1220] loss: 0.353\n",
            "[Epoch 71, Step  1230] loss: 0.408\n",
            "[Epoch 71, Step  1240] loss: 0.340\n",
            "[Epoch 71, Step  1250] loss: 0.312\n",
            "[Epoch 71, Step  1260] loss: 0.431\n",
            "[Epoch 71, Step  1270] loss: 0.083\n",
            "[Epoch 71, Step  1280] loss: 0.290\n",
            "[Epoch 71, Step  1290] loss: 0.435\n",
            "[Epoch 71, Step  1300] loss: 0.198\n",
            "[Epoch 71, Step  1310] loss: 0.220\n",
            "[Epoch 71, Step  1320] loss: 0.093\n",
            "[Epoch 71, Step  1330] loss: 0.370\n",
            "[Epoch 71, Step  1340] loss: 0.255\n",
            "[Epoch 71, Step  1350] loss: 0.068\n",
            "[Epoch 71, Step  1360] loss: 0.312\n",
            "[Epoch 71, Step  1370] loss: 0.075\n",
            "[Epoch 71, Step  1380] loss: 0.335\n",
            "[Epoch 71, Step  1390] loss: 0.102\n",
            "[Epoch 71, Step  1400] loss: 0.315\n",
            "[Epoch 71, Step  1410] loss: 0.837\n",
            "[Epoch 71, Step  1420] loss: 0.300\n",
            "[Epoch 71, Step  1430] loss: 0.212\n",
            "[Epoch 71, Step  1440] loss: 0.143\n",
            "[Epoch 71, Step  1450] loss: 0.405\n",
            "[Epoch 71, Step  1460] loss: 0.044\n",
            "[Epoch 71, Step  1470] loss: 0.264\n",
            "[Epoch 71, Step  1480] loss: 0.672\n",
            "[Epoch 71, Step  1490] loss: 0.110\n",
            "[Epoch 71, Step  1500] loss: 0.473\n",
            "[Epoch 71, Step  1510] loss: 0.166\n",
            "[Epoch 71, Step  1520] loss: 0.188\n",
            "[Epoch 71, Step  1530] loss: 0.064\n",
            "[Epoch 71, Step  1540] loss: 0.229\n",
            "[Epoch 71, Step  1550] loss: 0.299\n",
            "[Epoch 71, Step  1560] loss: 0.562\n",
            "[Epoch 71, Step  1570] loss: 0.343\n",
            "[Epoch 71, Step  1580] loss: 0.205\n",
            "[Epoch 71, Step  1590] loss: 0.189\n",
            "[Epoch 71, Step  1600] loss: 0.067\n",
            "[Epoch 72, Step    10] loss: 0.120\n",
            "[Epoch 72, Step    20] loss: 0.221\n",
            "[Epoch 72, Step    30] loss: 0.304\n",
            "[Epoch 72, Step    40] loss: 0.214\n",
            "[Epoch 72, Step    50] loss: 0.176\n",
            "[Epoch 72, Step    60] loss: 0.229\n",
            "[Epoch 72, Step    70] loss: 0.246\n",
            "[Epoch 72, Step    80] loss: 0.115\n",
            "[Epoch 72, Step    90] loss: 0.287\n",
            "[Epoch 72, Step   100] loss: 0.373\n",
            "[Epoch 72, Step   110] loss: 0.388\n",
            "[Epoch 72, Step   120] loss: 0.291\n",
            "[Epoch 72, Step   130] loss: 0.095\n",
            "[Epoch 72, Step   140] loss: 0.370\n",
            "[Epoch 72, Step   150] loss: 0.182\n",
            "[Epoch 72, Step   160] loss: 0.251\n",
            "[Epoch 72, Step   170] loss: 0.254\n",
            "[Epoch 72, Step   180] loss: 0.403\n",
            "[Epoch 72, Step   190] loss: 0.652\n",
            "[Epoch 72, Step   200] loss: 0.156\n",
            "[Epoch 72, Step   210] loss: 0.539\n",
            "[Epoch 72, Step   220] loss: 0.413\n",
            "[Epoch 72, Step   230] loss: 0.343\n",
            "[Epoch 72, Step   240] loss: 0.208\n",
            "[Epoch 72, Step   250] loss: 0.292\n",
            "[Epoch 72, Step   260] loss: 0.226\n",
            "[Epoch 72, Step   270] loss: 0.287\n",
            "[Epoch 72, Step   280] loss: 0.127\n",
            "[Epoch 72, Step   290] loss: 0.080\n",
            "[Epoch 72, Step   300] loss: 0.226\n",
            "[Epoch 72, Step   310] loss: 0.300\n",
            "[Epoch 72, Step   320] loss: 0.069\n",
            "[Epoch 72, Step   330] loss: 0.030\n",
            "[Epoch 72, Step   340] loss: 0.101\n",
            "[Epoch 72, Step   350] loss: 0.168\n",
            "[Epoch 72, Step   360] loss: 0.082\n",
            "[Epoch 72, Step   370] loss: 0.128\n",
            "[Epoch 72, Step   380] loss: 0.199\n",
            "[Epoch 72, Step   390] loss: 0.074\n",
            "[Epoch 72, Step   400] loss: 0.030\n",
            "[Epoch 72, Step   410] loss: 0.129\n",
            "[Epoch 72, Step   420] loss: 0.430\n",
            "[Epoch 72, Step   430] loss: 0.188\n",
            "[Epoch 72, Step   440] loss: 0.115\n",
            "[Epoch 72, Step   450] loss: 0.235\n",
            "[Epoch 72, Step   460] loss: 0.160\n",
            "[Epoch 72, Step   470] loss: 0.189\n",
            "[Epoch 72, Step   480] loss: 0.149\n",
            "[Epoch 72, Step   490] loss: 0.056\n",
            "[Epoch 72, Step   500] loss: 0.178\n",
            "[Epoch 72, Step   510] loss: 0.724\n",
            "[Epoch 72, Step   520] loss: 0.338\n",
            "[Epoch 72, Step   530] loss: 0.091\n",
            "[Epoch 72, Step   540] loss: 0.129\n",
            "[Epoch 72, Step   550] loss: 0.255\n",
            "[Epoch 72, Step   560] loss: 0.572\n",
            "[Epoch 72, Step   570] loss: 0.014\n",
            "[Epoch 72, Step   580] loss: 0.191\n",
            "[Epoch 72, Step   590] loss: 0.114\n",
            "[Epoch 72, Step   600] loss: 0.128\n",
            "[Epoch 72, Step   610] loss: 0.206\n",
            "[Epoch 72, Step   620] loss: 0.132\n",
            "[Epoch 72, Step   630] loss: 0.098\n",
            "[Epoch 72, Step   640] loss: 0.348\n",
            "[Epoch 72, Step   650] loss: 0.310\n",
            "[Epoch 72, Step   660] loss: 0.426\n",
            "[Epoch 72, Step   670] loss: 0.133\n",
            "[Epoch 72, Step   680] loss: 0.079\n",
            "[Epoch 72, Step   690] loss: 0.071\n",
            "[Epoch 72, Step   700] loss: 0.151\n",
            "[Epoch 72, Step   710] loss: 0.191\n",
            "[Epoch 72, Step   720] loss: 0.096\n",
            "[Epoch 72, Step   730] loss: 0.060\n",
            "[Epoch 72, Step   740] loss: 0.473\n",
            "[Epoch 72, Step   750] loss: 0.191\n",
            "[Epoch 72, Step   760] loss: 0.347\n",
            "[Epoch 72, Step   770] loss: 0.041\n",
            "[Epoch 72, Step   780] loss: 0.027\n",
            "[Epoch 72, Step   790] loss: 0.179\n",
            "[Epoch 72, Step   800] loss: 0.083\n",
            "[Epoch 72, Step   810] loss: 0.236\n",
            "[Epoch 72, Step   820] loss: 0.130\n",
            "[Epoch 72, Step   830] loss: 0.070\n",
            "[Epoch 72, Step   840] loss: 0.134\n",
            "[Epoch 72, Step   850] loss: 0.356\n",
            "[Epoch 72, Step   860] loss: 0.264\n",
            "[Epoch 72, Step   870] loss: 0.142\n",
            "[Epoch 72, Step   880] loss: 0.494\n",
            "[Epoch 72, Step   890] loss: 0.352\n",
            "[Epoch 72, Step   900] loss: 0.250\n",
            "[Epoch 72, Step   910] loss: 0.257\n",
            "[Epoch 72, Step   920] loss: 0.347\n",
            "[Epoch 72, Step   930] loss: 0.217\n",
            "[Epoch 72, Step   940] loss: 0.433\n",
            "[Epoch 72, Step   950] loss: 0.099\n",
            "[Epoch 72, Step   960] loss: 0.289\n",
            "[Epoch 72, Step   970] loss: 0.309\n",
            "[Epoch 72, Step   980] loss: 0.180\n",
            "[Epoch 72, Step   990] loss: 0.142\n",
            "[Epoch 72, Step  1000] loss: 0.074\n",
            "[Epoch 72, Step  1010] loss: 0.254\n",
            "[Epoch 72, Step  1020] loss: 0.344\n",
            "[Epoch 72, Step  1030] loss: 0.030\n",
            "[Epoch 72, Step  1040] loss: 0.440\n",
            "[Epoch 72, Step  1050] loss: 0.054\n",
            "[Epoch 72, Step  1060] loss: 0.164\n",
            "[Epoch 72, Step  1070] loss: 0.457\n",
            "[Epoch 72, Step  1080] loss: 0.257\n",
            "[Epoch 72, Step  1090] loss: 0.144\n",
            "[Epoch 72, Step  1100] loss: 0.179\n",
            "[Epoch 72, Step  1110] loss: 0.352\n",
            "[Epoch 72, Step  1120] loss: 0.303\n",
            "[Epoch 72, Step  1130] loss: 0.320\n",
            "[Epoch 72, Step  1140] loss: 0.205\n",
            "[Epoch 72, Step  1150] loss: 0.310\n",
            "[Epoch 72, Step  1160] loss: 0.114\n",
            "[Epoch 72, Step  1170] loss: 0.249\n",
            "[Epoch 72, Step  1180] loss: 0.218\n",
            "[Epoch 72, Step  1190] loss: 0.188\n",
            "[Epoch 72, Step  1200] loss: 0.253\n",
            "[Epoch 72, Step  1210] loss: 0.216\n",
            "[Epoch 72, Step  1220] loss: 0.368\n",
            "[Epoch 72, Step  1230] loss: 0.239\n",
            "[Epoch 72, Step  1240] loss: 0.548\n",
            "[Epoch 72, Step  1250] loss: 0.302\n",
            "[Epoch 72, Step  1260] loss: 0.272\n",
            "[Epoch 72, Step  1270] loss: 0.172\n",
            "[Epoch 72, Step  1280] loss: 0.696\n",
            "[Epoch 72, Step  1290] loss: 0.151\n",
            "[Epoch 72, Step  1300] loss: 0.288\n",
            "[Epoch 72, Step  1310] loss: 0.115\n",
            "[Epoch 72, Step  1320] loss: 0.459\n",
            "[Epoch 72, Step  1330] loss: 0.036\n",
            "[Epoch 72, Step  1340] loss: 0.208\n",
            "[Epoch 72, Step  1350] loss: 0.688\n",
            "[Epoch 72, Step  1360] loss: 0.138\n",
            "[Epoch 72, Step  1370] loss: 0.122\n",
            "[Epoch 72, Step  1380] loss: 0.124\n",
            "[Epoch 72, Step  1390] loss: 0.093\n",
            "[Epoch 72, Step  1400] loss: 0.061\n",
            "[Epoch 72, Step  1410] loss: 0.655\n",
            "[Epoch 72, Step  1420] loss: 0.179\n",
            "[Epoch 72, Step  1430] loss: 0.083\n",
            "[Epoch 72, Step  1440] loss: 0.123\n",
            "[Epoch 72, Step  1450] loss: 0.069\n",
            "[Epoch 72, Step  1460] loss: 0.064\n",
            "[Epoch 72, Step  1470] loss: 0.265\n",
            "[Epoch 72, Step  1480] loss: 0.214\n",
            "[Epoch 72, Step  1490] loss: 0.251\n",
            "[Epoch 72, Step  1500] loss: 0.913\n",
            "[Epoch 72, Step  1510] loss: 0.153\n",
            "[Epoch 72, Step  1520] loss: 0.402\n",
            "[Epoch 72, Step  1530] loss: 0.470\n",
            "[Epoch 72, Step  1540] loss: 0.152\n",
            "[Epoch 72, Step  1550] loss: 0.336\n",
            "[Epoch 72, Step  1560] loss: 0.087\n",
            "[Epoch 72, Step  1570] loss: 0.236\n",
            "[Epoch 72, Step  1580] loss: 0.227\n",
            "[Epoch 72, Step  1590] loss: 0.294\n",
            "[Epoch 72, Step  1600] loss: 0.482\n",
            "[Epoch 73, Step    10] loss: 0.125\n",
            "[Epoch 73, Step    20] loss: 0.345\n",
            "[Epoch 73, Step    30] loss: 0.077\n",
            "[Epoch 73, Step    40] loss: 0.209\n",
            "[Epoch 73, Step    50] loss: 0.107\n",
            "[Epoch 73, Step    60] loss: 0.435\n",
            "[Epoch 73, Step    70] loss: 0.264\n",
            "[Epoch 73, Step    80] loss: 0.335\n",
            "[Epoch 73, Step    90] loss: 0.194\n",
            "[Epoch 73, Step   100] loss: 0.034\n",
            "[Epoch 73, Step   110] loss: 0.272\n",
            "[Epoch 73, Step   120] loss: 0.169\n",
            "[Epoch 73, Step   130] loss: 0.033\n",
            "[Epoch 73, Step   140] loss: 0.012\n",
            "[Epoch 73, Step   150] loss: 0.076\n",
            "[Epoch 73, Step   160] loss: 0.610\n",
            "[Epoch 73, Step   170] loss: 0.268\n",
            "[Epoch 73, Step   180] loss: 0.201\n",
            "[Epoch 73, Step   190] loss: 0.109\n",
            "[Epoch 73, Step   200] loss: 0.336\n",
            "[Epoch 73, Step   210] loss: 0.070\n",
            "[Epoch 73, Step   220] loss: 0.243\n",
            "[Epoch 73, Step   230] loss: 0.339\n",
            "[Epoch 73, Step   240] loss: 1.026\n",
            "[Epoch 73, Step   250] loss: 0.220\n",
            "[Epoch 73, Step   260] loss: 0.299\n",
            "[Epoch 73, Step   270] loss: 0.235\n",
            "[Epoch 73, Step   280] loss: 0.394\n",
            "[Epoch 73, Step   290] loss: 0.198\n",
            "[Epoch 73, Step   300] loss: 0.202\n",
            "[Epoch 73, Step   310] loss: 0.225\n",
            "[Epoch 73, Step   320] loss: 0.044\n",
            "[Epoch 73, Step   330] loss: 0.117\n",
            "[Epoch 73, Step   340] loss: 0.294\n",
            "[Epoch 73, Step   350] loss: 0.442\n",
            "[Epoch 73, Step   360] loss: 0.234\n",
            "[Epoch 73, Step   370] loss: 0.170\n",
            "[Epoch 73, Step   380] loss: 0.246\n",
            "[Epoch 73, Step   390] loss: 0.455\n",
            "[Epoch 73, Step   400] loss: 0.232\n",
            "[Epoch 73, Step   410] loss: 0.241\n",
            "[Epoch 73, Step   420] loss: 0.086\n",
            "[Epoch 73, Step   430] loss: 0.748\n",
            "[Epoch 73, Step   440] loss: 0.164\n",
            "[Epoch 73, Step   450] loss: 0.201\n",
            "[Epoch 73, Step   460] loss: 0.120\n",
            "[Epoch 73, Step   470] loss: 0.172\n",
            "[Epoch 73, Step   480] loss: 0.161\n",
            "[Epoch 73, Step   490] loss: 0.151\n",
            "[Epoch 73, Step   500] loss: 0.195\n",
            "[Epoch 73, Step   510] loss: 0.288\n",
            "[Epoch 73, Step   520] loss: 0.238\n",
            "[Epoch 73, Step   530] loss: 0.127\n",
            "[Epoch 73, Step   540] loss: 0.255\n",
            "[Epoch 73, Step   550] loss: 0.071\n",
            "[Epoch 73, Step   560] loss: 0.056\n",
            "[Epoch 73, Step   570] loss: 0.396\n",
            "[Epoch 73, Step   580] loss: 0.111\n",
            "[Epoch 73, Step   590] loss: 0.179\n",
            "[Epoch 73, Step   600] loss: 0.185\n",
            "[Epoch 73, Step   610] loss: 0.370\n",
            "[Epoch 73, Step   620] loss: 0.340\n",
            "[Epoch 73, Step   630] loss: 0.227\n",
            "[Epoch 73, Step   640] loss: 0.481\n",
            "[Epoch 73, Step   650] loss: 0.176\n",
            "[Epoch 73, Step   660] loss: 0.102\n",
            "[Epoch 73, Step   670] loss: 0.229\n",
            "[Epoch 73, Step   680] loss: 0.241\n",
            "[Epoch 73, Step   690] loss: 0.418\n",
            "[Epoch 73, Step   700] loss: 0.301\n",
            "[Epoch 73, Step   710] loss: 0.311\n",
            "[Epoch 73, Step   720] loss: 0.164\n",
            "[Epoch 73, Step   730] loss: 0.096\n",
            "[Epoch 73, Step   740] loss: 0.182\n",
            "[Epoch 73, Step   750] loss: 0.304\n",
            "[Epoch 73, Step   760] loss: 0.155\n",
            "[Epoch 73, Step   770] loss: 0.090\n",
            "[Epoch 73, Step   780] loss: 0.206\n",
            "[Epoch 73, Step   790] loss: 0.073\n",
            "[Epoch 73, Step   800] loss: 0.177\n",
            "[Epoch 73, Step   810] loss: 0.309\n",
            "[Epoch 73, Step   820] loss: 0.152\n",
            "[Epoch 73, Step   830] loss: 0.426\n",
            "[Epoch 73, Step   840] loss: 0.096\n",
            "[Epoch 73, Step   850] loss: 0.170\n",
            "[Epoch 73, Step   860] loss: 0.118\n",
            "[Epoch 73, Step   870] loss: 0.350\n",
            "[Epoch 73, Step   880] loss: 0.249\n",
            "[Epoch 73, Step   890] loss: 0.188\n",
            "[Epoch 73, Step   900] loss: 0.247\n",
            "[Epoch 73, Step   910] loss: 0.211\n",
            "[Epoch 73, Step   920] loss: 0.319\n",
            "[Epoch 73, Step   930] loss: 0.272\n",
            "[Epoch 73, Step   940] loss: 0.158\n",
            "[Epoch 73, Step   950] loss: 0.042\n",
            "[Epoch 73, Step   960] loss: 0.092\n",
            "[Epoch 73, Step   970] loss: 0.167\n",
            "[Epoch 73, Step   980] loss: 0.429\n",
            "[Epoch 73, Step   990] loss: 0.353\n",
            "[Epoch 73, Step  1000] loss: 0.387\n",
            "[Epoch 73, Step  1010] loss: 0.116\n",
            "[Epoch 73, Step  1020] loss: 0.139\n",
            "[Epoch 73, Step  1030] loss: 0.306\n",
            "[Epoch 73, Step  1040] loss: 0.197\n",
            "[Epoch 73, Step  1050] loss: 0.220\n",
            "[Epoch 73, Step  1060] loss: 0.180\n",
            "[Epoch 73, Step  1070] loss: 0.253\n",
            "[Epoch 73, Step  1080] loss: 0.202\n",
            "[Epoch 73, Step  1090] loss: 0.141\n",
            "[Epoch 73, Step  1100] loss: 0.386\n",
            "[Epoch 73, Step  1110] loss: 0.424\n",
            "[Epoch 73, Step  1120] loss: 0.195\n",
            "[Epoch 73, Step  1130] loss: 0.282\n",
            "[Epoch 73, Step  1140] loss: 0.197\n",
            "[Epoch 73, Step  1150] loss: 0.227\n",
            "[Epoch 73, Step  1160] loss: 0.174\n",
            "[Epoch 73, Step  1170] loss: 0.075\n",
            "[Epoch 73, Step  1180] loss: 0.257\n",
            "[Epoch 73, Step  1190] loss: 0.291\n",
            "[Epoch 73, Step  1200] loss: 0.194\n",
            "[Epoch 73, Step  1210] loss: 0.062\n",
            "[Epoch 73, Step  1220] loss: 0.502\n",
            "[Epoch 73, Step  1230] loss: 0.441\n",
            "[Epoch 73, Step  1240] loss: 0.197\n",
            "[Epoch 73, Step  1250] loss: 0.086\n",
            "[Epoch 73, Step  1260] loss: 0.296\n",
            "[Epoch 73, Step  1270] loss: 0.099\n",
            "[Epoch 73, Step  1280] loss: 0.215\n",
            "[Epoch 73, Step  1290] loss: 0.138\n",
            "[Epoch 73, Step  1300] loss: 0.083\n",
            "[Epoch 73, Step  1310] loss: 0.457\n",
            "[Epoch 73, Step  1320] loss: 0.138\n",
            "[Epoch 73, Step  1330] loss: 0.070\n",
            "[Epoch 73, Step  1340] loss: 0.283\n",
            "[Epoch 73, Step  1350] loss: 0.244\n",
            "[Epoch 73, Step  1360] loss: 0.342\n",
            "[Epoch 73, Step  1370] loss: 0.251\n",
            "[Epoch 73, Step  1380] loss: 0.127\n",
            "[Epoch 73, Step  1390] loss: 0.109\n",
            "[Epoch 73, Step  1400] loss: 0.317\n",
            "[Epoch 73, Step  1410] loss: 0.176\n",
            "[Epoch 73, Step  1420] loss: 0.554\n",
            "[Epoch 73, Step  1430] loss: 0.297\n",
            "[Epoch 73, Step  1440] loss: 0.237\n",
            "[Epoch 73, Step  1450] loss: 0.742\n",
            "[Epoch 73, Step  1460] loss: 0.093\n",
            "[Epoch 73, Step  1470] loss: 0.250\n",
            "[Epoch 73, Step  1480] loss: 0.057\n",
            "[Epoch 73, Step  1490] loss: 0.315\n",
            "[Epoch 73, Step  1500] loss: 0.194\n",
            "[Epoch 73, Step  1510] loss: 0.101\n",
            "[Epoch 73, Step  1520] loss: 0.103\n",
            "[Epoch 73, Step  1530] loss: 0.326\n",
            "[Epoch 73, Step  1540] loss: 0.243\n",
            "[Epoch 73, Step  1550] loss: 0.442\n",
            "[Epoch 73, Step  1560] loss: 0.154\n",
            "[Epoch 73, Step  1570] loss: 0.355\n",
            "[Epoch 73, Step  1580] loss: 0.146\n",
            "[Epoch 73, Step  1590] loss: 0.116\n",
            "[Epoch 73, Step  1600] loss: 0.401\n",
            "[Epoch 74, Step    10] loss: 0.505\n",
            "[Epoch 74, Step    20] loss: 0.280\n",
            "[Epoch 74, Step    30] loss: 0.204\n",
            "[Epoch 74, Step    40] loss: 0.244\n",
            "[Epoch 74, Step    50] loss: 0.139\n",
            "[Epoch 74, Step    60] loss: 0.363\n",
            "[Epoch 74, Step    70] loss: 0.092\n",
            "[Epoch 74, Step    80] loss: 0.414\n",
            "[Epoch 74, Step    90] loss: 0.101\n",
            "[Epoch 74, Step   100] loss: 0.161\n",
            "[Epoch 74, Step   110] loss: 0.106\n",
            "[Epoch 74, Step   120] loss: 0.074\n",
            "[Epoch 74, Step   130] loss: 0.427\n",
            "[Epoch 74, Step   140] loss: 0.106\n",
            "[Epoch 74, Step   150] loss: 0.312\n",
            "[Epoch 74, Step   160] loss: 0.132\n",
            "[Epoch 74, Step   170] loss: 0.210\n",
            "[Epoch 74, Step   180] loss: 0.119\n",
            "[Epoch 74, Step   190] loss: 0.183\n",
            "[Epoch 74, Step   200] loss: 0.392\n",
            "[Epoch 74, Step   210] loss: 0.199\n",
            "[Epoch 74, Step   220] loss: 0.357\n",
            "[Epoch 74, Step   230] loss: 0.198\n",
            "[Epoch 74, Step   240] loss: 0.369\n",
            "[Epoch 74, Step   250] loss: 0.198\n",
            "[Epoch 74, Step   260] loss: 0.043\n",
            "[Epoch 74, Step   270] loss: 0.328\n",
            "[Epoch 74, Step   280] loss: 0.157\n",
            "[Epoch 74, Step   290] loss: 0.313\n",
            "[Epoch 74, Step   300] loss: 0.319\n",
            "[Epoch 74, Step   310] loss: 0.155\n",
            "[Epoch 74, Step   320] loss: 0.226\n",
            "[Epoch 74, Step   330] loss: 0.204\n",
            "[Epoch 74, Step   340] loss: 0.122\n",
            "[Epoch 74, Step   350] loss: 0.533\n",
            "[Epoch 74, Step   360] loss: 0.102\n",
            "[Epoch 74, Step   370] loss: 0.268\n",
            "[Epoch 74, Step   380] loss: 0.229\n",
            "[Epoch 74, Step   390] loss: 0.130\n",
            "[Epoch 74, Step   400] loss: 0.119\n",
            "[Epoch 74, Step   410] loss: 0.285\n",
            "[Epoch 74, Step   420] loss: 0.321\n",
            "[Epoch 74, Step   430] loss: 0.252\n",
            "[Epoch 74, Step   440] loss: 0.524\n",
            "[Epoch 74, Step   450] loss: 0.186\n",
            "[Epoch 74, Step   460] loss: 0.154\n",
            "[Epoch 74, Step   470] loss: 0.089\n",
            "[Epoch 74, Step   480] loss: 0.256\n",
            "[Epoch 74, Step   490] loss: 0.098\n",
            "[Epoch 74, Step   500] loss: 0.276\n",
            "[Epoch 74, Step   510] loss: 0.150\n",
            "[Epoch 74, Step   520] loss: 0.500\n",
            "[Epoch 74, Step   530] loss: 0.082\n",
            "[Epoch 74, Step   540] loss: 0.140\n",
            "[Epoch 74, Step   550] loss: 0.186\n",
            "[Epoch 74, Step   560] loss: 0.337\n",
            "[Epoch 74, Step   570] loss: 0.128\n",
            "[Epoch 74, Step   580] loss: 0.363\n",
            "[Epoch 74, Step   590] loss: 0.186\n",
            "[Epoch 74, Step   600] loss: 0.241\n",
            "[Epoch 74, Step   610] loss: 0.395\n",
            "[Epoch 74, Step   620] loss: 0.142\n",
            "[Epoch 74, Step   630] loss: 0.371\n",
            "[Epoch 74, Step   640] loss: 0.525\n",
            "[Epoch 74, Step   650] loss: 0.455\n",
            "[Epoch 74, Step   660] loss: 0.170\n",
            "[Epoch 74, Step   670] loss: 0.355\n",
            "[Epoch 74, Step   680] loss: 0.332\n",
            "[Epoch 74, Step   690] loss: 0.716\n",
            "[Epoch 74, Step   700] loss: 0.109\n",
            "[Epoch 74, Step   710] loss: 0.183\n",
            "[Epoch 74, Step   720] loss: 0.085\n",
            "[Epoch 74, Step   730] loss: 0.222\n",
            "[Epoch 74, Step   740] loss: 0.080\n",
            "[Epoch 74, Step   750] loss: 0.103\n",
            "[Epoch 74, Step   760] loss: 0.201\n",
            "[Epoch 74, Step   770] loss: 0.176\n",
            "[Epoch 74, Step   780] loss: 0.083\n",
            "[Epoch 74, Step   790] loss: 0.515\n",
            "[Epoch 74, Step   800] loss: 0.229\n",
            "[Epoch 74, Step   810] loss: 0.049\n",
            "[Epoch 74, Step   820] loss: 0.123\n",
            "[Epoch 74, Step   830] loss: 0.304\n",
            "[Epoch 74, Step   840] loss: 0.030\n",
            "[Epoch 74, Step   850] loss: 0.261\n",
            "[Epoch 74, Step   860] loss: 0.028\n",
            "[Epoch 74, Step   870] loss: 0.082\n",
            "[Epoch 74, Step   880] loss: 0.444\n",
            "[Epoch 74, Step   890] loss: 0.248\n",
            "[Epoch 74, Step   900] loss: 0.279\n",
            "[Epoch 74, Step   910] loss: 0.178\n",
            "[Epoch 74, Step   920] loss: 0.259\n",
            "[Epoch 74, Step   930] loss: 0.530\n",
            "[Epoch 74, Step   940] loss: 0.548\n",
            "[Epoch 74, Step   950] loss: 0.294\n",
            "[Epoch 74, Step   960] loss: 0.119\n",
            "[Epoch 74, Step   970] loss: 0.071\n",
            "[Epoch 74, Step   980] loss: 0.179\n",
            "[Epoch 74, Step   990] loss: 0.995\n",
            "[Epoch 74, Step  1000] loss: 0.116\n",
            "[Epoch 74, Step  1010] loss: 0.162\n",
            "[Epoch 74, Step  1020] loss: 0.191\n",
            "[Epoch 74, Step  1030] loss: 0.165\n",
            "[Epoch 74, Step  1040] loss: 0.254\n",
            "[Epoch 74, Step  1050] loss: 0.163\n",
            "[Epoch 74, Step  1060] loss: 0.090\n",
            "[Epoch 74, Step  1070] loss: 0.220\n",
            "[Epoch 74, Step  1080] loss: 0.290\n",
            "[Epoch 74, Step  1090] loss: 0.058\n",
            "[Epoch 74, Step  1100] loss: 0.129\n",
            "[Epoch 74, Step  1110] loss: 0.061\n",
            "[Epoch 74, Step  1120] loss: 0.248\n",
            "[Epoch 74, Step  1130] loss: 0.142\n",
            "[Epoch 74, Step  1140] loss: 0.387\n",
            "[Epoch 74, Step  1150] loss: 0.214\n",
            "[Epoch 74, Step  1160] loss: 0.165\n",
            "[Epoch 74, Step  1170] loss: 0.408\n",
            "[Epoch 74, Step  1180] loss: 0.666\n",
            "[Epoch 74, Step  1190] loss: 0.106\n",
            "[Epoch 74, Step  1200] loss: 0.081\n",
            "[Epoch 74, Step  1210] loss: 0.132\n",
            "[Epoch 74, Step  1220] loss: 0.194\n",
            "[Epoch 74, Step  1230] loss: 0.473\n",
            "[Epoch 74, Step  1240] loss: 0.246\n",
            "[Epoch 74, Step  1250] loss: 0.100\n",
            "[Epoch 74, Step  1260] loss: 0.182\n",
            "[Epoch 74, Step  1270] loss: 0.226\n",
            "[Epoch 74, Step  1280] loss: 0.272\n",
            "[Epoch 74, Step  1290] loss: 0.383\n",
            "[Epoch 74, Step  1300] loss: 0.223\n",
            "[Epoch 74, Step  1310] loss: 0.156\n",
            "[Epoch 74, Step  1320] loss: 0.138\n",
            "[Epoch 74, Step  1330] loss: 0.111\n",
            "[Epoch 74, Step  1340] loss: 0.101\n",
            "[Epoch 74, Step  1350] loss: 0.181\n",
            "[Epoch 74, Step  1360] loss: 0.066\n",
            "[Epoch 74, Step  1370] loss: 0.125\n",
            "[Epoch 74, Step  1380] loss: 0.374\n",
            "[Epoch 74, Step  1390] loss: 0.240\n",
            "[Epoch 74, Step  1400] loss: 0.230\n",
            "[Epoch 74, Step  1410] loss: 0.121\n",
            "[Epoch 74, Step  1420] loss: 0.079\n",
            "[Epoch 74, Step  1430] loss: 0.159\n",
            "[Epoch 74, Step  1440] loss: 0.162\n",
            "[Epoch 74, Step  1450] loss: 0.461\n",
            "[Epoch 74, Step  1460] loss: 0.069\n",
            "[Epoch 74, Step  1470] loss: 0.092\n",
            "[Epoch 74, Step  1480] loss: 0.131\n",
            "[Epoch 74, Step  1490] loss: 0.477\n",
            "[Epoch 74, Step  1500] loss: 0.164\n",
            "[Epoch 74, Step  1510] loss: 0.640\n",
            "[Epoch 74, Step  1520] loss: 0.297\n",
            "[Epoch 74, Step  1530] loss: 0.137\n",
            "[Epoch 74, Step  1540] loss: 0.121\n",
            "[Epoch 74, Step  1550] loss: 0.134\n",
            "[Epoch 74, Step  1560] loss: 0.640\n",
            "[Epoch 74, Step  1570] loss: 0.313\n",
            "[Epoch 74, Step  1580] loss: 0.435\n",
            "[Epoch 74, Step  1590] loss: 0.049\n",
            "[Epoch 74, Step  1600] loss: 0.094\n",
            "[Epoch 75, Step    10] loss: 0.404\n",
            "[Epoch 75, Step    20] loss: 0.150\n",
            "[Epoch 75, Step    30] loss: 0.095\n",
            "[Epoch 75, Step    40] loss: 0.152\n",
            "[Epoch 75, Step    50] loss: 0.197\n",
            "[Epoch 75, Step    60] loss: 0.140\n",
            "[Epoch 75, Step    70] loss: 0.111\n",
            "[Epoch 75, Step    80] loss: 0.205\n",
            "[Epoch 75, Step    90] loss: 0.030\n",
            "[Epoch 75, Step   100] loss: 0.064\n",
            "[Epoch 75, Step   110] loss: 0.173\n",
            "[Epoch 75, Step   120] loss: 0.217\n",
            "[Epoch 75, Step   130] loss: 0.228\n",
            "[Epoch 75, Step   140] loss: 0.101\n",
            "[Epoch 75, Step   150] loss: 0.424\n",
            "[Epoch 75, Step   160] loss: 0.365\n",
            "[Epoch 75, Step   170] loss: 0.380\n",
            "[Epoch 75, Step   180] loss: 0.122\n",
            "[Epoch 75, Step   190] loss: 0.217\n",
            "[Epoch 75, Step   200] loss: 0.405\n",
            "[Epoch 75, Step   210] loss: 0.153\n",
            "[Epoch 75, Step   220] loss: 0.301\n",
            "[Epoch 75, Step   230] loss: 0.090\n",
            "[Epoch 75, Step   240] loss: 0.135\n",
            "[Epoch 75, Step   250] loss: 0.299\n",
            "[Epoch 75, Step   260] loss: 0.601\n",
            "[Epoch 75, Step   270] loss: 0.166\n",
            "[Epoch 75, Step   280] loss: 0.119\n",
            "[Epoch 75, Step   290] loss: 0.142\n",
            "[Epoch 75, Step   300] loss: 0.381\n",
            "[Epoch 75, Step   310] loss: 0.310\n",
            "[Epoch 75, Step   320] loss: 0.259\n",
            "[Epoch 75, Step   330] loss: 0.350\n",
            "[Epoch 75, Step   340] loss: 0.120\n",
            "[Epoch 75, Step   350] loss: 0.224\n",
            "[Epoch 75, Step   360] loss: 0.153\n",
            "[Epoch 75, Step   370] loss: 0.512\n",
            "[Epoch 75, Step   380] loss: 0.174\n",
            "[Epoch 75, Step   390] loss: 0.257\n",
            "[Epoch 75, Step   400] loss: 0.096\n",
            "[Epoch 75, Step   410] loss: 0.253\n",
            "[Epoch 75, Step   420] loss: 0.318\n",
            "[Epoch 75, Step   430] loss: 0.392\n",
            "[Epoch 75, Step   440] loss: 0.477\n",
            "[Epoch 75, Step   450] loss: 0.127\n",
            "[Epoch 75, Step   460] loss: 0.282\n",
            "[Epoch 75, Step   470] loss: 0.310\n",
            "[Epoch 75, Step   480] loss: 0.082\n",
            "[Epoch 75, Step   490] loss: 0.287\n",
            "[Epoch 75, Step   500] loss: 0.044\n",
            "[Epoch 75, Step   510] loss: 0.190\n",
            "[Epoch 75, Step   520] loss: 0.083\n",
            "[Epoch 75, Step   530] loss: 0.144\n",
            "[Epoch 75, Step   540] loss: 0.233\n",
            "[Epoch 75, Step   550] loss: 0.200\n",
            "[Epoch 75, Step   560] loss: 0.589\n",
            "[Epoch 75, Step   570] loss: 0.330\n",
            "[Epoch 75, Step   580] loss: 0.142\n",
            "[Epoch 75, Step   590] loss: 0.230\n",
            "[Epoch 75, Step   600] loss: 0.062\n",
            "[Epoch 75, Step   610] loss: 0.340\n",
            "[Epoch 75, Step   620] loss: 0.151\n",
            "[Epoch 75, Step   630] loss: 0.305\n",
            "[Epoch 75, Step   640] loss: 0.145\n",
            "[Epoch 75, Step   650] loss: 0.339\n",
            "[Epoch 75, Step   660] loss: 0.380\n",
            "[Epoch 75, Step   670] loss: 0.204\n",
            "[Epoch 75, Step   680] loss: 0.304\n",
            "[Epoch 75, Step   690] loss: 0.334\n",
            "[Epoch 75, Step   700] loss: 0.271\n",
            "[Epoch 75, Step   710] loss: 0.215\n",
            "[Epoch 75, Step   720] loss: 0.028\n",
            "[Epoch 75, Step   730] loss: 0.225\n",
            "[Epoch 75, Step   740] loss: 0.272\n",
            "[Epoch 75, Step   750] loss: 0.065\n",
            "[Epoch 75, Step   760] loss: 0.078\n",
            "[Epoch 75, Step   770] loss: 0.146\n",
            "[Epoch 75, Step   780] loss: 0.506\n",
            "[Epoch 75, Step   790] loss: 0.422\n",
            "[Epoch 75, Step   800] loss: 0.076\n",
            "[Epoch 75, Step   810] loss: 0.284\n",
            "[Epoch 75, Step   820] loss: 0.220\n",
            "[Epoch 75, Step   830] loss: 0.551\n",
            "[Epoch 75, Step   840] loss: 0.406\n",
            "[Epoch 75, Step   850] loss: 0.038\n",
            "[Epoch 75, Step   860] loss: 0.120\n",
            "[Epoch 75, Step   870] loss: 0.137\n",
            "[Epoch 75, Step   880] loss: 0.499\n",
            "[Epoch 75, Step   890] loss: 0.176\n",
            "[Epoch 75, Step   900] loss: 0.175\n",
            "[Epoch 75, Step   910] loss: 0.319\n",
            "[Epoch 75, Step   920] loss: 0.233\n",
            "[Epoch 75, Step   930] loss: 0.152\n",
            "[Epoch 75, Step   940] loss: 0.499\n",
            "[Epoch 75, Step   950] loss: 0.615\n",
            "[Epoch 75, Step   960] loss: 0.046\n",
            "[Epoch 75, Step   970] loss: 0.264\n",
            "[Epoch 75, Step   980] loss: 0.275\n",
            "[Epoch 75, Step   990] loss: 0.149\n",
            "[Epoch 75, Step  1000] loss: 0.126\n",
            "[Epoch 75, Step  1010] loss: 0.153\n",
            "[Epoch 75, Step  1020] loss: 0.222\n",
            "[Epoch 75, Step  1030] loss: 0.418\n",
            "[Epoch 75, Step  1040] loss: 0.197\n",
            "[Epoch 75, Step  1050] loss: 0.109\n",
            "[Epoch 75, Step  1060] loss: 0.258\n",
            "[Epoch 75, Step  1070] loss: 0.062\n",
            "[Epoch 75, Step  1080] loss: 0.256\n",
            "[Epoch 75, Step  1090] loss: 0.092\n",
            "[Epoch 75, Step  1100] loss: 0.222\n",
            "[Epoch 75, Step  1110] loss: 0.246\n",
            "[Epoch 75, Step  1120] loss: 0.121\n",
            "[Epoch 75, Step  1130] loss: 0.284\n",
            "[Epoch 75, Step  1140] loss: 0.101\n",
            "[Epoch 75, Step  1150] loss: 0.241\n",
            "[Epoch 75, Step  1160] loss: 0.099\n",
            "[Epoch 75, Step  1170] loss: 0.254\n",
            "[Epoch 75, Step  1180] loss: 0.309\n",
            "[Epoch 75, Step  1190] loss: 0.409\n",
            "[Epoch 75, Step  1200] loss: 0.181\n",
            "[Epoch 75, Step  1210] loss: 0.068\n",
            "[Epoch 75, Step  1220] loss: 0.197\n",
            "[Epoch 75, Step  1230] loss: 0.198\n",
            "[Epoch 75, Step  1240] loss: 0.227\n",
            "[Epoch 75, Step  1250] loss: 0.232\n",
            "[Epoch 75, Step  1260] loss: 0.350\n",
            "[Epoch 75, Step  1270] loss: 0.180\n",
            "[Epoch 75, Step  1280] loss: 0.113\n",
            "[Epoch 75, Step  1290] loss: 0.251\n",
            "[Epoch 75, Step  1300] loss: 0.104\n",
            "[Epoch 75, Step  1310] loss: 0.024\n",
            "[Epoch 75, Step  1320] loss: 0.109\n",
            "[Epoch 75, Step  1330] loss: 0.045\n",
            "[Epoch 75, Step  1340] loss: 0.201\n",
            "[Epoch 75, Step  1350] loss: 0.612\n",
            "[Epoch 75, Step  1360] loss: 0.421\n",
            "[Epoch 75, Step  1370] loss: 0.428\n",
            "[Epoch 75, Step  1380] loss: 0.240\n",
            "[Epoch 75, Step  1390] loss: 0.334\n",
            "[Epoch 75, Step  1400] loss: 0.190\n",
            "[Epoch 75, Step  1410] loss: 0.186\n",
            "[Epoch 75, Step  1420] loss: 0.099\n",
            "[Epoch 75, Step  1430] loss: 0.190\n",
            "[Epoch 75, Step  1440] loss: 0.090\n",
            "[Epoch 75, Step  1450] loss: 0.099\n",
            "[Epoch 75, Step  1460] loss: 0.085\n",
            "[Epoch 75, Step  1470] loss: 0.265\n",
            "[Epoch 75, Step  1480] loss: 0.581\n",
            "[Epoch 75, Step  1490] loss: 0.442\n",
            "[Epoch 75, Step  1500] loss: 0.118\n",
            "[Epoch 75, Step  1510] loss: 0.244\n",
            "[Epoch 75, Step  1520] loss: 0.297\n",
            "[Epoch 75, Step  1530] loss: 0.380\n",
            "[Epoch 75, Step  1540] loss: 0.196\n",
            "[Epoch 75, Step  1550] loss: 0.111\n",
            "[Epoch 75, Step  1560] loss: 0.516\n",
            "[Epoch 75, Step  1570] loss: 0.398\n",
            "[Epoch 75, Step  1580] loss: 0.006\n",
            "[Epoch 75, Step  1590] loss: 0.224\n",
            "[Epoch 75, Step  1600] loss: 0.311\n",
            "[Epoch 76, Step    10] loss: 0.219\n",
            "[Epoch 76, Step    20] loss: 0.203\n",
            "[Epoch 76, Step    30] loss: 0.211\n",
            "[Epoch 76, Step    40] loss: 0.178\n",
            "[Epoch 76, Step    50] loss: 0.226\n",
            "[Epoch 76, Step    60] loss: 0.283\n",
            "[Epoch 76, Step    70] loss: 0.233\n",
            "[Epoch 76, Step    80] loss: 0.252\n",
            "[Epoch 76, Step    90] loss: 0.055\n",
            "[Epoch 76, Step   100] loss: 0.272\n",
            "[Epoch 76, Step   110] loss: 0.067\n",
            "[Epoch 76, Step   120] loss: 0.106\n",
            "[Epoch 76, Step   130] loss: 0.204\n",
            "[Epoch 76, Step   140] loss: 0.038\n",
            "[Epoch 76, Step   150] loss: 0.268\n",
            "[Epoch 76, Step   160] loss: 0.194\n",
            "[Epoch 76, Step   170] loss: 0.067\n",
            "[Epoch 76, Step   180] loss: 0.121\n",
            "[Epoch 76, Step   190] loss: 0.074\n",
            "[Epoch 76, Step   200] loss: 0.213\n",
            "[Epoch 76, Step   210] loss: 0.181\n",
            "[Epoch 76, Step   220] loss: 0.381\n",
            "[Epoch 76, Step   230] loss: 0.261\n",
            "[Epoch 76, Step   240] loss: 0.666\n",
            "[Epoch 76, Step   250] loss: 0.500\n",
            "[Epoch 76, Step   260] loss: 0.432\n",
            "[Epoch 76, Step   270] loss: 0.463\n",
            "[Epoch 76, Step   280] loss: 0.139\n",
            "[Epoch 76, Step   290] loss: 0.432\n",
            "[Epoch 76, Step   300] loss: 0.098\n",
            "[Epoch 76, Step   310] loss: 0.130\n",
            "[Epoch 76, Step   320] loss: 0.319\n",
            "[Epoch 76, Step   330] loss: 0.076\n",
            "[Epoch 76, Step   340] loss: 0.223\n",
            "[Epoch 76, Step   350] loss: 0.052\n",
            "[Epoch 76, Step   360] loss: 0.075\n",
            "[Epoch 76, Step   370] loss: 0.283\n",
            "[Epoch 76, Step   380] loss: 0.254\n",
            "[Epoch 76, Step   390] loss: 0.231\n",
            "[Epoch 76, Step   400] loss: 0.315\n",
            "[Epoch 76, Step   410] loss: 0.360\n",
            "[Epoch 76, Step   420] loss: 0.179\n",
            "[Epoch 76, Step   430] loss: 0.176\n",
            "[Epoch 76, Step   440] loss: 0.336\n",
            "[Epoch 76, Step   450] loss: 0.232\n",
            "[Epoch 76, Step   460] loss: 0.074\n",
            "[Epoch 76, Step   470] loss: 0.185\n",
            "[Epoch 76, Step   480] loss: 0.235\n",
            "[Epoch 76, Step   490] loss: 0.394\n",
            "[Epoch 76, Step   500] loss: 0.106\n",
            "[Epoch 76, Step   510] loss: 0.306\n",
            "[Epoch 76, Step   520] loss: 0.086\n",
            "[Epoch 76, Step   530] loss: 0.136\n",
            "[Epoch 76, Step   540] loss: 0.278\n",
            "[Epoch 76, Step   550] loss: 0.084\n",
            "[Epoch 76, Step   560] loss: 0.499\n",
            "[Epoch 76, Step   570] loss: 0.153\n",
            "[Epoch 76, Step   580] loss: 0.506\n",
            "[Epoch 76, Step   590] loss: 0.227\n",
            "[Epoch 76, Step   600] loss: 0.228\n",
            "[Epoch 76, Step   610] loss: 0.037\n",
            "[Epoch 76, Step   620] loss: 0.075\n",
            "[Epoch 76, Step   630] loss: 0.487\n",
            "[Epoch 76, Step   640] loss: 0.303\n",
            "[Epoch 76, Step   650] loss: 0.191\n",
            "[Epoch 76, Step   660] loss: 0.155\n",
            "[Epoch 76, Step   670] loss: 0.180\n",
            "[Epoch 76, Step   680] loss: 0.204\n",
            "[Epoch 76, Step   690] loss: 0.390\n",
            "[Epoch 76, Step   700] loss: 0.405\n",
            "[Epoch 76, Step   710] loss: 0.320\n",
            "[Epoch 76, Step   720] loss: 0.326\n",
            "[Epoch 76, Step   730] loss: 0.159\n",
            "[Epoch 76, Step   740] loss: 0.214\n",
            "[Epoch 76, Step   750] loss: 0.129\n",
            "[Epoch 76, Step   760] loss: 0.287\n",
            "[Epoch 76, Step   770] loss: 0.143\n",
            "[Epoch 76, Step   780] loss: 0.181\n",
            "[Epoch 76, Step   790] loss: 0.446\n",
            "[Epoch 76, Step   800] loss: 0.312\n",
            "[Epoch 76, Step   810] loss: 0.104\n",
            "[Epoch 76, Step   820] loss: 0.108\n",
            "[Epoch 76, Step   830] loss: 0.167\n",
            "[Epoch 76, Step   840] loss: 0.194\n",
            "[Epoch 76, Step   850] loss: 0.126\n",
            "[Epoch 76, Step   860] loss: 0.311\n",
            "[Epoch 76, Step   870] loss: 0.322\n",
            "[Epoch 76, Step   880] loss: 0.071\n",
            "[Epoch 76, Step   890] loss: 0.080\n",
            "[Epoch 76, Step   900] loss: 0.106\n",
            "[Epoch 76, Step   910] loss: 0.217\n",
            "[Epoch 76, Step   920] loss: 0.023\n",
            "[Epoch 76, Step   930] loss: 0.092\n",
            "[Epoch 76, Step   940] loss: 0.244\n",
            "[Epoch 76, Step   950] loss: 0.209\n",
            "[Epoch 76, Step   960] loss: 0.412\n",
            "[Epoch 76, Step   970] loss: 0.231\n",
            "[Epoch 76, Step   980] loss: 0.225\n",
            "[Epoch 76, Step   990] loss: 0.093\n",
            "[Epoch 76, Step  1000] loss: 0.161\n",
            "[Epoch 76, Step  1010] loss: 0.033\n",
            "[Epoch 76, Step  1020] loss: 0.242\n",
            "[Epoch 76, Step  1030] loss: 0.433\n",
            "[Epoch 76, Step  1040] loss: 0.548\n",
            "[Epoch 76, Step  1050] loss: 0.076\n",
            "[Epoch 76, Step  1060] loss: 0.055\n",
            "[Epoch 76, Step  1070] loss: 0.136\n",
            "[Epoch 76, Step  1080] loss: 0.294\n",
            "[Epoch 76, Step  1090] loss: 0.233\n",
            "[Epoch 76, Step  1100] loss: 0.155\n",
            "[Epoch 76, Step  1110] loss: 0.095\n",
            "[Epoch 76, Step  1120] loss: 0.191\n",
            "[Epoch 76, Step  1130] loss: 0.289\n",
            "[Epoch 76, Step  1140] loss: 0.092\n",
            "[Epoch 76, Step  1150] loss: 0.311\n",
            "[Epoch 76, Step  1160] loss: 0.284\n",
            "[Epoch 76, Step  1170] loss: 0.275\n",
            "[Epoch 76, Step  1180] loss: 0.226\n",
            "[Epoch 76, Step  1190] loss: 0.193\n",
            "[Epoch 76, Step  1200] loss: 0.146\n",
            "[Epoch 76, Step  1210] loss: 0.113\n",
            "[Epoch 76, Step  1220] loss: 0.377\n",
            "[Epoch 76, Step  1230] loss: 0.078\n",
            "[Epoch 76, Step  1240] loss: 0.337\n",
            "[Epoch 76, Step  1250] loss: 0.106\n",
            "[Epoch 76, Step  1260] loss: 0.317\n",
            "[Epoch 76, Step  1270] loss: 0.070\n",
            "[Epoch 76, Step  1280] loss: 0.122\n",
            "[Epoch 76, Step  1290] loss: 0.031\n",
            "[Epoch 76, Step  1300] loss: 0.113\n",
            "[Epoch 76, Step  1310] loss: 0.551\n",
            "[Epoch 76, Step  1320] loss: 0.261\n",
            "[Epoch 76, Step  1330] loss: 0.298\n",
            "[Epoch 76, Step  1340] loss: 0.196\n",
            "[Epoch 76, Step  1350] loss: 0.301\n",
            "[Epoch 76, Step  1360] loss: 0.516\n",
            "[Epoch 76, Step  1370] loss: 0.400\n",
            "[Epoch 76, Step  1380] loss: 0.251\n",
            "[Epoch 76, Step  1390] loss: 0.375\n",
            "[Epoch 76, Step  1400] loss: 0.045\n",
            "[Epoch 76, Step  1410] loss: 0.056\n",
            "[Epoch 76, Step  1420] loss: 0.199\n",
            "[Epoch 76, Step  1430] loss: 0.095\n",
            "[Epoch 76, Step  1440] loss: 0.335\n",
            "[Epoch 76, Step  1450] loss: 0.132\n",
            "[Epoch 76, Step  1460] loss: 0.424\n",
            "[Epoch 76, Step  1470] loss: 0.149\n",
            "[Epoch 76, Step  1480] loss: 0.343\n",
            "[Epoch 76, Step  1490] loss: 0.106\n",
            "[Epoch 76, Step  1500] loss: 0.413\n",
            "[Epoch 76, Step  1510] loss: 0.521\n",
            "[Epoch 76, Step  1520] loss: 0.619\n",
            "[Epoch 76, Step  1530] loss: 0.125\n",
            "[Epoch 76, Step  1540] loss: 0.379\n",
            "[Epoch 76, Step  1550] loss: 0.063\n",
            "[Epoch 76, Step  1560] loss: 0.627\n",
            "[Epoch 76, Step  1570] loss: 0.159\n",
            "[Epoch 76, Step  1580] loss: 0.595\n",
            "[Epoch 76, Step  1590] loss: 0.474\n",
            "[Epoch 76, Step  1600] loss: 0.155\n",
            "[Epoch 77, Step    10] loss: 0.153\n",
            "[Epoch 77, Step    20] loss: 0.051\n",
            "[Epoch 77, Step    30] loss: 0.326\n",
            "[Epoch 77, Step    40] loss: 0.142\n",
            "[Epoch 77, Step    50] loss: 0.124\n",
            "[Epoch 77, Step    60] loss: 0.049\n",
            "[Epoch 77, Step    70] loss: 0.093\n",
            "[Epoch 77, Step    80] loss: 0.374\n",
            "[Epoch 77, Step    90] loss: 0.193\n",
            "[Epoch 77, Step   100] loss: 0.162\n",
            "[Epoch 77, Step   110] loss: 0.151\n",
            "[Epoch 77, Step   120] loss: 0.060\n",
            "[Epoch 77, Step   130] loss: 0.242\n",
            "[Epoch 77, Step   140] loss: 0.645\n",
            "[Epoch 77, Step   150] loss: 0.211\n",
            "[Epoch 77, Step   160] loss: 0.436\n",
            "[Epoch 77, Step   170] loss: 0.426\n",
            "[Epoch 77, Step   180] loss: 0.235\n",
            "[Epoch 77, Step   190] loss: 0.410\n",
            "[Epoch 77, Step   200] loss: 0.260\n",
            "[Epoch 77, Step   210] loss: 0.162\n",
            "[Epoch 77, Step   220] loss: 0.177\n",
            "[Epoch 77, Step   230] loss: 0.070\n",
            "[Epoch 77, Step   240] loss: 0.789\n",
            "[Epoch 77, Step   250] loss: 0.242\n",
            "[Epoch 77, Step   260] loss: 0.209\n",
            "[Epoch 77, Step   270] loss: 0.147\n",
            "[Epoch 77, Step   280] loss: 0.146\n",
            "[Epoch 77, Step   290] loss: 0.482\n",
            "[Epoch 77, Step   300] loss: 0.254\n",
            "[Epoch 77, Step   310] loss: 0.497\n",
            "[Epoch 77, Step   320] loss: 0.156\n",
            "[Epoch 77, Step   330] loss: 0.338\n",
            "[Epoch 77, Step   340] loss: 0.232\n",
            "[Epoch 77, Step   350] loss: 0.097\n",
            "[Epoch 77, Step   360] loss: 0.425\n",
            "[Epoch 77, Step   370] loss: 0.429\n",
            "[Epoch 77, Step   380] loss: 0.338\n",
            "[Epoch 77, Step   390] loss: 0.040\n",
            "[Epoch 77, Step   400] loss: 0.144\n",
            "[Epoch 77, Step   410] loss: 0.201\n",
            "[Epoch 77, Step   420] loss: 0.176\n",
            "[Epoch 77, Step   430] loss: 0.233\n",
            "[Epoch 77, Step   440] loss: 0.040\n",
            "[Epoch 77, Step   450] loss: 0.081\n",
            "[Epoch 77, Step   460] loss: 0.135\n",
            "[Epoch 77, Step   470] loss: 0.141\n",
            "[Epoch 77, Step   480] loss: 0.100\n",
            "[Epoch 77, Step   490] loss: 0.195\n",
            "[Epoch 77, Step   500] loss: 0.339\n",
            "[Epoch 77, Step   510] loss: 0.533\n",
            "[Epoch 77, Step   520] loss: 0.117\n",
            "[Epoch 77, Step   530] loss: 0.305\n",
            "[Epoch 77, Step   540] loss: 0.104\n",
            "[Epoch 77, Step   550] loss: 0.379\n",
            "[Epoch 77, Step   560] loss: 0.617\n",
            "[Epoch 77, Step   570] loss: 0.295\n",
            "[Epoch 77, Step   580] loss: 0.130\n",
            "[Epoch 77, Step   590] loss: 0.073\n",
            "[Epoch 77, Step   600] loss: 0.326\n",
            "[Epoch 77, Step   610] loss: 0.418\n",
            "[Epoch 77, Step   620] loss: 0.129\n",
            "[Epoch 77, Step   630] loss: 0.093\n",
            "[Epoch 77, Step   640] loss: 0.032\n",
            "[Epoch 77, Step   650] loss: 0.175\n",
            "[Epoch 77, Step   660] loss: 0.161\n",
            "[Epoch 77, Step   670] loss: 0.339\n",
            "[Epoch 77, Step   680] loss: 0.607\n",
            "[Epoch 77, Step   690] loss: 0.076\n",
            "[Epoch 77, Step   700] loss: 0.213\n",
            "[Epoch 77, Step   710] loss: 0.085\n",
            "[Epoch 77, Step   720] loss: 0.094\n",
            "[Epoch 77, Step   730] loss: 0.363\n",
            "[Epoch 77, Step   740] loss: 0.284\n",
            "[Epoch 77, Step   750] loss: 0.216\n",
            "[Epoch 77, Step   760] loss: 0.082\n",
            "[Epoch 77, Step   770] loss: 0.226\n",
            "[Epoch 77, Step   780] loss: 0.284\n",
            "[Epoch 77, Step   790] loss: 0.664\n",
            "[Epoch 77, Step   800] loss: 0.184\n",
            "[Epoch 77, Step   810] loss: 0.207\n",
            "[Epoch 77, Step   820] loss: 0.093\n",
            "[Epoch 77, Step   830] loss: 0.532\n",
            "[Epoch 77, Step   840] loss: 0.252\n",
            "[Epoch 77, Step   850] loss: 0.285\n",
            "[Epoch 77, Step   860] loss: 0.179\n",
            "[Epoch 77, Step   870] loss: 0.268\n",
            "[Epoch 77, Step   880] loss: 0.337\n",
            "[Epoch 77, Step   890] loss: 0.031\n",
            "[Epoch 77, Step   900] loss: 0.153\n",
            "[Epoch 77, Step   910] loss: 0.315\n",
            "[Epoch 77, Step   920] loss: 0.176\n",
            "[Epoch 77, Step   930] loss: 0.193\n",
            "[Epoch 77, Step   940] loss: 0.184\n",
            "[Epoch 77, Step   950] loss: 0.056\n",
            "[Epoch 77, Step   960] loss: 0.246\n",
            "[Epoch 77, Step   970] loss: 0.198\n",
            "[Epoch 77, Step   980] loss: 0.188\n",
            "[Epoch 77, Step   990] loss: 0.134\n",
            "[Epoch 77, Step  1000] loss: 0.015\n",
            "[Epoch 77, Step  1010] loss: 0.302\n",
            "[Epoch 77, Step  1020] loss: 0.189\n",
            "[Epoch 77, Step  1030] loss: 0.327\n",
            "[Epoch 77, Step  1040] loss: 0.250\n",
            "[Epoch 77, Step  1050] loss: 0.130\n",
            "[Epoch 77, Step  1060] loss: 0.155\n",
            "[Epoch 77, Step  1070] loss: 0.352\n",
            "[Epoch 77, Step  1080] loss: 0.192\n",
            "[Epoch 77, Step  1090] loss: 0.164\n",
            "[Epoch 77, Step  1100] loss: 0.313\n",
            "[Epoch 77, Step  1110] loss: 0.449\n",
            "[Epoch 77, Step  1120] loss: 0.146\n",
            "[Epoch 77, Step  1130] loss: 0.074\n",
            "[Epoch 77, Step  1140] loss: 0.168\n",
            "[Epoch 77, Step  1150] loss: 0.279\n",
            "[Epoch 77, Step  1160] loss: 0.239\n",
            "[Epoch 77, Step  1170] loss: 0.072\n",
            "[Epoch 77, Step  1180] loss: 0.076\n",
            "[Epoch 77, Step  1190] loss: 0.361\n",
            "[Epoch 77, Step  1200] loss: 0.114\n",
            "[Epoch 77, Step  1210] loss: 0.263\n",
            "[Epoch 77, Step  1220] loss: 0.105\n",
            "[Epoch 77, Step  1230] loss: 0.169\n",
            "[Epoch 77, Step  1240] loss: 0.214\n",
            "[Epoch 77, Step  1250] loss: 0.106\n",
            "[Epoch 77, Step  1260] loss: 0.009\n",
            "[Epoch 77, Step  1270] loss: 0.505\n",
            "[Epoch 77, Step  1280] loss: 0.468\n",
            "[Epoch 77, Step  1290] loss: 0.361\n",
            "[Epoch 77, Step  1300] loss: 0.264\n",
            "[Epoch 77, Step  1310] loss: 0.267\n",
            "[Epoch 77, Step  1320] loss: 0.182\n",
            "[Epoch 77, Step  1330] loss: 0.317\n",
            "[Epoch 77, Step  1340] loss: 0.271\n",
            "[Epoch 77, Step  1350] loss: 0.263\n",
            "[Epoch 77, Step  1360] loss: 0.249\n",
            "[Epoch 77, Step  1370] loss: 0.241\n",
            "[Epoch 77, Step  1380] loss: 0.553\n",
            "[Epoch 77, Step  1390] loss: 0.146\n",
            "[Epoch 77, Step  1400] loss: 0.389\n",
            "[Epoch 77, Step  1410] loss: 0.225\n",
            "[Epoch 77, Step  1420] loss: 0.071\n",
            "[Epoch 77, Step  1430] loss: 0.371\n",
            "[Epoch 77, Step  1440] loss: 0.287\n",
            "[Epoch 77, Step  1450] loss: 0.130\n",
            "[Epoch 77, Step  1460] loss: 0.182\n",
            "[Epoch 77, Step  1470] loss: 0.229\n",
            "[Epoch 77, Step  1480] loss: 0.011\n",
            "[Epoch 77, Step  1490] loss: 0.354\n",
            "[Epoch 77, Step  1500] loss: 0.129\n",
            "[Epoch 77, Step  1510] loss: 0.136\n",
            "[Epoch 77, Step  1520] loss: 0.333\n",
            "[Epoch 77, Step  1530] loss: 0.176\n",
            "[Epoch 77, Step  1540] loss: 0.120\n",
            "[Epoch 77, Step  1550] loss: 0.040\n",
            "[Epoch 77, Step  1560] loss: 0.231\n",
            "[Epoch 77, Step  1570] loss: 0.167\n",
            "[Epoch 77, Step  1580] loss: 0.365\n",
            "[Epoch 77, Step  1590] loss: 0.218\n",
            "[Epoch 77, Step  1600] loss: 0.068\n",
            "[Epoch 78, Step    10] loss: 0.129\n",
            "[Epoch 78, Step    20] loss: 0.249\n",
            "[Epoch 78, Step    30] loss: 0.142\n",
            "[Epoch 78, Step    40] loss: 0.355\n",
            "[Epoch 78, Step    50] loss: 0.210\n",
            "[Epoch 78, Step    60] loss: 0.312\n",
            "[Epoch 78, Step    70] loss: 0.338\n",
            "[Epoch 78, Step    80] loss: 0.205\n",
            "[Epoch 78, Step    90] loss: 0.342\n",
            "[Epoch 78, Step   100] loss: 0.231\n",
            "[Epoch 78, Step   110] loss: 0.321\n",
            "[Epoch 78, Step   120] loss: 0.055\n",
            "[Epoch 78, Step   130] loss: 0.107\n",
            "[Epoch 78, Step   140] loss: 0.208\n",
            "[Epoch 78, Step   150] loss: 0.135\n",
            "[Epoch 78, Step   160] loss: 0.224\n",
            "[Epoch 78, Step   170] loss: 0.352\n",
            "[Epoch 78, Step   180] loss: 0.113\n",
            "[Epoch 78, Step   190] loss: 0.148\n",
            "[Epoch 78, Step   200] loss: 0.277\n",
            "[Epoch 78, Step   210] loss: 0.275\n",
            "[Epoch 78, Step   220] loss: 0.104\n",
            "[Epoch 78, Step   230] loss: 0.276\n",
            "[Epoch 78, Step   240] loss: 0.445\n",
            "[Epoch 78, Step   250] loss: 0.207\n",
            "[Epoch 78, Step   260] loss: 0.252\n",
            "[Epoch 78, Step   270] loss: 0.161\n",
            "[Epoch 78, Step   280] loss: 0.221\n",
            "[Epoch 78, Step   290] loss: 0.237\n",
            "[Epoch 78, Step   300] loss: 0.150\n",
            "[Epoch 78, Step   310] loss: 0.510\n",
            "[Epoch 78, Step   320] loss: 0.078\n",
            "[Epoch 78, Step   330] loss: 0.185\n",
            "[Epoch 78, Step   340] loss: 0.131\n",
            "[Epoch 78, Step   350] loss: 0.270\n",
            "[Epoch 78, Step   360] loss: 0.067\n",
            "[Epoch 78, Step   370] loss: 0.223\n",
            "[Epoch 78, Step   380] loss: 0.261\n",
            "[Epoch 78, Step   390] loss: 0.147\n",
            "[Epoch 78, Step   400] loss: 0.064\n",
            "[Epoch 78, Step   410] loss: 0.521\n",
            "[Epoch 78, Step   420] loss: 0.270\n",
            "[Epoch 78, Step   430] loss: 0.313\n",
            "[Epoch 78, Step   440] loss: 0.035\n",
            "[Epoch 78, Step   450] loss: 0.329\n",
            "[Epoch 78, Step   460] loss: 0.473\n",
            "[Epoch 78, Step   470] loss: 0.313\n",
            "[Epoch 78, Step   480] loss: 0.273\n",
            "[Epoch 78, Step   490] loss: 0.049\n",
            "[Epoch 78, Step   500] loss: 0.268\n",
            "[Epoch 78, Step   510] loss: 0.146\n",
            "[Epoch 78, Step   520] loss: 0.253\n",
            "[Epoch 78, Step   530] loss: 0.079\n",
            "[Epoch 78, Step   540] loss: 0.295\n",
            "[Epoch 78, Step   550] loss: 0.201\n",
            "[Epoch 78, Step   560] loss: 0.132\n",
            "[Epoch 78, Step   570] loss: 0.298\n",
            "[Epoch 78, Step   580] loss: 0.210\n",
            "[Epoch 78, Step   590] loss: 0.413\n",
            "[Epoch 78, Step   600] loss: 0.028\n",
            "[Epoch 78, Step   610] loss: 0.202\n",
            "[Epoch 78, Step   620] loss: 0.092\n",
            "[Epoch 78, Step   630] loss: 0.072\n",
            "[Epoch 78, Step   640] loss: 0.177\n",
            "[Epoch 78, Step   650] loss: 0.675\n",
            "[Epoch 78, Step   660] loss: 0.167\n",
            "[Epoch 78, Step   670] loss: 0.134\n",
            "[Epoch 78, Step   680] loss: 0.328\n",
            "[Epoch 78, Step   690] loss: 0.163\n",
            "[Epoch 78, Step   700] loss: 0.152\n",
            "[Epoch 78, Step   710] loss: 0.195\n",
            "[Epoch 78, Step   720] loss: 0.379\n",
            "[Epoch 78, Step   730] loss: 0.077\n",
            "[Epoch 78, Step   740] loss: 0.178\n",
            "[Epoch 78, Step   750] loss: 0.095\n",
            "[Epoch 78, Step   760] loss: 0.136\n",
            "[Epoch 78, Step   770] loss: 0.288\n",
            "[Epoch 78, Step   780] loss: 0.310\n",
            "[Epoch 78, Step   790] loss: 0.056\n",
            "[Epoch 78, Step   800] loss: 0.223\n",
            "[Epoch 78, Step   810] loss: 0.363\n",
            "[Epoch 78, Step   820] loss: 0.094\n",
            "[Epoch 78, Step   830] loss: 0.035\n",
            "[Epoch 78, Step   840] loss: 0.201\n",
            "[Epoch 78, Step   850] loss: 0.101\n",
            "[Epoch 78, Step   860] loss: 0.102\n",
            "[Epoch 78, Step   870] loss: 0.557\n",
            "[Epoch 78, Step   880] loss: 0.677\n",
            "[Epoch 78, Step   890] loss: 0.215\n",
            "[Epoch 78, Step   900] loss: 0.321\n",
            "[Epoch 78, Step   910] loss: 0.067\n",
            "[Epoch 78, Step   920] loss: 0.325\n",
            "[Epoch 78, Step   930] loss: 0.273\n",
            "[Epoch 78, Step   940] loss: 0.174\n",
            "[Epoch 78, Step   950] loss: 0.221\n",
            "[Epoch 78, Step   960] loss: 0.166\n",
            "[Epoch 78, Step   970] loss: 0.132\n",
            "[Epoch 78, Step   980] loss: 0.155\n",
            "[Epoch 78, Step   990] loss: 0.040\n",
            "[Epoch 78, Step  1000] loss: 0.218\n",
            "[Epoch 78, Step  1010] loss: 0.167\n",
            "[Epoch 78, Step  1020] loss: 0.184\n",
            "[Epoch 78, Step  1030] loss: 0.223\n",
            "[Epoch 78, Step  1040] loss: 0.557\n",
            "[Epoch 78, Step  1050] loss: 0.359\n",
            "[Epoch 78, Step  1060] loss: 0.281\n",
            "[Epoch 78, Step  1070] loss: 0.237\n",
            "[Epoch 78, Step  1080] loss: 0.081\n",
            "[Epoch 78, Step  1090] loss: 0.095\n",
            "[Epoch 78, Step  1100] loss: 0.506\n",
            "[Epoch 78, Step  1110] loss: 0.252\n",
            "[Epoch 78, Step  1120] loss: 0.065\n",
            "[Epoch 78, Step  1130] loss: 0.143\n",
            "[Epoch 78, Step  1140] loss: 0.249\n",
            "[Epoch 78, Step  1150] loss: 0.342\n",
            "[Epoch 78, Step  1160] loss: 0.328\n",
            "[Epoch 78, Step  1170] loss: 0.046\n",
            "[Epoch 78, Step  1180] loss: 0.165\n",
            "[Epoch 78, Step  1190] loss: 0.162\n",
            "[Epoch 78, Step  1200] loss: 0.226\n",
            "[Epoch 78, Step  1210] loss: 0.062\n",
            "[Epoch 78, Step  1220] loss: 0.101\n",
            "[Epoch 78, Step  1230] loss: 0.239\n",
            "[Epoch 78, Step  1240] loss: 0.211\n",
            "[Epoch 78, Step  1250] loss: 0.229\n",
            "[Epoch 78, Step  1260] loss: 0.085\n",
            "[Epoch 78, Step  1270] loss: 0.109\n",
            "[Epoch 78, Step  1280] loss: 0.434\n",
            "[Epoch 78, Step  1290] loss: 0.362\n",
            "[Epoch 78, Step  1300] loss: 0.430\n",
            "[Epoch 78, Step  1310] loss: 0.087\n",
            "[Epoch 78, Step  1320] loss: 0.160\n",
            "[Epoch 78, Step  1330] loss: 0.169\n",
            "[Epoch 78, Step  1340] loss: 0.223\n",
            "[Epoch 78, Step  1350] loss: 0.677\n",
            "[Epoch 78, Step  1360] loss: 0.180\n",
            "[Epoch 78, Step  1370] loss: 0.473\n",
            "[Epoch 78, Step  1380] loss: 0.268\n",
            "[Epoch 78, Step  1390] loss: 0.161\n",
            "[Epoch 78, Step  1400] loss: 0.098\n",
            "[Epoch 78, Step  1410] loss: 0.562\n",
            "[Epoch 78, Step  1420] loss: 0.328\n",
            "[Epoch 78, Step  1430] loss: 0.388\n",
            "[Epoch 78, Step  1440] loss: 0.386\n",
            "[Epoch 78, Step  1450] loss: 0.296\n",
            "[Epoch 78, Step  1460] loss: 0.087\n",
            "[Epoch 78, Step  1470] loss: 0.041\n",
            "[Epoch 78, Step  1480] loss: 0.190\n",
            "[Epoch 78, Step  1490] loss: 0.063\n",
            "[Epoch 78, Step  1500] loss: 0.109\n",
            "[Epoch 78, Step  1510] loss: 0.759\n",
            "[Epoch 78, Step  1520] loss: 0.235\n",
            "[Epoch 78, Step  1530] loss: 0.190\n",
            "[Epoch 78, Step  1540] loss: 0.305\n",
            "[Epoch 78, Step  1550] loss: 0.161\n",
            "[Epoch 78, Step  1560] loss: 0.543\n",
            "[Epoch 78, Step  1570] loss: 0.211\n",
            "[Epoch 78, Step  1580] loss: 0.102\n",
            "[Epoch 78, Step  1590] loss: 0.421\n",
            "[Epoch 78, Step  1600] loss: 0.187\n",
            "[Epoch 79, Step    10] loss: 0.432\n",
            "[Epoch 79, Step    20] loss: 0.173\n",
            "[Epoch 79, Step    30] loss: 0.165\n",
            "[Epoch 79, Step    40] loss: 0.465\n",
            "[Epoch 79, Step    50] loss: 0.193\n",
            "[Epoch 79, Step    60] loss: 0.229\n",
            "[Epoch 79, Step    70] loss: 0.157\n",
            "[Epoch 79, Step    80] loss: 0.300\n",
            "[Epoch 79, Step    90] loss: 0.241\n",
            "[Epoch 79, Step   100] loss: 0.193\n",
            "[Epoch 79, Step   110] loss: 0.046\n",
            "[Epoch 79, Step   120] loss: 0.232\n",
            "[Epoch 79, Step   130] loss: 0.446\n",
            "[Epoch 79, Step   140] loss: 0.201\n",
            "[Epoch 79, Step   150] loss: 0.091\n",
            "[Epoch 79, Step   160] loss: 0.202\n",
            "[Epoch 79, Step   170] loss: 0.256\n",
            "[Epoch 79, Step   180] loss: 0.146\n",
            "[Epoch 79, Step   190] loss: 0.347\n",
            "[Epoch 79, Step   200] loss: 0.087\n",
            "[Epoch 79, Step   210] loss: 0.085\n",
            "[Epoch 79, Step   220] loss: 0.227\n",
            "[Epoch 79, Step   230] loss: 0.113\n",
            "[Epoch 79, Step   240] loss: 0.538\n",
            "[Epoch 79, Step   250] loss: 0.087\n",
            "[Epoch 79, Step   260] loss: 0.141\n",
            "[Epoch 79, Step   270] loss: 0.370\n",
            "[Epoch 79, Step   280] loss: 0.106\n",
            "[Epoch 79, Step   290] loss: 0.157\n",
            "[Epoch 79, Step   300] loss: 0.282\n",
            "[Epoch 79, Step   310] loss: 0.175\n",
            "[Epoch 79, Step   320] loss: 0.214\n",
            "[Epoch 79, Step   330] loss: 0.111\n",
            "[Epoch 79, Step   340] loss: 0.090\n",
            "[Epoch 79, Step   350] loss: 0.311\n",
            "[Epoch 79, Step   360] loss: 0.134\n",
            "[Epoch 79, Step   370] loss: 0.063\n",
            "[Epoch 79, Step   380] loss: 0.195\n",
            "[Epoch 79, Step   390] loss: 0.158\n",
            "[Epoch 79, Step   400] loss: 0.175\n",
            "[Epoch 79, Step   410] loss: 0.232\n",
            "[Epoch 79, Step   420] loss: 0.268\n",
            "[Epoch 79, Step   430] loss: 0.120\n",
            "[Epoch 79, Step   440] loss: 0.050\n",
            "[Epoch 79, Step   450] loss: 0.070\n",
            "[Epoch 79, Step   460] loss: 0.077\n",
            "[Epoch 79, Step   470] loss: 0.061\n",
            "[Epoch 79, Step   480] loss: 0.088\n",
            "[Epoch 79, Step   490] loss: 0.196\n",
            "[Epoch 79, Step   500] loss: 0.218\n",
            "[Epoch 79, Step   510] loss: 0.279\n",
            "[Epoch 79, Step   520] loss: 0.151\n",
            "[Epoch 79, Step   530] loss: 0.156\n",
            "[Epoch 79, Step   540] loss: 0.248\n",
            "[Epoch 79, Step   550] loss: 0.405\n",
            "[Epoch 79, Step   560] loss: 0.383\n",
            "[Epoch 79, Step   570] loss: 0.220\n",
            "[Epoch 79, Step   580] loss: 0.217\n",
            "[Epoch 79, Step   590] loss: 0.176\n",
            "[Epoch 79, Step   600] loss: 0.139\n",
            "[Epoch 79, Step   610] loss: 0.275\n",
            "[Epoch 79, Step   620] loss: 0.538\n",
            "[Epoch 79, Step   630] loss: 0.097\n",
            "[Epoch 79, Step   640] loss: 0.437\n",
            "[Epoch 79, Step   650] loss: 0.290\n",
            "[Epoch 79, Step   660] loss: 0.374\n",
            "[Epoch 79, Step   670] loss: 0.377\n",
            "[Epoch 79, Step   680] loss: 0.110\n",
            "[Epoch 79, Step   690] loss: 0.294\n",
            "[Epoch 79, Step   700] loss: 0.114\n",
            "[Epoch 79, Step   710] loss: 0.207\n",
            "[Epoch 79, Step   720] loss: 0.150\n",
            "[Epoch 79, Step   730] loss: 0.246\n",
            "[Epoch 79, Step   740] loss: 0.071\n",
            "[Epoch 79, Step   750] loss: 0.212\n",
            "[Epoch 79, Step   760] loss: 0.235\n",
            "[Epoch 79, Step   770] loss: 0.218\n",
            "[Epoch 79, Step   780] loss: 0.035\n",
            "[Epoch 79, Step   790] loss: 0.374\n",
            "[Epoch 79, Step   800] loss: 0.566\n",
            "[Epoch 79, Step   810] loss: 0.198\n",
            "[Epoch 79, Step   820] loss: 0.240\n",
            "[Epoch 79, Step   830] loss: 0.371\n",
            "[Epoch 79, Step   840] loss: 0.357\n",
            "[Epoch 79, Step   850] loss: 0.057\n",
            "[Epoch 79, Step   860] loss: 0.152\n",
            "[Epoch 79, Step   870] loss: 0.508\n",
            "[Epoch 79, Step   880] loss: 0.120\n",
            "[Epoch 79, Step   890] loss: 0.175\n",
            "[Epoch 79, Step   900] loss: 0.166\n",
            "[Epoch 79, Step   910] loss: 0.218\n",
            "[Epoch 79, Step   920] loss: 0.325\n",
            "[Epoch 79, Step   930] loss: 0.126\n",
            "[Epoch 79, Step   940] loss: 0.234\n",
            "[Epoch 79, Step   950] loss: 0.198\n",
            "[Epoch 79, Step   960] loss: 0.414\n",
            "[Epoch 79, Step   970] loss: 0.442\n",
            "[Epoch 79, Step   980] loss: 0.167\n",
            "[Epoch 79, Step   990] loss: 0.136\n",
            "[Epoch 79, Step  1000] loss: 0.685\n",
            "[Epoch 79, Step  1010] loss: 0.399\n",
            "[Epoch 79, Step  1020] loss: 0.194\n",
            "[Epoch 79, Step  1030] loss: 0.114\n",
            "[Epoch 79, Step  1040] loss: 0.244\n",
            "[Epoch 79, Step  1050] loss: 0.313\n",
            "[Epoch 79, Step  1060] loss: 0.259\n",
            "[Epoch 79, Step  1070] loss: 0.103\n",
            "[Epoch 79, Step  1080] loss: 0.151\n",
            "[Epoch 79, Step  1090] loss: 0.350\n",
            "[Epoch 79, Step  1100] loss: 0.133\n",
            "[Epoch 79, Step  1110] loss: 0.264\n",
            "[Epoch 79, Step  1120] loss: 0.265\n",
            "[Epoch 79, Step  1130] loss: 0.200\n",
            "[Epoch 79, Step  1140] loss: 0.447\n",
            "[Epoch 79, Step  1150] loss: 0.244\n",
            "[Epoch 79, Step  1160] loss: 0.299\n",
            "[Epoch 79, Step  1170] loss: 0.398\n",
            "[Epoch 79, Step  1180] loss: 0.447\n",
            "[Epoch 79, Step  1190] loss: 0.325\n",
            "[Epoch 79, Step  1200] loss: 0.249\n",
            "[Epoch 79, Step  1210] loss: 0.272\n",
            "[Epoch 79, Step  1220] loss: 0.173\n",
            "[Epoch 79, Step  1230] loss: 0.474\n",
            "[Epoch 79, Step  1240] loss: 0.110\n",
            "[Epoch 79, Step  1250] loss: 0.160\n",
            "[Epoch 79, Step  1260] loss: 0.111\n",
            "[Epoch 79, Step  1270] loss: 0.017\n",
            "[Epoch 79, Step  1280] loss: 0.331\n",
            "[Epoch 79, Step  1290] loss: 0.283\n",
            "[Epoch 79, Step  1300] loss: 0.132\n",
            "[Epoch 79, Step  1310] loss: 0.052\n",
            "[Epoch 79, Step  1320] loss: 0.070\n",
            "[Epoch 79, Step  1330] loss: 0.369\n",
            "[Epoch 79, Step  1340] loss: 0.081\n",
            "[Epoch 79, Step  1350] loss: 0.300\n",
            "[Epoch 79, Step  1360] loss: 0.202\n",
            "[Epoch 79, Step  1370] loss: 0.056\n",
            "[Epoch 79, Step  1380] loss: 0.262\n",
            "[Epoch 79, Step  1390] loss: 0.334\n",
            "[Epoch 79, Step  1400] loss: 0.284\n",
            "[Epoch 79, Step  1410] loss: 0.181\n",
            "[Epoch 79, Step  1420] loss: 0.410\n",
            "[Epoch 79, Step  1430] loss: 0.240\n",
            "[Epoch 79, Step  1440] loss: 0.263\n",
            "[Epoch 79, Step  1450] loss: 0.269\n",
            "[Epoch 79, Step  1460] loss: 0.019\n",
            "[Epoch 79, Step  1470] loss: 0.605\n",
            "[Epoch 79, Step  1480] loss: 0.211\n",
            "[Epoch 79, Step  1490] loss: 0.021\n",
            "[Epoch 79, Step  1500] loss: 0.219\n",
            "[Epoch 79, Step  1510] loss: 0.313\n",
            "[Epoch 79, Step  1520] loss: 0.096\n",
            "[Epoch 79, Step  1530] loss: 0.275\n",
            "[Epoch 79, Step  1540] loss: 0.027\n",
            "[Epoch 79, Step  1550] loss: 0.305\n",
            "[Epoch 79, Step  1560] loss: 0.274\n",
            "[Epoch 79, Step  1570] loss: 0.408\n",
            "[Epoch 79, Step  1580] loss: 0.118\n",
            "[Epoch 79, Step  1590] loss: 0.106\n",
            "[Epoch 79, Step  1600] loss: 0.296\n",
            "[Epoch 80, Step    10] loss: 0.115\n",
            "[Epoch 80, Step    20] loss: 0.257\n",
            "[Epoch 80, Step    30] loss: 0.494\n",
            "[Epoch 80, Step    40] loss: 0.268\n",
            "[Epoch 80, Step    50] loss: 0.191\n",
            "[Epoch 80, Step    60] loss: 0.227\n",
            "[Epoch 80, Step    70] loss: 0.215\n",
            "[Epoch 80, Step    80] loss: 0.324\n",
            "[Epoch 80, Step    90] loss: 0.023\n",
            "[Epoch 80, Step   100] loss: 0.346\n",
            "[Epoch 80, Step   110] loss: 0.212\n",
            "[Epoch 80, Step   120] loss: 0.244\n",
            "[Epoch 80, Step   130] loss: 0.192\n",
            "[Epoch 80, Step   140] loss: 0.063\n",
            "[Epoch 80, Step   150] loss: 0.237\n",
            "[Epoch 80, Step   160] loss: 0.055\n",
            "[Epoch 80, Step   170] loss: 0.235\n",
            "[Epoch 80, Step   180] loss: 0.323\n",
            "[Epoch 80, Step   190] loss: 0.055\n",
            "[Epoch 80, Step   200] loss: 0.078\n",
            "[Epoch 80, Step   210] loss: 0.261\n",
            "[Epoch 80, Step   220] loss: 0.281\n",
            "[Epoch 80, Step   230] loss: 0.113\n",
            "[Epoch 80, Step   240] loss: 0.285\n",
            "[Epoch 80, Step   250] loss: 0.205\n",
            "[Epoch 80, Step   260] loss: 0.087\n",
            "[Epoch 80, Step   270] loss: 0.231\n",
            "[Epoch 80, Step   280] loss: 0.584\n",
            "[Epoch 80, Step   290] loss: 0.192\n",
            "[Epoch 80, Step   300] loss: 0.663\n",
            "[Epoch 80, Step   310] loss: 0.233\n",
            "[Epoch 80, Step   320] loss: 0.139\n",
            "[Epoch 80, Step   330] loss: 0.165\n",
            "[Epoch 80, Step   340] loss: 0.316\n",
            "[Epoch 80, Step   350] loss: 0.154\n",
            "[Epoch 80, Step   360] loss: 0.304\n",
            "[Epoch 80, Step   370] loss: 0.289\n",
            "[Epoch 80, Step   380] loss: 0.189\n",
            "[Epoch 80, Step   390] loss: 0.108\n",
            "[Epoch 80, Step   400] loss: 0.535\n",
            "[Epoch 80, Step   410] loss: 0.166\n",
            "[Epoch 80, Step   420] loss: 0.368\n",
            "[Epoch 80, Step   430] loss: 0.275\n",
            "[Epoch 80, Step   440] loss: 0.190\n",
            "[Epoch 80, Step   450] loss: 0.283\n",
            "[Epoch 80, Step   460] loss: 0.112\n",
            "[Epoch 80, Step   470] loss: 0.376\n",
            "[Epoch 80, Step   480] loss: 0.253\n",
            "[Epoch 80, Step   490] loss: 0.240\n",
            "[Epoch 80, Step   500] loss: 0.085\n",
            "[Epoch 80, Step   510] loss: 0.188\n",
            "[Epoch 80, Step   520] loss: 0.682\n",
            "[Epoch 80, Step   530] loss: 0.120\n",
            "[Epoch 80, Step   540] loss: 0.123\n",
            "[Epoch 80, Step   550] loss: 0.137\n",
            "[Epoch 80, Step   560] loss: 0.271\n",
            "[Epoch 80, Step   570] loss: 0.216\n",
            "[Epoch 80, Step   580] loss: 0.197\n",
            "[Epoch 80, Step   590] loss: 0.144\n",
            "[Epoch 80, Step   600] loss: 0.198\n",
            "[Epoch 80, Step   610] loss: 0.279\n",
            "[Epoch 80, Step   620] loss: 0.332\n",
            "[Epoch 80, Step   630] loss: 0.599\n",
            "[Epoch 80, Step   640] loss: 0.208\n",
            "[Epoch 80, Step   650] loss: 0.267\n",
            "[Epoch 80, Step   660] loss: 0.196\n",
            "[Epoch 80, Step   670] loss: 0.325\n",
            "[Epoch 80, Step   680] loss: 0.295\n",
            "[Epoch 80, Step   690] loss: 0.223\n",
            "[Epoch 80, Step   700] loss: 0.216\n",
            "[Epoch 80, Step   710] loss: 0.149\n",
            "[Epoch 80, Step   720] loss: 0.110\n",
            "[Epoch 80, Step   730] loss: 0.189\n",
            "[Epoch 80, Step   740] loss: 0.273\n",
            "[Epoch 80, Step   750] loss: 0.184\n",
            "[Epoch 80, Step   760] loss: 0.176\n",
            "[Epoch 80, Step   770] loss: 0.151\n",
            "[Epoch 80, Step   780] loss: 0.412\n",
            "[Epoch 80, Step   790] loss: 0.538\n",
            "[Epoch 80, Step   800] loss: 0.101\n",
            "[Epoch 80, Step   810] loss: 0.203\n",
            "[Epoch 80, Step   820] loss: 0.136\n",
            "[Epoch 80, Step   830] loss: 0.128\n",
            "[Epoch 80, Step   840] loss: 0.217\n",
            "[Epoch 80, Step   850] loss: 0.227\n",
            "[Epoch 80, Step   860] loss: 0.567\n",
            "[Epoch 80, Step   870] loss: 0.239\n",
            "[Epoch 80, Step   880] loss: 0.343\n",
            "[Epoch 80, Step   890] loss: 0.306\n",
            "[Epoch 80, Step   900] loss: 0.145\n",
            "[Epoch 80, Step   910] loss: 0.290\n",
            "[Epoch 80, Step   920] loss: 0.218\n",
            "[Epoch 80, Step   930] loss: 0.152\n",
            "[Epoch 80, Step   940] loss: 0.168\n",
            "[Epoch 80, Step   950] loss: 0.227\n",
            "[Epoch 80, Step   960] loss: 0.106\n",
            "[Epoch 80, Step   970] loss: 0.069\n",
            "[Epoch 80, Step   980] loss: 0.163\n",
            "[Epoch 80, Step   990] loss: 0.436\n",
            "[Epoch 80, Step  1000] loss: 0.209\n",
            "[Epoch 80, Step  1010] loss: 0.093\n",
            "[Epoch 80, Step  1020] loss: 0.076\n",
            "[Epoch 80, Step  1030] loss: 0.083\n",
            "[Epoch 80, Step  1040] loss: 0.150\n",
            "[Epoch 80, Step  1050] loss: 0.251\n",
            "[Epoch 80, Step  1060] loss: 0.221\n",
            "[Epoch 80, Step  1070] loss: 0.143\n",
            "[Epoch 80, Step  1080] loss: 0.070\n",
            "[Epoch 80, Step  1090] loss: 0.164\n",
            "[Epoch 80, Step  1100] loss: 0.045\n",
            "[Epoch 80, Step  1110] loss: 0.606\n",
            "[Epoch 80, Step  1120] loss: 0.250\n",
            "[Epoch 80, Step  1130] loss: 0.183\n",
            "[Epoch 80, Step  1140] loss: 0.169\n",
            "[Epoch 80, Step  1150] loss: 0.167\n",
            "[Epoch 80, Step  1160] loss: 0.374\n",
            "[Epoch 80, Step  1170] loss: 0.072\n",
            "[Epoch 80, Step  1180] loss: 0.292\n",
            "[Epoch 80, Step  1190] loss: 0.366\n",
            "[Epoch 80, Step  1200] loss: 0.066\n",
            "[Epoch 80, Step  1210] loss: 0.337\n",
            "[Epoch 80, Step  1220] loss: 0.421\n",
            "[Epoch 80, Step  1230] loss: 0.157\n",
            "[Epoch 80, Step  1240] loss: 0.549\n",
            "[Epoch 80, Step  1250] loss: 0.371\n",
            "[Epoch 80, Step  1260] loss: 0.363\n",
            "[Epoch 80, Step  1270] loss: 0.320\n",
            "[Epoch 80, Step  1280] loss: 0.095\n",
            "[Epoch 80, Step  1290] loss: 0.200\n",
            "[Epoch 80, Step  1300] loss: 0.195\n",
            "[Epoch 80, Step  1310] loss: 0.151\n",
            "[Epoch 80, Step  1320] loss: 0.104\n",
            "[Epoch 80, Step  1330] loss: 0.307\n",
            "[Epoch 80, Step  1340] loss: 0.045\n",
            "[Epoch 80, Step  1350] loss: 0.037\n",
            "[Epoch 80, Step  1360] loss: 0.388\n",
            "[Epoch 80, Step  1370] loss: 0.082\n",
            "[Epoch 80, Step  1380] loss: 0.179\n",
            "[Epoch 80, Step  1390] loss: 0.061\n",
            "[Epoch 80, Step  1400] loss: 0.106\n",
            "[Epoch 80, Step  1410] loss: 0.421\n",
            "[Epoch 80, Step  1420] loss: 0.046\n",
            "[Epoch 80, Step  1430] loss: 0.157\n",
            "[Epoch 80, Step  1440] loss: 0.110\n",
            "[Epoch 80, Step  1450] loss: 0.165\n",
            "[Epoch 80, Step  1460] loss: 0.320\n",
            "[Epoch 80, Step  1470] loss: 0.356\n",
            "[Epoch 80, Step  1480] loss: 0.274\n",
            "[Epoch 80, Step  1490] loss: 0.378\n",
            "[Epoch 80, Step  1500] loss: 0.319\n",
            "[Epoch 80, Step  1510] loss: 0.297\n",
            "[Epoch 80, Step  1520] loss: 0.098\n",
            "[Epoch 80, Step  1530] loss: 0.227\n",
            "[Epoch 80, Step  1540] loss: 0.162\n",
            "[Epoch 80, Step  1550] loss: 0.087\n",
            "[Epoch 80, Step  1560] loss: 0.162\n",
            "[Epoch 80, Step  1570] loss: 0.047\n",
            "[Epoch 80, Step  1580] loss: 0.353\n",
            "[Epoch 80, Step  1590] loss: 0.272\n",
            "[Epoch 80, Step  1600] loss: 0.439\n",
            "[Epoch 81, Step    10] loss: 0.294\n",
            "[Epoch 81, Step    20] loss: 0.216\n",
            "[Epoch 81, Step    30] loss: 0.188\n",
            "[Epoch 81, Step    40] loss: 0.314\n",
            "[Epoch 81, Step    50] loss: 0.369\n",
            "[Epoch 81, Step    60] loss: 0.159\n",
            "[Epoch 81, Step    70] loss: 0.433\n",
            "[Epoch 81, Step    80] loss: 0.281\n",
            "[Epoch 81, Step    90] loss: 0.104\n",
            "[Epoch 81, Step   100] loss: 0.097\n",
            "[Epoch 81, Step   110] loss: 0.566\n",
            "[Epoch 81, Step   120] loss: 0.056\n",
            "[Epoch 81, Step   130] loss: 0.399\n",
            "[Epoch 81, Step   140] loss: 0.131\n",
            "[Epoch 81, Step   150] loss: 0.060\n",
            "[Epoch 81, Step   160] loss: 0.256\n",
            "[Epoch 81, Step   170] loss: 0.694\n",
            "[Epoch 81, Step   180] loss: 0.244\n",
            "[Epoch 81, Step   190] loss: 0.178\n",
            "[Epoch 81, Step   200] loss: 0.138\n",
            "[Epoch 81, Step   210] loss: 0.440\n",
            "[Epoch 81, Step   220] loss: 0.094\n",
            "[Epoch 81, Step   230] loss: 0.261\n",
            "[Epoch 81, Step   240] loss: 0.255\n",
            "[Epoch 81, Step   250] loss: 0.109\n",
            "[Epoch 81, Step   260] loss: 0.134\n",
            "[Epoch 81, Step   270] loss: 0.082\n",
            "[Epoch 81, Step   280] loss: 0.191\n",
            "[Epoch 81, Step   290] loss: 0.110\n",
            "[Epoch 81, Step   300] loss: 0.352\n",
            "[Epoch 81, Step   310] loss: 0.040\n",
            "[Epoch 81, Step   320] loss: 0.509\n",
            "[Epoch 81, Step   330] loss: 0.337\n",
            "[Epoch 81, Step   340] loss: 0.387\n",
            "[Epoch 81, Step   350] loss: 0.419\n",
            "[Epoch 81, Step   360] loss: 0.223\n",
            "[Epoch 81, Step   370] loss: 0.366\n",
            "[Epoch 81, Step   380] loss: 0.260\n",
            "[Epoch 81, Step   390] loss: 0.179\n",
            "[Epoch 81, Step   400] loss: 0.185\n",
            "[Epoch 81, Step   410] loss: 0.298\n",
            "[Epoch 81, Step   420] loss: 0.280\n",
            "[Epoch 81, Step   430] loss: 0.110\n",
            "[Epoch 81, Step   440] loss: 0.059\n",
            "[Epoch 81, Step   450] loss: 0.104\n",
            "[Epoch 81, Step   460] loss: 0.307\n",
            "[Epoch 81, Step   470] loss: 0.077\n",
            "[Epoch 81, Step   480] loss: 0.422\n",
            "[Epoch 81, Step   490] loss: 0.282\n",
            "[Epoch 81, Step   500] loss: 0.094\n",
            "[Epoch 81, Step   510] loss: 0.160\n",
            "[Epoch 81, Step   520] loss: 0.144\n",
            "[Epoch 81, Step   530] loss: 0.191\n",
            "[Epoch 81, Step   540] loss: 0.193\n",
            "[Epoch 81, Step   550] loss: 0.107\n",
            "[Epoch 81, Step   560] loss: 0.219\n",
            "[Epoch 81, Step   570] loss: 0.197\n",
            "[Epoch 81, Step   580] loss: 0.029\n",
            "[Epoch 81, Step   590] loss: 0.046\n",
            "[Epoch 81, Step   600] loss: 0.244\n",
            "[Epoch 81, Step   610] loss: 0.565\n",
            "[Epoch 81, Step   620] loss: 0.065\n",
            "[Epoch 81, Step   630] loss: 0.095\n",
            "[Epoch 81, Step   640] loss: 0.179\n",
            "[Epoch 81, Step   650] loss: 0.461\n",
            "[Epoch 81, Step   660] loss: 0.134\n",
            "[Epoch 81, Step   670] loss: 0.205\n",
            "[Epoch 81, Step   680] loss: 0.127\n",
            "[Epoch 81, Step   690] loss: 0.346\n",
            "[Epoch 81, Step   700] loss: 0.128\n",
            "[Epoch 81, Step   710] loss: 0.220\n",
            "[Epoch 81, Step   720] loss: 0.275\n",
            "[Epoch 81, Step   730] loss: 0.424\n",
            "[Epoch 81, Step   740] loss: 0.208\n",
            "[Epoch 81, Step   750] loss: 0.060\n",
            "[Epoch 81, Step   760] loss: 0.263\n",
            "[Epoch 81, Step   770] loss: 0.302\n",
            "[Epoch 81, Step   780] loss: 0.356\n",
            "[Epoch 81, Step   790] loss: 0.285\n",
            "[Epoch 81, Step   800] loss: 0.089\n",
            "[Epoch 81, Step   810] loss: 0.163\n",
            "[Epoch 81, Step   820] loss: 0.161\n",
            "[Epoch 81, Step   830] loss: 0.276\n",
            "[Epoch 81, Step   840] loss: 0.192\n",
            "[Epoch 81, Step   850] loss: 0.351\n",
            "[Epoch 81, Step   860] loss: 0.090\n",
            "[Epoch 81, Step   870] loss: 0.875\n",
            "[Epoch 81, Step   880] loss: 0.258\n",
            "[Epoch 81, Step   890] loss: 0.196\n",
            "[Epoch 81, Step   900] loss: 0.188\n",
            "[Epoch 81, Step   910] loss: 0.119\n",
            "[Epoch 81, Step   920] loss: 0.182\n",
            "[Epoch 81, Step   930] loss: 0.099\n",
            "[Epoch 81, Step   940] loss: 0.314\n",
            "[Epoch 81, Step   950] loss: 0.187\n",
            "[Epoch 81, Step   960] loss: 0.158\n",
            "[Epoch 81, Step   970] loss: 0.357\n",
            "[Epoch 81, Step   980] loss: 0.151\n",
            "[Epoch 81, Step   990] loss: 0.224\n",
            "[Epoch 81, Step  1000] loss: 0.167\n",
            "[Epoch 81, Step  1010] loss: 0.114\n",
            "[Epoch 81, Step  1020] loss: 0.097\n",
            "[Epoch 81, Step  1030] loss: 0.483\n",
            "[Epoch 81, Step  1040] loss: 0.262\n",
            "[Epoch 81, Step  1050] loss: 0.165\n",
            "[Epoch 81, Step  1060] loss: 0.203\n",
            "[Epoch 81, Step  1070] loss: 0.123\n",
            "[Epoch 81, Step  1080] loss: 0.171\n",
            "[Epoch 81, Step  1090] loss: 0.330\n",
            "[Epoch 81, Step  1100] loss: 0.223\n",
            "[Epoch 81, Step  1110] loss: 0.128\n",
            "[Epoch 81, Step  1120] loss: 0.324\n",
            "[Epoch 81, Step  1130] loss: 0.139\n",
            "[Epoch 81, Step  1140] loss: 0.062\n",
            "[Epoch 81, Step  1150] loss: 0.653\n",
            "[Epoch 81, Step  1160] loss: 0.340\n",
            "[Epoch 81, Step  1170] loss: 0.656\n",
            "[Epoch 81, Step  1180] loss: 0.164\n",
            "[Epoch 81, Step  1190] loss: 0.213\n",
            "[Epoch 81, Step  1200] loss: 0.050\n",
            "[Epoch 81, Step  1210] loss: 0.119\n",
            "[Epoch 81, Step  1220] loss: 0.161\n",
            "[Epoch 81, Step  1230] loss: 0.346\n",
            "[Epoch 81, Step  1240] loss: 0.059\n",
            "[Epoch 81, Step  1250] loss: 0.195\n",
            "[Epoch 81, Step  1260] loss: 0.068\n",
            "[Epoch 81, Step  1270] loss: 0.104\n",
            "[Epoch 81, Step  1280] loss: 0.305\n",
            "[Epoch 81, Step  1290] loss: 0.304\n",
            "[Epoch 81, Step  1300] loss: 0.382\n",
            "[Epoch 81, Step  1310] loss: 0.076\n",
            "[Epoch 81, Step  1320] loss: 0.240\n",
            "[Epoch 81, Step  1330] loss: 0.499\n",
            "[Epoch 81, Step  1340] loss: 0.529\n",
            "[Epoch 81, Step  1350] loss: 0.180\n",
            "[Epoch 81, Step  1360] loss: 0.106\n",
            "[Epoch 81, Step  1370] loss: 0.139\n",
            "[Epoch 81, Step  1380] loss: 0.141\n",
            "[Epoch 81, Step  1390] loss: 0.245\n",
            "[Epoch 81, Step  1400] loss: 0.134\n",
            "[Epoch 81, Step  1410] loss: 0.448\n",
            "[Epoch 81, Step  1420] loss: 0.012\n",
            "[Epoch 81, Step  1430] loss: 0.546\n",
            "[Epoch 81, Step  1440] loss: 0.291\n",
            "[Epoch 81, Step  1450] loss: 0.112\n",
            "[Epoch 81, Step  1460] loss: 0.244\n",
            "[Epoch 81, Step  1470] loss: 0.109\n",
            "[Epoch 81, Step  1480] loss: 0.067\n",
            "[Epoch 81, Step  1490] loss: 0.168\n",
            "[Epoch 81, Step  1500] loss: 0.098\n",
            "[Epoch 81, Step  1510] loss: 0.237\n",
            "[Epoch 81, Step  1520] loss: 0.119\n",
            "[Epoch 81, Step  1530] loss: 0.022\n",
            "[Epoch 81, Step  1540] loss: 0.312\n",
            "[Epoch 81, Step  1550] loss: 0.186\n",
            "[Epoch 81, Step  1560] loss: 0.478\n",
            "[Epoch 81, Step  1570] loss: 0.094\n",
            "[Epoch 81, Step  1580] loss: 0.294\n",
            "[Epoch 81, Step  1590] loss: 0.248\n",
            "[Epoch 81, Step  1600] loss: 0.298\n",
            "[Epoch 82, Step    10] loss: 0.152\n",
            "[Epoch 82, Step    20] loss: 0.287\n",
            "[Epoch 82, Step    30] loss: 0.118\n",
            "[Epoch 82, Step    40] loss: 0.644\n",
            "[Epoch 82, Step    50] loss: 0.296\n",
            "[Epoch 82, Step    60] loss: 0.191\n",
            "[Epoch 82, Step    70] loss: 0.351\n",
            "[Epoch 82, Step    80] loss: 0.163\n",
            "[Epoch 82, Step    90] loss: 0.363\n",
            "[Epoch 82, Step   100] loss: 0.150\n",
            "[Epoch 82, Step   110] loss: 0.178\n",
            "[Epoch 82, Step   120] loss: 0.104\n",
            "[Epoch 82, Step   130] loss: 0.583\n",
            "[Epoch 82, Step   140] loss: 0.084\n",
            "[Epoch 82, Step   150] loss: 0.186\n",
            "[Epoch 82, Step   160] loss: 0.123\n",
            "[Epoch 82, Step   170] loss: 0.100\n",
            "[Epoch 82, Step   180] loss: 0.205\n",
            "[Epoch 82, Step   190] loss: 0.095\n",
            "[Epoch 82, Step   200] loss: 0.413\n",
            "[Epoch 82, Step   210] loss: 0.139\n",
            "[Epoch 82, Step   220] loss: 0.147\n",
            "[Epoch 82, Step   230] loss: 0.313\n",
            "[Epoch 82, Step   240] loss: 0.258\n",
            "[Epoch 82, Step   250] loss: 0.121\n",
            "[Epoch 82, Step   260] loss: 0.234\n",
            "[Epoch 82, Step   270] loss: 0.223\n",
            "[Epoch 82, Step   280] loss: 0.191\n",
            "[Epoch 82, Step   290] loss: 0.091\n",
            "[Epoch 82, Step   300] loss: 0.190\n",
            "[Epoch 82, Step   310] loss: 0.109\n",
            "[Epoch 82, Step   320] loss: 0.105\n",
            "[Epoch 82, Step   330] loss: 0.319\n",
            "[Epoch 82, Step   340] loss: 0.232\n",
            "[Epoch 82, Step   350] loss: 0.111\n",
            "[Epoch 82, Step   360] loss: 0.315\n",
            "[Epoch 82, Step   370] loss: 0.497\n",
            "[Epoch 82, Step   380] loss: 0.347\n",
            "[Epoch 82, Step   390] loss: 0.380\n",
            "[Epoch 82, Step   400] loss: 0.104\n",
            "[Epoch 82, Step   410] loss: 0.058\n",
            "[Epoch 82, Step   420] loss: 0.048\n",
            "[Epoch 82, Step   430] loss: 0.156\n",
            "[Epoch 82, Step   440] loss: 0.210\n",
            "[Epoch 82, Step   450] loss: 0.124\n",
            "[Epoch 82, Step   460] loss: 0.365\n",
            "[Epoch 82, Step   470] loss: 0.376\n",
            "[Epoch 82, Step   480] loss: 0.268\n",
            "[Epoch 82, Step   490] loss: 0.130\n",
            "[Epoch 82, Step   500] loss: 0.380\n",
            "[Epoch 82, Step   510] loss: 0.216\n",
            "[Epoch 82, Step   520] loss: 0.040\n",
            "[Epoch 82, Step   530] loss: 0.051\n",
            "[Epoch 82, Step   540] loss: 0.155\n",
            "[Epoch 82, Step   550] loss: 0.275\n",
            "[Epoch 82, Step   560] loss: 0.285\n",
            "[Epoch 82, Step   570] loss: 0.625\n",
            "[Epoch 82, Step   580] loss: 0.227\n",
            "[Epoch 82, Step   590] loss: 0.329\n",
            "[Epoch 82, Step   600] loss: 0.657\n",
            "[Epoch 82, Step   610] loss: 0.644\n",
            "[Epoch 82, Step   620] loss: 0.106\n",
            "[Epoch 82, Step   630] loss: 0.249\n",
            "[Epoch 82, Step   640] loss: 0.244\n",
            "[Epoch 82, Step   650] loss: 0.397\n",
            "[Epoch 82, Step   660] loss: 0.311\n",
            "[Epoch 82, Step   670] loss: 0.265\n",
            "[Epoch 82, Step   680] loss: 0.123\n",
            "[Epoch 82, Step   690] loss: 0.545\n",
            "[Epoch 82, Step   700] loss: 0.166\n",
            "[Epoch 82, Step   710] loss: 0.140\n",
            "[Epoch 82, Step   720] loss: 0.371\n",
            "[Epoch 82, Step   730] loss: 0.220\n",
            "[Epoch 82, Step   740] loss: 0.153\n",
            "[Epoch 82, Step   750] loss: 0.209\n",
            "[Epoch 82, Step   760] loss: 0.049\n",
            "[Epoch 82, Step   770] loss: 0.223\n",
            "[Epoch 82, Step   780] loss: 0.376\n",
            "[Epoch 82, Step   790] loss: 0.168\n",
            "[Epoch 82, Step   800] loss: 0.111\n",
            "[Epoch 82, Step   810] loss: 0.085\n",
            "[Epoch 82, Step   820] loss: 0.067\n",
            "[Epoch 82, Step   830] loss: 0.055\n",
            "[Epoch 82, Step   840] loss: 0.261\n",
            "[Epoch 82, Step   850] loss: 0.397\n",
            "[Epoch 82, Step   860] loss: 0.259\n",
            "[Epoch 82, Step   870] loss: 0.171\n",
            "[Epoch 82, Step   880] loss: 0.215\n",
            "[Epoch 82, Step   890] loss: 0.184\n",
            "[Epoch 82, Step   900] loss: 0.156\n",
            "[Epoch 82, Step   910] loss: 0.202\n",
            "[Epoch 82, Step   920] loss: 0.121\n",
            "[Epoch 82, Step   930] loss: 0.437\n",
            "[Epoch 82, Step   940] loss: 0.133\n",
            "[Epoch 82, Step   950] loss: 0.282\n",
            "[Epoch 82, Step   960] loss: 0.415\n",
            "[Epoch 82, Step   970] loss: 0.471\n",
            "[Epoch 82, Step   980] loss: 0.238\n",
            "[Epoch 82, Step   990] loss: 0.208\n",
            "[Epoch 82, Step  1000] loss: 0.260\n",
            "[Epoch 82, Step  1010] loss: 0.133\n",
            "[Epoch 82, Step  1020] loss: 0.422\n",
            "[Epoch 82, Step  1030] loss: 0.242\n",
            "[Epoch 82, Step  1040] loss: 0.142\n",
            "[Epoch 82, Step  1050] loss: 0.321\n",
            "[Epoch 82, Step  1060] loss: 0.164\n",
            "[Epoch 82, Step  1070] loss: 0.286\n",
            "[Epoch 82, Step  1080] loss: 0.301\n",
            "[Epoch 82, Step  1090] loss: 0.109\n",
            "[Epoch 82, Step  1100] loss: 0.057\n",
            "[Epoch 82, Step  1110] loss: 0.285\n",
            "[Epoch 82, Step  1120] loss: 0.178\n",
            "[Epoch 82, Step  1130] loss: 0.373\n",
            "[Epoch 82, Step  1140] loss: 0.147\n",
            "[Epoch 82, Step  1150] loss: 0.314\n",
            "[Epoch 82, Step  1160] loss: 0.122\n",
            "[Epoch 82, Step  1170] loss: 0.186\n",
            "[Epoch 82, Step  1180] loss: 0.398\n",
            "[Epoch 82, Step  1190] loss: 0.319\n",
            "[Epoch 82, Step  1200] loss: 0.131\n",
            "[Epoch 82, Step  1210] loss: 0.475\n",
            "[Epoch 82, Step  1220] loss: 0.174\n",
            "[Epoch 82, Step  1230] loss: 0.219\n",
            "[Epoch 82, Step  1240] loss: 0.075\n",
            "[Epoch 82, Step  1250] loss: 0.159\n",
            "[Epoch 82, Step  1260] loss: 0.229\n",
            "[Epoch 82, Step  1270] loss: 0.230\n",
            "[Epoch 82, Step  1280] loss: 0.224\n",
            "[Epoch 82, Step  1290] loss: 0.433\n",
            "[Epoch 82, Step  1300] loss: 0.249\n",
            "[Epoch 82, Step  1310] loss: 0.109\n",
            "[Epoch 82, Step  1320] loss: 0.086\n",
            "[Epoch 82, Step  1330] loss: 0.108\n",
            "[Epoch 82, Step  1340] loss: 0.101\n",
            "[Epoch 82, Step  1350] loss: 0.150\n",
            "[Epoch 82, Step  1360] loss: 0.253\n",
            "[Epoch 82, Step  1370] loss: 0.207\n",
            "[Epoch 82, Step  1380] loss: 0.370\n",
            "[Epoch 82, Step  1390] loss: 0.090\n",
            "[Epoch 82, Step  1400] loss: 0.090\n",
            "[Epoch 82, Step  1410] loss: 0.142\n",
            "[Epoch 82, Step  1420] loss: 0.253\n",
            "[Epoch 82, Step  1430] loss: 0.102\n",
            "[Epoch 82, Step  1440] loss: 0.241\n",
            "[Epoch 82, Step  1450] loss: 0.033\n",
            "[Epoch 82, Step  1460] loss: 0.564\n",
            "[Epoch 82, Step  1470] loss: 0.068\n",
            "[Epoch 82, Step  1480] loss: 0.165\n",
            "[Epoch 82, Step  1490] loss: 0.184\n",
            "[Epoch 82, Step  1500] loss: 0.146\n",
            "[Epoch 82, Step  1510] loss: 0.163\n",
            "[Epoch 82, Step  1520] loss: 0.252\n",
            "[Epoch 82, Step  1530] loss: 0.357\n",
            "[Epoch 82, Step  1540] loss: 0.271\n",
            "[Epoch 82, Step  1550] loss: 0.113\n",
            "[Epoch 82, Step  1560] loss: 0.091\n",
            "[Epoch 82, Step  1570] loss: 0.177\n",
            "[Epoch 82, Step  1580] loss: 0.350\n",
            "[Epoch 82, Step  1590] loss: 0.142\n",
            "[Epoch 82, Step  1600] loss: 0.242\n",
            "[Epoch 83, Step    10] loss: 0.118\n",
            "[Epoch 83, Step    20] loss: 0.184\n",
            "[Epoch 83, Step    30] loss: 0.156\n",
            "[Epoch 83, Step    40] loss: 0.461\n",
            "[Epoch 83, Step    50] loss: 0.132\n",
            "[Epoch 83, Step    60] loss: 0.327\n",
            "[Epoch 83, Step    70] loss: 0.215\n",
            "[Epoch 83, Step    80] loss: 0.135\n",
            "[Epoch 83, Step    90] loss: 0.334\n",
            "[Epoch 83, Step   100] loss: 0.258\n",
            "[Epoch 83, Step   110] loss: 0.327\n",
            "[Epoch 83, Step   120] loss: 0.365\n",
            "[Epoch 83, Step   130] loss: 0.148\n",
            "[Epoch 83, Step   140] loss: 0.288\n",
            "[Epoch 83, Step   150] loss: 0.368\n",
            "[Epoch 83, Step   160] loss: 0.369\n",
            "[Epoch 83, Step   170] loss: 0.034\n",
            "[Epoch 83, Step   180] loss: 0.973\n",
            "[Epoch 83, Step   190] loss: 0.204\n",
            "[Epoch 83, Step   200] loss: 0.104\n",
            "[Epoch 83, Step   210] loss: 0.457\n",
            "[Epoch 83, Step   220] loss: 0.291\n",
            "[Epoch 83, Step   230] loss: 0.170\n",
            "[Epoch 83, Step   240] loss: 0.205\n",
            "[Epoch 83, Step   250] loss: 0.205\n",
            "[Epoch 83, Step   260] loss: 0.305\n",
            "[Epoch 83, Step   270] loss: 0.343\n",
            "[Epoch 83, Step   280] loss: 0.136\n",
            "[Epoch 83, Step   290] loss: 0.184\n",
            "[Epoch 83, Step   300] loss: 0.148\n",
            "[Epoch 83, Step   310] loss: 0.219\n",
            "[Epoch 83, Step   320] loss: 0.098\n",
            "[Epoch 83, Step   330] loss: 0.047\n",
            "[Epoch 83, Step   340] loss: 0.313\n",
            "[Epoch 83, Step   350] loss: 0.321\n",
            "[Epoch 83, Step   360] loss: 0.078\n",
            "[Epoch 83, Step   370] loss: 0.332\n",
            "[Epoch 83, Step   380] loss: 0.203\n",
            "[Epoch 83, Step   390] loss: 0.048\n",
            "[Epoch 83, Step   400] loss: 0.373\n",
            "[Epoch 83, Step   410] loss: 0.170\n",
            "[Epoch 83, Step   420] loss: 0.110\n",
            "[Epoch 83, Step   430] loss: 0.080\n",
            "[Epoch 83, Step   440] loss: 0.365\n",
            "[Epoch 83, Step   450] loss: 0.173\n",
            "[Epoch 83, Step   460] loss: 0.345\n",
            "[Epoch 83, Step   470] loss: 0.247\n",
            "[Epoch 83, Step   480] loss: 0.130\n",
            "[Epoch 83, Step   490] loss: 0.287\n",
            "[Epoch 83, Step   500] loss: 0.055\n",
            "[Epoch 83, Step   510] loss: 0.578\n",
            "[Epoch 83, Step   520] loss: 0.422\n",
            "[Epoch 83, Step   530] loss: 0.186\n",
            "[Epoch 83, Step   540] loss: 0.089\n",
            "[Epoch 83, Step   550] loss: 0.158\n",
            "[Epoch 83, Step   560] loss: 0.200\n",
            "[Epoch 83, Step   570] loss: 0.567\n",
            "[Epoch 83, Step   580] loss: 0.172\n",
            "[Epoch 83, Step   590] loss: 0.374\n",
            "[Epoch 83, Step   600] loss: 0.061\n",
            "[Epoch 83, Step   610] loss: 0.449\n",
            "[Epoch 83, Step   620] loss: 0.063\n",
            "[Epoch 83, Step   630] loss: 0.322\n",
            "[Epoch 83, Step   640] loss: 0.115\n",
            "[Epoch 83, Step   650] loss: 0.091\n",
            "[Epoch 83, Step   660] loss: 0.109\n",
            "[Epoch 83, Step   670] loss: 0.399\n",
            "[Epoch 83, Step   680] loss: 0.288\n",
            "[Epoch 83, Step   690] loss: 0.065\n",
            "[Epoch 83, Step   700] loss: 0.147\n",
            "[Epoch 83, Step   710] loss: 0.207\n",
            "[Epoch 83, Step   720] loss: 0.085\n",
            "[Epoch 83, Step   730] loss: 0.203\n",
            "[Epoch 83, Step   740] loss: 0.027\n",
            "[Epoch 83, Step   750] loss: 0.211\n",
            "[Epoch 83, Step   760] loss: 0.189\n",
            "[Epoch 83, Step   770] loss: 0.158\n",
            "[Epoch 83, Step   780] loss: 0.126\n",
            "[Epoch 83, Step   790] loss: 0.259\n",
            "[Epoch 83, Step   800] loss: 0.244\n",
            "[Epoch 83, Step   810] loss: 0.079\n",
            "[Epoch 83, Step   820] loss: 0.183\n",
            "[Epoch 83, Step   830] loss: 0.031\n",
            "[Epoch 83, Step   840] loss: 0.495\n",
            "[Epoch 83, Step   850] loss: 0.125\n",
            "[Epoch 83, Step   860] loss: 0.252\n",
            "[Epoch 83, Step   870] loss: 0.103\n",
            "[Epoch 83, Step   880] loss: 0.119\n",
            "[Epoch 83, Step   890] loss: 0.143\n",
            "[Epoch 83, Step   900] loss: 0.461\n",
            "[Epoch 83, Step   910] loss: 0.389\n",
            "[Epoch 83, Step   920] loss: 0.064\n",
            "[Epoch 83, Step   930] loss: 0.542\n",
            "[Epoch 83, Step   940] loss: 0.136\n",
            "[Epoch 83, Step   950] loss: 0.337\n",
            "[Epoch 83, Step   960] loss: 0.120\n",
            "[Epoch 83, Step   970] loss: 0.208\n",
            "[Epoch 83, Step   980] loss: 0.180\n",
            "[Epoch 83, Step   990] loss: 0.505\n",
            "[Epoch 83, Step  1000] loss: 0.123\n",
            "[Epoch 83, Step  1010] loss: 0.269\n",
            "[Epoch 83, Step  1020] loss: 0.166\n",
            "[Epoch 83, Step  1030] loss: 0.177\n",
            "[Epoch 83, Step  1040] loss: 0.099\n",
            "[Epoch 83, Step  1050] loss: 0.202\n",
            "[Epoch 83, Step  1060] loss: 0.069\n",
            "[Epoch 83, Step  1070] loss: 0.429\n",
            "[Epoch 83, Step  1080] loss: 0.250\n",
            "[Epoch 83, Step  1090] loss: 0.316\n",
            "[Epoch 83, Step  1100] loss: 0.163\n",
            "[Epoch 83, Step  1110] loss: 0.297\n",
            "[Epoch 83, Step  1120] loss: 0.306\n",
            "[Epoch 83, Step  1130] loss: 0.049\n",
            "[Epoch 83, Step  1140] loss: 0.289\n",
            "[Epoch 83, Step  1150] loss: 0.050\n",
            "[Epoch 83, Step  1160] loss: 0.129\n",
            "[Epoch 83, Step  1170] loss: 0.556\n",
            "[Epoch 83, Step  1180] loss: 0.184\n",
            "[Epoch 83, Step  1190] loss: 0.093\n",
            "[Epoch 83, Step  1200] loss: 0.097\n",
            "[Epoch 83, Step  1210] loss: 0.441\n",
            "[Epoch 83, Step  1220] loss: 0.436\n",
            "[Epoch 83, Step  1230] loss: 0.211\n",
            "[Epoch 83, Step  1240] loss: 0.290\n",
            "[Epoch 83, Step  1250] loss: 0.347\n",
            "[Epoch 83, Step  1260] loss: 0.124\n",
            "[Epoch 83, Step  1270] loss: 0.125\n",
            "[Epoch 83, Step  1280] loss: 0.578\n",
            "[Epoch 83, Step  1290] loss: 0.137\n",
            "[Epoch 83, Step  1300] loss: 0.189\n",
            "[Epoch 83, Step  1310] loss: 0.143\n",
            "[Epoch 83, Step  1320] loss: 0.150\n",
            "[Epoch 83, Step  1330] loss: 0.086\n",
            "[Epoch 83, Step  1340] loss: 0.277\n",
            "[Epoch 83, Step  1350] loss: 0.195\n",
            "[Epoch 83, Step  1360] loss: 0.230\n",
            "[Epoch 83, Step  1370] loss: 0.050\n",
            "[Epoch 83, Step  1380] loss: 0.191\n",
            "[Epoch 83, Step  1390] loss: 0.154\n",
            "[Epoch 83, Step  1400] loss: 0.285\n",
            "[Epoch 83, Step  1410] loss: 0.070\n",
            "[Epoch 83, Step  1420] loss: 0.237\n",
            "[Epoch 83, Step  1430] loss: 0.349\n",
            "[Epoch 83, Step  1440] loss: 0.146\n",
            "[Epoch 83, Step  1450] loss: 0.560\n",
            "[Epoch 83, Step  1460] loss: 0.238\n",
            "[Epoch 83, Step  1470] loss: 0.819\n",
            "[Epoch 83, Step  1480] loss: 0.386\n",
            "[Epoch 83, Step  1490] loss: 0.155\n",
            "[Epoch 83, Step  1500] loss: 0.107\n",
            "[Epoch 83, Step  1510] loss: 0.121\n",
            "[Epoch 83, Step  1520] loss: 0.306\n",
            "[Epoch 83, Step  1530] loss: 0.084\n",
            "[Epoch 83, Step  1540] loss: 0.170\n",
            "[Epoch 83, Step  1550] loss: 0.083\n",
            "[Epoch 83, Step  1560] loss: 0.044\n",
            "[Epoch 83, Step  1570] loss: 0.217\n",
            "[Epoch 83, Step  1580] loss: 0.065\n",
            "[Epoch 83, Step  1590] loss: 0.294\n",
            "[Epoch 83, Step  1600] loss: 0.100\n",
            "[Epoch 84, Step    10] loss: 0.339\n",
            "[Epoch 84, Step    20] loss: 0.011\n",
            "[Epoch 84, Step    30] loss: 0.046\n",
            "[Epoch 84, Step    40] loss: 0.032\n",
            "[Epoch 84, Step    50] loss: 0.410\n",
            "[Epoch 84, Step    60] loss: 0.665\n",
            "[Epoch 84, Step    70] loss: 0.068\n",
            "[Epoch 84, Step    80] loss: 0.364\n",
            "[Epoch 84, Step    90] loss: 0.059\n",
            "[Epoch 84, Step   100] loss: 0.144\n",
            "[Epoch 84, Step   110] loss: 0.227\n",
            "[Epoch 84, Step   120] loss: 0.160\n",
            "[Epoch 84, Step   130] loss: 0.050\n",
            "[Epoch 84, Step   140] loss: 0.122\n",
            "[Epoch 84, Step   150] loss: 0.449\n",
            "[Epoch 84, Step   160] loss: 0.173\n",
            "[Epoch 84, Step   170] loss: 0.110\n",
            "[Epoch 84, Step   180] loss: 0.161\n",
            "[Epoch 84, Step   190] loss: 0.346\n",
            "[Epoch 84, Step   200] loss: 0.141\n",
            "[Epoch 84, Step   210] loss: 0.116\n",
            "[Epoch 84, Step   220] loss: 0.352\n",
            "[Epoch 84, Step   230] loss: 0.318\n",
            "[Epoch 84, Step   240] loss: 0.141\n",
            "[Epoch 84, Step   250] loss: 0.214\n",
            "[Epoch 84, Step   260] loss: 0.113\n",
            "[Epoch 84, Step   270] loss: 0.226\n",
            "[Epoch 84, Step   280] loss: 0.115\n",
            "[Epoch 84, Step   290] loss: 0.152\n",
            "[Epoch 84, Step   300] loss: 0.174\n",
            "[Epoch 84, Step   310] loss: 0.383\n",
            "[Epoch 84, Step   320] loss: 0.115\n",
            "[Epoch 84, Step   330] loss: 0.432\n",
            "[Epoch 84, Step   340] loss: 0.231\n",
            "[Epoch 84, Step   350] loss: 0.039\n",
            "[Epoch 84, Step   360] loss: 0.097\n",
            "[Epoch 84, Step   370] loss: 0.189\n",
            "[Epoch 84, Step   380] loss: 0.138\n",
            "[Epoch 84, Step   390] loss: 0.343\n",
            "[Epoch 84, Step   400] loss: 0.240\n",
            "[Epoch 84, Step   410] loss: 0.408\n",
            "[Epoch 84, Step   420] loss: 0.288\n",
            "[Epoch 84, Step   430] loss: 0.122\n",
            "[Epoch 84, Step   440] loss: 0.252\n",
            "[Epoch 84, Step   450] loss: 0.138\n",
            "[Epoch 84, Step   460] loss: 0.116\n",
            "[Epoch 84, Step   470] loss: 0.069\n",
            "[Epoch 84, Step   480] loss: 0.235\n",
            "[Epoch 84, Step   490] loss: 0.065\n",
            "[Epoch 84, Step   500] loss: 0.211\n",
            "[Epoch 84, Step   510] loss: 0.254\n",
            "[Epoch 84, Step   520] loss: 0.110\n",
            "[Epoch 84, Step   530] loss: 0.541\n",
            "[Epoch 84, Step   540] loss: 0.302\n",
            "[Epoch 84, Step   550] loss: 0.243\n",
            "[Epoch 84, Step   560] loss: 0.078\n",
            "[Epoch 84, Step   570] loss: 0.422\n",
            "[Epoch 84, Step   580] loss: 0.375\n",
            "[Epoch 84, Step   590] loss: 0.066\n",
            "[Epoch 84, Step   600] loss: 0.228\n",
            "[Epoch 84, Step   610] loss: 0.276\n",
            "[Epoch 84, Step   620] loss: 0.241\n",
            "[Epoch 84, Step   630] loss: 0.080\n",
            "[Epoch 84, Step   640] loss: 0.260\n",
            "[Epoch 84, Step   650] loss: 0.434\n",
            "[Epoch 84, Step   660] loss: 0.312\n",
            "[Epoch 84, Step   670] loss: 0.157\n",
            "[Epoch 84, Step   680] loss: 0.085\n",
            "[Epoch 84, Step   690] loss: 0.067\n",
            "[Epoch 84, Step   700] loss: 0.155\n",
            "[Epoch 84, Step   710] loss: 0.271\n",
            "[Epoch 84, Step   720] loss: 0.135\n",
            "[Epoch 84, Step   730] loss: 0.096\n",
            "[Epoch 84, Step   740] loss: 0.189\n",
            "[Epoch 84, Step   750] loss: 0.129\n",
            "[Epoch 84, Step   760] loss: 0.193\n",
            "[Epoch 84, Step   770] loss: 0.100\n",
            "[Epoch 84, Step   780] loss: 0.193\n",
            "[Epoch 84, Step   790] loss: 0.074\n",
            "[Epoch 84, Step   800] loss: 0.553\n",
            "[Epoch 84, Step   810] loss: 0.458\n",
            "[Epoch 84, Step   820] loss: 0.208\n",
            "[Epoch 84, Step   830] loss: 0.042\n",
            "[Epoch 84, Step   840] loss: 0.315\n",
            "[Epoch 84, Step   850] loss: 0.282\n",
            "[Epoch 84, Step   860] loss: 0.488\n",
            "[Epoch 84, Step   870] loss: 0.035\n",
            "[Epoch 84, Step   880] loss: 0.725\n",
            "[Epoch 84, Step   890] loss: 0.305\n",
            "[Epoch 84, Step   900] loss: 0.142\n",
            "[Epoch 84, Step   910] loss: 0.314\n",
            "[Epoch 84, Step   920] loss: 0.224\n",
            "[Epoch 84, Step   930] loss: 0.215\n",
            "[Epoch 84, Step   940] loss: 0.520\n",
            "[Epoch 84, Step   950] loss: 0.614\n",
            "[Epoch 84, Step   960] loss: 0.080\n",
            "[Epoch 84, Step   970] loss: 0.067\n",
            "[Epoch 84, Step   980] loss: 0.056\n",
            "[Epoch 84, Step   990] loss: 0.182\n",
            "[Epoch 84, Step  1000] loss: 0.070\n",
            "[Epoch 84, Step  1010] loss: 0.369\n",
            "[Epoch 84, Step  1020] loss: 0.169\n",
            "[Epoch 84, Step  1030] loss: 0.212\n",
            "[Epoch 84, Step  1040] loss: 0.128\n",
            "[Epoch 84, Step  1050] loss: 0.249\n",
            "[Epoch 84, Step  1060] loss: 0.335\n",
            "[Epoch 84, Step  1070] loss: 0.412\n",
            "[Epoch 84, Step  1080] loss: 0.319\n",
            "[Epoch 84, Step  1090] loss: 0.338\n",
            "[Epoch 84, Step  1100] loss: 0.511\n",
            "[Epoch 84, Step  1110] loss: 0.549\n",
            "[Epoch 84, Step  1120] loss: 0.504\n",
            "[Epoch 84, Step  1130] loss: 0.116\n",
            "[Epoch 84, Step  1140] loss: 0.223\n",
            "[Epoch 84, Step  1150] loss: 0.223\n",
            "[Epoch 84, Step  1160] loss: 0.050\n",
            "[Epoch 84, Step  1170] loss: 0.205\n",
            "[Epoch 84, Step  1180] loss: 0.159\n",
            "[Epoch 84, Step  1190] loss: 0.288\n",
            "[Epoch 84, Step  1200] loss: 0.240\n",
            "[Epoch 84, Step  1210] loss: 0.203\n",
            "[Epoch 84, Step  1220] loss: 0.315\n",
            "[Epoch 84, Step  1230] loss: 0.230\n",
            "[Epoch 84, Step  1240] loss: 0.217\n",
            "[Epoch 84, Step  1250] loss: 0.260\n",
            "[Epoch 84, Step  1260] loss: 0.299\n",
            "[Epoch 84, Step  1270] loss: 0.325\n",
            "[Epoch 84, Step  1280] loss: 0.225\n",
            "[Epoch 84, Step  1290] loss: 0.312\n",
            "[Epoch 84, Step  1300] loss: 0.126\n",
            "[Epoch 84, Step  1310] loss: 0.071\n",
            "[Epoch 84, Step  1320] loss: 0.146\n",
            "[Epoch 84, Step  1330] loss: 0.583\n",
            "[Epoch 84, Step  1340] loss: 0.511\n",
            "[Epoch 84, Step  1350] loss: 0.106\n",
            "[Epoch 84, Step  1360] loss: 0.185\n",
            "[Epoch 84, Step  1370] loss: 0.076\n",
            "[Epoch 84, Step  1380] loss: 0.421\n",
            "[Epoch 84, Step  1390] loss: 0.269\n",
            "[Epoch 84, Step  1400] loss: 0.054\n",
            "[Epoch 84, Step  1410] loss: 0.289\n",
            "[Epoch 84, Step  1420] loss: 0.248\n",
            "[Epoch 84, Step  1430] loss: 0.123\n",
            "[Epoch 84, Step  1440] loss: 0.236\n",
            "[Epoch 84, Step  1450] loss: 0.369\n",
            "[Epoch 84, Step  1460] loss: 0.076\n",
            "[Epoch 84, Step  1470] loss: 0.245\n",
            "[Epoch 84, Step  1480] loss: 0.067\n",
            "[Epoch 84, Step  1490] loss: 0.077\n",
            "[Epoch 84, Step  1500] loss: 0.246\n",
            "[Epoch 84, Step  1510] loss: 0.145\n",
            "[Epoch 84, Step  1520] loss: 0.099\n",
            "[Epoch 84, Step  1530] loss: 0.173\n",
            "[Epoch 84, Step  1540] loss: 0.135\n",
            "[Epoch 84, Step  1550] loss: 0.057\n",
            "[Epoch 84, Step  1560] loss: 0.172\n",
            "[Epoch 84, Step  1570] loss: 0.251\n",
            "[Epoch 84, Step  1580] loss: 0.178\n",
            "[Epoch 84, Step  1590] loss: 0.315\n",
            "[Epoch 84, Step  1600] loss: 0.122\n",
            "[Epoch 85, Step    10] loss: 0.310\n",
            "[Epoch 85, Step    20] loss: 0.187\n",
            "[Epoch 85, Step    30] loss: 0.508\n",
            "[Epoch 85, Step    40] loss: 0.090\n",
            "[Epoch 85, Step    50] loss: 0.250\n",
            "[Epoch 85, Step    60] loss: 0.119\n",
            "[Epoch 85, Step    70] loss: 0.061\n",
            "[Epoch 85, Step    80] loss: 0.235\n",
            "[Epoch 85, Step    90] loss: 0.454\n",
            "[Epoch 85, Step   100] loss: 0.100\n",
            "[Epoch 85, Step   110] loss: 0.014\n",
            "[Epoch 85, Step   120] loss: 0.168\n",
            "[Epoch 85, Step   130] loss: 0.182\n",
            "[Epoch 85, Step   140] loss: 0.453\n",
            "[Epoch 85, Step   150] loss: 0.100\n",
            "[Epoch 85, Step   160] loss: 0.086\n",
            "[Epoch 85, Step   170] loss: 0.270\n",
            "[Epoch 85, Step   180] loss: 0.150\n",
            "[Epoch 85, Step   190] loss: 0.472\n",
            "[Epoch 85, Step   200] loss: 0.173\n",
            "[Epoch 85, Step   210] loss: 0.312\n",
            "[Epoch 85, Step   220] loss: 0.155\n",
            "[Epoch 85, Step   230] loss: 0.030\n",
            "[Epoch 85, Step   240] loss: 0.131\n",
            "[Epoch 85, Step   250] loss: 0.157\n",
            "[Epoch 85, Step   260] loss: 0.205\n",
            "[Epoch 85, Step   270] loss: 0.137\n",
            "[Epoch 85, Step   280] loss: 0.355\n",
            "[Epoch 85, Step   290] loss: 0.176\n",
            "[Epoch 85, Step   300] loss: 0.199\n",
            "[Epoch 85, Step   310] loss: 0.018\n",
            "[Epoch 85, Step   320] loss: 0.235\n",
            "[Epoch 85, Step   330] loss: 0.439\n",
            "[Epoch 85, Step   340] loss: 0.425\n",
            "[Epoch 85, Step   350] loss: 0.238\n",
            "[Epoch 85, Step   360] loss: 0.190\n",
            "[Epoch 85, Step   370] loss: 0.085\n",
            "[Epoch 85, Step   380] loss: 0.234\n",
            "[Epoch 85, Step   390] loss: 0.174\n",
            "[Epoch 85, Step   400] loss: 0.085\n",
            "[Epoch 85, Step   410] loss: 0.082\n",
            "[Epoch 85, Step   420] loss: 0.227\n",
            "[Epoch 85, Step   430] loss: 0.114\n",
            "[Epoch 85, Step   440] loss: 0.316\n",
            "[Epoch 85, Step   450] loss: 0.207\n",
            "[Epoch 85, Step   460] loss: 0.477\n",
            "[Epoch 85, Step   470] loss: 0.129\n",
            "[Epoch 85, Step   480] loss: 0.128\n",
            "[Epoch 85, Step   490] loss: 0.394\n",
            "[Epoch 85, Step   500] loss: 0.331\n",
            "[Epoch 85, Step   510] loss: 0.215\n",
            "[Epoch 85, Step   520] loss: 0.053\n",
            "[Epoch 85, Step   530] loss: 0.452\n",
            "[Epoch 85, Step   540] loss: 0.109\n",
            "[Epoch 85, Step   550] loss: 0.180\n",
            "[Epoch 85, Step   560] loss: 0.055\n",
            "[Epoch 85, Step   570] loss: 0.224\n",
            "[Epoch 85, Step   580] loss: 0.224\n",
            "[Epoch 85, Step   590] loss: 0.357\n",
            "[Epoch 85, Step   600] loss: 0.524\n",
            "[Epoch 85, Step   610] loss: 0.366\n",
            "[Epoch 85, Step   620] loss: 0.212\n",
            "[Epoch 85, Step   630] loss: 0.180\n",
            "[Epoch 85, Step   640] loss: 0.176\n",
            "[Epoch 85, Step   650] loss: 0.461\n",
            "[Epoch 85, Step   660] loss: 0.661\n",
            "[Epoch 85, Step   670] loss: 0.210\n",
            "[Epoch 85, Step   680] loss: 0.089\n",
            "[Epoch 85, Step   690] loss: 0.072\n",
            "[Epoch 85, Step   700] loss: 0.074\n",
            "[Epoch 85, Step   710] loss: 0.270\n",
            "[Epoch 85, Step   720] loss: 0.142\n",
            "[Epoch 85, Step   730] loss: 0.042\n",
            "[Epoch 85, Step   740] loss: 0.318\n",
            "[Epoch 85, Step   750] loss: 0.456\n",
            "[Epoch 85, Step   760] loss: 0.070\n",
            "[Epoch 85, Step   770] loss: 0.366\n",
            "[Epoch 85, Step   780] loss: 0.285\n",
            "[Epoch 85, Step   790] loss: 0.121\n",
            "[Epoch 85, Step   800] loss: 0.179\n",
            "[Epoch 85, Step   810] loss: 0.103\n",
            "[Epoch 85, Step   820] loss: 0.131\n",
            "[Epoch 85, Step   830] loss: 0.075\n",
            "[Epoch 85, Step   840] loss: 0.790\n",
            "[Epoch 85, Step   850] loss: 0.098\n",
            "[Epoch 85, Step   860] loss: 0.232\n",
            "[Epoch 85, Step   870] loss: 0.114\n",
            "[Epoch 85, Step   880] loss: 0.364\n",
            "[Epoch 85, Step   890] loss: 0.146\n",
            "[Epoch 85, Step   900] loss: 0.206\n",
            "[Epoch 85, Step   910] loss: 0.240\n",
            "[Epoch 85, Step   920] loss: 0.241\n",
            "[Epoch 85, Step   930] loss: 0.105\n",
            "[Epoch 85, Step   940] loss: 0.263\n",
            "[Epoch 85, Step   950] loss: 0.067\n",
            "[Epoch 85, Step   960] loss: 0.391\n",
            "[Epoch 85, Step   970] loss: 0.157\n",
            "[Epoch 85, Step   980] loss: 0.489\n",
            "[Epoch 85, Step   990] loss: 0.142\n",
            "[Epoch 85, Step  1000] loss: 0.197\n",
            "[Epoch 85, Step  1010] loss: 0.082\n",
            "[Epoch 85, Step  1020] loss: 0.145\n",
            "[Epoch 85, Step  1030] loss: 0.475\n",
            "[Epoch 85, Step  1040] loss: 0.143\n",
            "[Epoch 85, Step  1050] loss: 0.105\n",
            "[Epoch 85, Step  1060] loss: 0.166\n",
            "[Epoch 85, Step  1070] loss: 0.307\n",
            "[Epoch 85, Step  1080] loss: 0.301\n",
            "[Epoch 85, Step  1090] loss: 0.314\n",
            "[Epoch 85, Step  1100] loss: 0.240\n",
            "[Epoch 85, Step  1110] loss: 0.544\n",
            "[Epoch 85, Step  1120] loss: 0.123\n",
            "[Epoch 85, Step  1130] loss: 0.433\n",
            "[Epoch 85, Step  1140] loss: 0.204\n",
            "[Epoch 85, Step  1150] loss: 0.233\n",
            "[Epoch 85, Step  1160] loss: 0.052\n",
            "[Epoch 85, Step  1170] loss: 0.200\n",
            "[Epoch 85, Step  1180] loss: 0.191\n",
            "[Epoch 85, Step  1190] loss: 0.193\n",
            "[Epoch 85, Step  1200] loss: 0.100\n",
            "[Epoch 85, Step  1210] loss: 0.346\n",
            "[Epoch 85, Step  1220] loss: 0.023\n",
            "[Epoch 85, Step  1230] loss: 0.095\n",
            "[Epoch 85, Step  1240] loss: 0.220\n",
            "[Epoch 85, Step  1250] loss: 0.065\n",
            "[Epoch 85, Step  1260] loss: 0.411\n",
            "[Epoch 85, Step  1270] loss: 0.047\n",
            "[Epoch 85, Step  1280] loss: 0.056\n",
            "[Epoch 85, Step  1290] loss: 0.037\n",
            "[Epoch 85, Step  1300] loss: 0.205\n",
            "[Epoch 85, Step  1310] loss: 0.244\n",
            "[Epoch 85, Step  1320] loss: 0.086\n",
            "[Epoch 85, Step  1330] loss: 0.178\n",
            "[Epoch 85, Step  1340] loss: 0.169\n",
            "[Epoch 85, Step  1350] loss: 0.412\n",
            "[Epoch 85, Step  1360] loss: 0.138\n",
            "[Epoch 85, Step  1370] loss: 0.102\n",
            "[Epoch 85, Step  1380] loss: 0.209\n",
            "[Epoch 85, Step  1390] loss: 0.147\n",
            "[Epoch 85, Step  1400] loss: 0.221\n",
            "[Epoch 85, Step  1410] loss: 0.489\n",
            "[Epoch 85, Step  1420] loss: 0.192\n",
            "[Epoch 85, Step  1430] loss: 0.116\n",
            "[Epoch 85, Step  1440] loss: 0.590\n",
            "[Epoch 85, Step  1450] loss: 0.276\n",
            "[Epoch 85, Step  1460] loss: 0.167\n",
            "[Epoch 85, Step  1470] loss: 0.103\n",
            "[Epoch 85, Step  1480] loss: 0.401\n",
            "[Epoch 85, Step  1490] loss: 0.384\n",
            "[Epoch 85, Step  1500] loss: 0.248\n",
            "[Epoch 85, Step  1510] loss: 0.185\n",
            "[Epoch 85, Step  1520] loss: 0.179\n",
            "[Epoch 85, Step  1530] loss: 0.520\n",
            "[Epoch 85, Step  1540] loss: 0.325\n",
            "[Epoch 85, Step  1550] loss: 0.130\n",
            "[Epoch 85, Step  1560] loss: 0.125\n",
            "[Epoch 85, Step  1570] loss: 0.560\n",
            "[Epoch 85, Step  1580] loss: 0.365\n",
            "[Epoch 85, Step  1590] loss: 0.327\n",
            "[Epoch 85, Step  1600] loss: 0.144\n",
            "[Epoch 86, Step    10] loss: 0.184\n",
            "[Epoch 86, Step    20] loss: 0.127\n",
            "[Epoch 86, Step    30] loss: 0.438\n",
            "[Epoch 86, Step    40] loss: 0.093\n",
            "[Epoch 86, Step    50] loss: 0.046\n",
            "[Epoch 86, Step    60] loss: 0.032\n",
            "[Epoch 86, Step    70] loss: 0.587\n",
            "[Epoch 86, Step    80] loss: 0.355\n",
            "[Epoch 86, Step    90] loss: 0.283\n",
            "[Epoch 86, Step   100] loss: 0.035\n",
            "[Epoch 86, Step   110] loss: 0.072\n",
            "[Epoch 86, Step   120] loss: 0.381\n",
            "[Epoch 86, Step   130] loss: 0.396\n",
            "[Epoch 86, Step   140] loss: 0.067\n",
            "[Epoch 86, Step   150] loss: 0.187\n",
            "[Epoch 86, Step   160] loss: 0.072\n",
            "[Epoch 86, Step   170] loss: 0.189\n",
            "[Epoch 86, Step   180] loss: 0.381\n",
            "[Epoch 86, Step   190] loss: 0.346\n",
            "[Epoch 86, Step   200] loss: 0.067\n",
            "[Epoch 86, Step   210] loss: 0.047\n",
            "[Epoch 86, Step   220] loss: 0.532\n",
            "[Epoch 86, Step   230] loss: 0.169\n",
            "[Epoch 86, Step   240] loss: 0.128\n",
            "[Epoch 86, Step   250] loss: 0.578\n",
            "[Epoch 86, Step   260] loss: 0.267\n",
            "[Epoch 86, Step   270] loss: 0.357\n",
            "[Epoch 86, Step   280] loss: 0.167\n",
            "[Epoch 86, Step   290] loss: 0.028\n",
            "[Epoch 86, Step   300] loss: 0.135\n",
            "[Epoch 86, Step   310] loss: 0.775\n",
            "[Epoch 86, Step   320] loss: 0.380\n",
            "[Epoch 86, Step   330] loss: 0.224\n",
            "[Epoch 86, Step   340] loss: 0.616\n",
            "[Epoch 86, Step   350] loss: 0.145\n",
            "[Epoch 86, Step   360] loss: 0.480\n",
            "[Epoch 86, Step   370] loss: 0.117\n",
            "[Epoch 86, Step   380] loss: 0.060\n",
            "[Epoch 86, Step   390] loss: 0.110\n",
            "[Epoch 86, Step   400] loss: 0.050\n",
            "[Epoch 86, Step   410] loss: 0.416\n",
            "[Epoch 86, Step   420] loss: 0.438\n",
            "[Epoch 86, Step   430] loss: 0.083\n",
            "[Epoch 86, Step   440] loss: 0.395\n",
            "[Epoch 86, Step   450] loss: 0.208\n",
            "[Epoch 86, Step   460] loss: 0.100\n",
            "[Epoch 86, Step   470] loss: 0.144\n",
            "[Epoch 86, Step   480] loss: 0.287\n",
            "[Epoch 86, Step   490] loss: 0.092\n",
            "[Epoch 86, Step   500] loss: 0.129\n",
            "[Epoch 86, Step   510] loss: 0.076\n",
            "[Epoch 86, Step   520] loss: 0.278\n",
            "[Epoch 86, Step   530] loss: 0.695\n",
            "[Epoch 86, Step   540] loss: 0.136\n",
            "[Epoch 86, Step   550] loss: 0.313\n",
            "[Epoch 86, Step   560] loss: 0.155\n",
            "[Epoch 86, Step   570] loss: 0.626\n",
            "[Epoch 86, Step   580] loss: 0.110\n",
            "[Epoch 86, Step   590] loss: 0.593\n",
            "[Epoch 86, Step   600] loss: 0.068\n",
            "[Epoch 86, Step   610] loss: 0.124\n",
            "[Epoch 86, Step   620] loss: 0.041\n",
            "[Epoch 86, Step   630] loss: 0.289\n",
            "[Epoch 86, Step   640] loss: 0.115\n",
            "[Epoch 86, Step   650] loss: 0.132\n",
            "[Epoch 86, Step   660] loss: 0.311\n",
            "[Epoch 86, Step   670] loss: 0.234\n",
            "[Epoch 86, Step   680] loss: 0.355\n",
            "[Epoch 86, Step   690] loss: 0.332\n",
            "[Epoch 86, Step   700] loss: 0.199\n",
            "[Epoch 86, Step   710] loss: 0.110\n",
            "[Epoch 86, Step   720] loss: 0.269\n",
            "[Epoch 86, Step   730] loss: 0.230\n",
            "[Epoch 86, Step   740] loss: 0.310\n",
            "[Epoch 86, Step   750] loss: 0.136\n",
            "[Epoch 86, Step   760] loss: 0.171\n",
            "[Epoch 86, Step   770] loss: 0.300\n",
            "[Epoch 86, Step   780] loss: 0.267\n",
            "[Epoch 86, Step   790] loss: 0.214\n",
            "[Epoch 86, Step   800] loss: 0.025\n",
            "[Epoch 86, Step   810] loss: 0.154\n",
            "[Epoch 86, Step   820] loss: 0.054\n",
            "[Epoch 86, Step   830] loss: 0.140\n",
            "[Epoch 86, Step   840] loss: 0.479\n",
            "[Epoch 86, Step   850] loss: 0.270\n",
            "[Epoch 86, Step   860] loss: 0.143\n",
            "[Epoch 86, Step   870] loss: 0.113\n",
            "[Epoch 86, Step   880] loss: 0.134\n",
            "[Epoch 86, Step   890] loss: 0.580\n",
            "[Epoch 86, Step   900] loss: 0.154\n",
            "[Epoch 86, Step   910] loss: 0.224\n",
            "[Epoch 86, Step   920] loss: 0.450\n",
            "[Epoch 86, Step   930] loss: 0.195\n",
            "[Epoch 86, Step   940] loss: 0.158\n",
            "[Epoch 86, Step   950] loss: 0.235\n",
            "[Epoch 86, Step   960] loss: 0.079\n",
            "[Epoch 86, Step   970] loss: 0.276\n",
            "[Epoch 86, Step   980] loss: 0.213\n",
            "[Epoch 86, Step   990] loss: 0.208\n",
            "[Epoch 86, Step  1000] loss: 0.078\n",
            "[Epoch 86, Step  1010] loss: 0.175\n",
            "[Epoch 86, Step  1020] loss: 0.190\n",
            "[Epoch 86, Step  1030] loss: 0.033\n",
            "[Epoch 86, Step  1040] loss: 0.113\n",
            "[Epoch 86, Step  1050] loss: 0.427\n",
            "[Epoch 86, Step  1060] loss: 0.107\n",
            "[Epoch 86, Step  1070] loss: 0.395\n",
            "[Epoch 86, Step  1080] loss: 0.152\n",
            "[Epoch 86, Step  1090] loss: 0.319\n",
            "[Epoch 86, Step  1100] loss: 0.139\n",
            "[Epoch 86, Step  1110] loss: 0.191\n",
            "[Epoch 86, Step  1120] loss: 0.082\n",
            "[Epoch 86, Step  1130] loss: 0.146\n",
            "[Epoch 86, Step  1140] loss: 0.165\n",
            "[Epoch 86, Step  1150] loss: 0.193\n",
            "[Epoch 86, Step  1160] loss: 0.349\n",
            "[Epoch 86, Step  1170] loss: 0.335\n",
            "[Epoch 86, Step  1180] loss: 0.235\n",
            "[Epoch 86, Step  1190] loss: 0.371\n",
            "[Epoch 86, Step  1200] loss: 0.022\n",
            "[Epoch 86, Step  1210] loss: 0.150\n",
            "[Epoch 86, Step  1220] loss: 0.074\n",
            "[Epoch 86, Step  1230] loss: 0.353\n",
            "[Epoch 86, Step  1240] loss: 0.162\n",
            "[Epoch 86, Step  1250] loss: 0.079\n",
            "[Epoch 86, Step  1260] loss: 0.413\n",
            "[Epoch 86, Step  1270] loss: 0.275\n",
            "[Epoch 86, Step  1280] loss: 0.379\n",
            "[Epoch 86, Step  1290] loss: 0.125\n",
            "[Epoch 86, Step  1300] loss: 0.264\n",
            "[Epoch 86, Step  1310] loss: 0.339\n",
            "[Epoch 86, Step  1320] loss: 0.142\n",
            "[Epoch 86, Step  1330] loss: 0.243\n",
            "[Epoch 86, Step  1340] loss: 0.249\n",
            "[Epoch 86, Step  1350] loss: 0.166\n",
            "[Epoch 86, Step  1360] loss: 0.246\n",
            "[Epoch 86, Step  1370] loss: 0.155\n",
            "[Epoch 86, Step  1380] loss: 0.197\n",
            "[Epoch 86, Step  1390] loss: 0.387\n",
            "[Epoch 86, Step  1400] loss: 0.316\n",
            "[Epoch 86, Step  1410] loss: 0.090\n",
            "[Epoch 86, Step  1420] loss: 0.106\n",
            "[Epoch 86, Step  1430] loss: 0.128\n",
            "[Epoch 86, Step  1440] loss: 0.065\n",
            "[Epoch 86, Step  1450] loss: 0.252\n",
            "[Epoch 86, Step  1460] loss: 0.361\n",
            "[Epoch 86, Step  1470] loss: 0.477\n",
            "[Epoch 86, Step  1480] loss: 0.177\n",
            "[Epoch 86, Step  1490] loss: 0.185\n",
            "[Epoch 86, Step  1500] loss: 0.179\n",
            "[Epoch 86, Step  1510] loss: 0.103\n",
            "[Epoch 86, Step  1520] loss: 0.300\n",
            "[Epoch 86, Step  1530] loss: 0.269\n",
            "[Epoch 86, Step  1540] loss: 0.170\n",
            "[Epoch 86, Step  1550] loss: 0.153\n",
            "[Epoch 86, Step  1560] loss: 0.107\n",
            "[Epoch 86, Step  1570] loss: 0.184\n",
            "[Epoch 86, Step  1580] loss: 0.077\n",
            "[Epoch 86, Step  1590] loss: 0.158\n",
            "[Epoch 86, Step  1600] loss: 0.143\n",
            "[Epoch 87, Step    10] loss: 0.157\n",
            "[Epoch 87, Step    20] loss: 0.396\n",
            "[Epoch 87, Step    30] loss: 0.112\n",
            "[Epoch 87, Step    40] loss: 0.101\n",
            "[Epoch 87, Step    50] loss: 0.138\n",
            "[Epoch 87, Step    60] loss: 0.063\n",
            "[Epoch 87, Step    70] loss: 0.198\n",
            "[Epoch 87, Step    80] loss: 0.253\n",
            "[Epoch 87, Step    90] loss: 0.300\n",
            "[Epoch 87, Step   100] loss: 0.253\n",
            "[Epoch 87, Step   110] loss: 0.289\n",
            "[Epoch 87, Step   120] loss: 0.337\n",
            "[Epoch 87, Step   130] loss: 0.126\n",
            "[Epoch 87, Step   140] loss: 0.540\n",
            "[Epoch 87, Step   150] loss: 0.166\n",
            "[Epoch 87, Step   160] loss: 0.032\n",
            "[Epoch 87, Step   170] loss: 0.083\n",
            "[Epoch 87, Step   180] loss: 0.446\n",
            "[Epoch 87, Step   190] loss: 0.449\n",
            "[Epoch 87, Step   200] loss: 0.261\n",
            "[Epoch 87, Step   210] loss: 0.316\n",
            "[Epoch 87, Step   220] loss: 0.251\n",
            "[Epoch 87, Step   230] loss: 0.088\n",
            "[Epoch 87, Step   240] loss: 0.123\n",
            "[Epoch 87, Step   250] loss: 0.109\n",
            "[Epoch 87, Step   260] loss: 0.241\n",
            "[Epoch 87, Step   270] loss: 0.311\n",
            "[Epoch 87, Step   280] loss: 0.268\n",
            "[Epoch 87, Step   290] loss: 0.341\n",
            "[Epoch 87, Step   300] loss: 0.271\n",
            "[Epoch 87, Step   310] loss: 0.166\n",
            "[Epoch 87, Step   320] loss: 0.057\n",
            "[Epoch 87, Step   330] loss: 0.433\n",
            "[Epoch 87, Step   340] loss: 0.179\n",
            "[Epoch 87, Step   350] loss: 0.260\n",
            "[Epoch 87, Step   360] loss: 0.498\n",
            "[Epoch 87, Step   370] loss: 0.414\n",
            "[Epoch 87, Step   380] loss: 0.195\n",
            "[Epoch 87, Step   390] loss: 0.273\n",
            "[Epoch 87, Step   400] loss: 0.443\n",
            "[Epoch 87, Step   410] loss: 0.508\n",
            "[Epoch 87, Step   420] loss: 0.216\n",
            "[Epoch 87, Step   430] loss: 0.191\n",
            "[Epoch 87, Step   440] loss: 0.024\n",
            "[Epoch 87, Step   450] loss: 0.116\n",
            "[Epoch 87, Step   460] loss: 0.042\n",
            "[Epoch 87, Step   470] loss: 0.102\n",
            "[Epoch 87, Step   480] loss: 0.384\n",
            "[Epoch 87, Step   490] loss: 0.356\n",
            "[Epoch 87, Step   500] loss: 0.090\n",
            "[Epoch 87, Step   510] loss: 0.269\n",
            "[Epoch 87, Step   520] loss: 0.178\n",
            "[Epoch 87, Step   530] loss: 0.347\n",
            "[Epoch 87, Step   540] loss: 0.209\n",
            "[Epoch 87, Step   550] loss: 0.082\n",
            "[Epoch 87, Step   560] loss: 0.270\n",
            "[Epoch 87, Step   570] loss: 0.127\n",
            "[Epoch 87, Step   580] loss: 0.145\n",
            "[Epoch 87, Step   590] loss: 0.379\n",
            "[Epoch 87, Step   600] loss: 0.158\n",
            "[Epoch 87, Step   610] loss: 0.079\n",
            "[Epoch 87, Step   620] loss: 0.061\n",
            "[Epoch 87, Step   630] loss: 0.441\n",
            "[Epoch 87, Step   640] loss: 0.584\n",
            "[Epoch 87, Step   650] loss: 0.047\n",
            "[Epoch 87, Step   660] loss: 0.156\n",
            "[Epoch 87, Step   670] loss: 0.166\n",
            "[Epoch 87, Step   680] loss: 0.175\n",
            "[Epoch 87, Step   690] loss: 0.353\n",
            "[Epoch 87, Step   700] loss: 0.287\n",
            "[Epoch 87, Step   710] loss: 0.119\n",
            "[Epoch 87, Step   720] loss: 0.247\n",
            "[Epoch 87, Step   730] loss: 0.252\n",
            "[Epoch 87, Step   740] loss: 0.031\n",
            "[Epoch 87, Step   750] loss: 0.085\n",
            "[Epoch 87, Step   760] loss: 0.383\n",
            "[Epoch 87, Step   770] loss: 0.065\n",
            "[Epoch 87, Step   780] loss: 0.156\n",
            "[Epoch 87, Step   790] loss: 0.059\n",
            "[Epoch 87, Step   800] loss: 0.162\n",
            "[Epoch 87, Step   810] loss: 0.048\n",
            "[Epoch 87, Step   820] loss: 0.088\n",
            "[Epoch 87, Step   830] loss: 0.405\n",
            "[Epoch 87, Step   840] loss: 0.408\n",
            "[Epoch 87, Step   850] loss: 0.313\n",
            "[Epoch 87, Step   860] loss: 0.227\n",
            "[Epoch 87, Step   870] loss: 0.093\n",
            "[Epoch 87, Step   880] loss: 0.120\n",
            "[Epoch 87, Step   890] loss: 0.073\n",
            "[Epoch 87, Step   900] loss: 0.274\n",
            "[Epoch 87, Step   910] loss: 0.235\n",
            "[Epoch 87, Step   920] loss: 0.308\n",
            "[Epoch 87, Step   930] loss: 0.228\n",
            "[Epoch 87, Step   940] loss: 0.262\n",
            "[Epoch 87, Step   950] loss: 0.214\n",
            "[Epoch 87, Step   960] loss: 0.210\n",
            "[Epoch 87, Step   970] loss: 0.122\n",
            "[Epoch 87, Step   980] loss: 0.290\n",
            "[Epoch 87, Step   990] loss: 0.182\n",
            "[Epoch 87, Step  1000] loss: 0.139\n",
            "[Epoch 87, Step  1010] loss: 0.127\n",
            "[Epoch 87, Step  1020] loss: 0.181\n",
            "[Epoch 87, Step  1030] loss: 0.114\n",
            "[Epoch 87, Step  1040] loss: 0.143\n",
            "[Epoch 87, Step  1050] loss: 0.617\n",
            "[Epoch 87, Step  1060] loss: 0.116\n",
            "[Epoch 87, Step  1070] loss: 0.033\n",
            "[Epoch 87, Step  1080] loss: 0.324\n",
            "[Epoch 87, Step  1090] loss: 0.093\n",
            "[Epoch 87, Step  1100] loss: 0.350\n",
            "[Epoch 87, Step  1110] loss: 0.155\n",
            "[Epoch 87, Step  1120] loss: 0.459\n",
            "[Epoch 87, Step  1130] loss: 0.103\n",
            "[Epoch 87, Step  1140] loss: 0.587\n",
            "[Epoch 87, Step  1150] loss: 0.158\n",
            "[Epoch 87, Step  1160] loss: 0.134\n",
            "[Epoch 87, Step  1170] loss: 0.267\n",
            "[Epoch 87, Step  1180] loss: 0.128\n",
            "[Epoch 87, Step  1190] loss: 0.128\n",
            "[Epoch 87, Step  1200] loss: 0.068\n",
            "[Epoch 87, Step  1210] loss: 0.265\n",
            "[Epoch 87, Step  1220] loss: 0.334\n",
            "[Epoch 87, Step  1230] loss: 0.087\n",
            "[Epoch 87, Step  1240] loss: 0.172\n",
            "[Epoch 87, Step  1250] loss: 0.295\n",
            "[Epoch 87, Step  1260] loss: 0.152\n",
            "[Epoch 87, Step  1270] loss: 0.320\n",
            "[Epoch 87, Step  1280] loss: 0.268\n",
            "[Epoch 87, Step  1290] loss: 0.117\n",
            "[Epoch 87, Step  1300] loss: 0.289\n",
            "[Epoch 87, Step  1310] loss: 0.367\n",
            "[Epoch 87, Step  1320] loss: 0.198\n",
            "[Epoch 87, Step  1330] loss: 0.286\n",
            "[Epoch 87, Step  1340] loss: 0.066\n",
            "[Epoch 87, Step  1350] loss: 0.295\n",
            "[Epoch 87, Step  1360] loss: 0.160\n",
            "[Epoch 87, Step  1370] loss: 0.176\n",
            "[Epoch 87, Step  1380] loss: 0.035\n",
            "[Epoch 87, Step  1390] loss: 0.218\n",
            "[Epoch 87, Step  1400] loss: 0.233\n",
            "[Epoch 87, Step  1410] loss: 0.285\n",
            "[Epoch 87, Step  1420] loss: 0.318\n",
            "[Epoch 87, Step  1430] loss: 0.210\n",
            "[Epoch 87, Step  1440] loss: 0.089\n",
            "[Epoch 87, Step  1450] loss: 0.082\n",
            "[Epoch 87, Step  1460] loss: 0.176\n",
            "[Epoch 87, Step  1470] loss: 0.152\n",
            "[Epoch 87, Step  1480] loss: 0.388\n",
            "[Epoch 87, Step  1490] loss: 0.121\n",
            "[Epoch 87, Step  1500] loss: 0.451\n",
            "[Epoch 87, Step  1510] loss: 0.092\n",
            "[Epoch 87, Step  1520] loss: 0.247\n",
            "[Epoch 87, Step  1530] loss: 0.538\n",
            "[Epoch 87, Step  1540] loss: 0.160\n",
            "[Epoch 87, Step  1550] loss: 0.086\n",
            "[Epoch 87, Step  1560] loss: 0.107\n",
            "[Epoch 87, Step  1570] loss: 0.561\n",
            "[Epoch 87, Step  1580] loss: 0.246\n",
            "[Epoch 87, Step  1590] loss: 0.131\n",
            "[Epoch 87, Step  1600] loss: 0.441\n",
            "[Epoch 88, Step    10] loss: 0.249\n",
            "[Epoch 88, Step    20] loss: 0.063\n",
            "[Epoch 88, Step    30] loss: 0.054\n",
            "[Epoch 88, Step    40] loss: 0.049\n",
            "[Epoch 88, Step    50] loss: 0.318\n",
            "[Epoch 88, Step    60] loss: 0.064\n",
            "[Epoch 88, Step    70] loss: 0.044\n",
            "[Epoch 88, Step    80] loss: 0.121\n",
            "[Epoch 88, Step    90] loss: 0.341\n",
            "[Epoch 88, Step   100] loss: 0.098\n",
            "[Epoch 88, Step   110] loss: 0.044\n",
            "[Epoch 88, Step   120] loss: 0.046\n",
            "[Epoch 88, Step   130] loss: 0.024\n",
            "[Epoch 88, Step   140] loss: 0.074\n",
            "[Epoch 88, Step   150] loss: 0.245\n",
            "[Epoch 88, Step   160] loss: 0.188\n",
            "[Epoch 88, Step   170] loss: 0.488\n",
            "[Epoch 88, Step   180] loss: 0.219\n",
            "[Epoch 88, Step   190] loss: 0.275\n",
            "[Epoch 88, Step   200] loss: 0.135\n",
            "[Epoch 88, Step   210] loss: 0.370\n",
            "[Epoch 88, Step   220] loss: 0.421\n",
            "[Epoch 88, Step   230] loss: 0.323\n",
            "[Epoch 88, Step   240] loss: 0.241\n",
            "[Epoch 88, Step   250] loss: 0.293\n",
            "[Epoch 88, Step   260] loss: 0.064\n",
            "[Epoch 88, Step   270] loss: 0.262\n",
            "[Epoch 88, Step   280] loss: 0.118\n",
            "[Epoch 88, Step   290] loss: 0.121\n",
            "[Epoch 88, Step   300] loss: 0.228\n",
            "[Epoch 88, Step   310] loss: 0.221\n",
            "[Epoch 88, Step   320] loss: 0.172\n",
            "[Epoch 88, Step   330] loss: 0.332\n",
            "[Epoch 88, Step   340] loss: 0.084\n",
            "[Epoch 88, Step   350] loss: 0.098\n",
            "[Epoch 88, Step   360] loss: 0.056\n",
            "[Epoch 88, Step   370] loss: 0.231\n",
            "[Epoch 88, Step   380] loss: 0.086\n",
            "[Epoch 88, Step   390] loss: 0.473\n",
            "[Epoch 88, Step   400] loss: 0.214\n",
            "[Epoch 88, Step   410] loss: 0.213\n",
            "[Epoch 88, Step   420] loss: 0.220\n",
            "[Epoch 88, Step   430] loss: 0.382\n",
            "[Epoch 88, Step   440] loss: 0.248\n",
            "[Epoch 88, Step   450] loss: 0.151\n",
            "[Epoch 88, Step   460] loss: 0.178\n",
            "[Epoch 88, Step   470] loss: 0.296\n",
            "[Epoch 88, Step   480] loss: 0.273\n",
            "[Epoch 88, Step   490] loss: 0.151\n",
            "[Epoch 88, Step   500] loss: 0.403\n",
            "[Epoch 88, Step   510] loss: 0.237\n",
            "[Epoch 88, Step   520] loss: 0.147\n",
            "[Epoch 88, Step   530] loss: 0.181\n",
            "[Epoch 88, Step   540] loss: 0.122\n",
            "[Epoch 88, Step   550] loss: 0.282\n",
            "[Epoch 88, Step   560] loss: 0.090\n",
            "[Epoch 88, Step   570] loss: 0.321\n",
            "[Epoch 88, Step   580] loss: 0.296\n",
            "[Epoch 88, Step   590] loss: 0.189\n",
            "[Epoch 88, Step   600] loss: 0.247\n",
            "[Epoch 88, Step   610] loss: 0.055\n",
            "[Epoch 88, Step   620] loss: 0.131\n",
            "[Epoch 88, Step   630] loss: 0.268\n",
            "[Epoch 88, Step   640] loss: 0.052\n",
            "[Epoch 88, Step   650] loss: 0.164\n",
            "[Epoch 88, Step   660] loss: 0.194\n",
            "[Epoch 88, Step   670] loss: 0.046\n",
            "[Epoch 88, Step   680] loss: 0.293\n",
            "[Epoch 88, Step   690] loss: 0.330\n",
            "[Epoch 88, Step   700] loss: 0.317\n",
            "[Epoch 88, Step   710] loss: 0.590\n",
            "[Epoch 88, Step   720] loss: 0.368\n",
            "[Epoch 88, Step   730] loss: 0.094\n",
            "[Epoch 88, Step   740] loss: 0.190\n",
            "[Epoch 88, Step   750] loss: 0.722\n",
            "[Epoch 88, Step   760] loss: 0.223\n",
            "[Epoch 88, Step   770] loss: 0.267\n",
            "[Epoch 88, Step   780] loss: 0.100\n",
            "[Epoch 88, Step   790] loss: 0.180\n",
            "[Epoch 88, Step   800] loss: 0.196\n",
            "[Epoch 88, Step   810] loss: 0.493\n",
            "[Epoch 88, Step   820] loss: 0.036\n",
            "[Epoch 88, Step   830] loss: 0.062\n",
            "[Epoch 88, Step   840] loss: 0.085\n",
            "[Epoch 88, Step   850] loss: 0.158\n",
            "[Epoch 88, Step   860] loss: 0.574\n",
            "[Epoch 88, Step   870] loss: 0.140\n",
            "[Epoch 88, Step   880] loss: 0.340\n",
            "[Epoch 88, Step   890] loss: 0.122\n",
            "[Epoch 88, Step   900] loss: 0.381\n",
            "[Epoch 88, Step   910] loss: 0.124\n",
            "[Epoch 88, Step   920] loss: 0.039\n",
            "[Epoch 88, Step   930] loss: 0.255\n",
            "[Epoch 88, Step   940] loss: 0.431\n",
            "[Epoch 88, Step   950] loss: 0.136\n",
            "[Epoch 88, Step   960] loss: 0.084\n",
            "[Epoch 88, Step   970] loss: 0.233\n",
            "[Epoch 88, Step   980] loss: 0.238\n",
            "[Epoch 88, Step   990] loss: 0.361\n",
            "[Epoch 88, Step  1000] loss: 0.510\n",
            "[Epoch 88, Step  1010] loss: 0.247\n",
            "[Epoch 88, Step  1020] loss: 0.230\n",
            "[Epoch 88, Step  1030] loss: 0.091\n",
            "[Epoch 88, Step  1040] loss: 0.283\n",
            "[Epoch 88, Step  1050] loss: 0.091\n",
            "[Epoch 88, Step  1060] loss: 0.278\n",
            "[Epoch 88, Step  1070] loss: 0.511\n",
            "[Epoch 88, Step  1080] loss: 0.024\n",
            "[Epoch 88, Step  1090] loss: 0.242\n",
            "[Epoch 88, Step  1100] loss: 0.130\n",
            "[Epoch 88, Step  1110] loss: 0.210\n",
            "[Epoch 88, Step  1120] loss: 0.245\n",
            "[Epoch 88, Step  1130] loss: 0.215\n",
            "[Epoch 88, Step  1140] loss: 0.185\n",
            "[Epoch 88, Step  1150] loss: 0.172\n",
            "[Epoch 88, Step  1160] loss: 0.083\n",
            "[Epoch 88, Step  1170] loss: 0.427\n",
            "[Epoch 88, Step  1180] loss: 0.170\n",
            "[Epoch 88, Step  1190] loss: 0.194\n",
            "[Epoch 88, Step  1200] loss: 0.287\n",
            "[Epoch 88, Step  1210] loss: 0.133\n",
            "[Epoch 88, Step  1220] loss: 0.008\n",
            "[Epoch 88, Step  1230] loss: 0.524\n",
            "[Epoch 88, Step  1240] loss: 0.165\n",
            "[Epoch 88, Step  1250] loss: 0.194\n",
            "[Epoch 88, Step  1260] loss: 0.253\n",
            "[Epoch 88, Step  1270] loss: 0.221\n",
            "[Epoch 88, Step  1280] loss: 0.121\n",
            "[Epoch 88, Step  1290] loss: 0.218\n",
            "[Epoch 88, Step  1300] loss: 0.253\n",
            "[Epoch 88, Step  1310] loss: 0.614\n",
            "[Epoch 88, Step  1320] loss: 0.033\n",
            "[Epoch 88, Step  1330] loss: 0.180\n",
            "[Epoch 88, Step  1340] loss: 0.177\n",
            "[Epoch 88, Step  1350] loss: 0.410\n",
            "[Epoch 88, Step  1360] loss: 0.415\n",
            "[Epoch 88, Step  1370] loss: 0.090\n",
            "[Epoch 88, Step  1380] loss: 0.200\n",
            "[Epoch 88, Step  1390] loss: 0.123\n",
            "[Epoch 88, Step  1400] loss: 0.337\n",
            "[Epoch 88, Step  1410] loss: 0.071\n",
            "[Epoch 88, Step  1420] loss: 0.265\n",
            "[Epoch 88, Step  1430] loss: 0.074\n",
            "[Epoch 88, Step  1440] loss: 0.391\n",
            "[Epoch 88, Step  1450] loss: 0.294\n",
            "[Epoch 88, Step  1460] loss: 0.237\n",
            "[Epoch 88, Step  1470] loss: 0.369\n",
            "[Epoch 88, Step  1480] loss: 0.299\n",
            "[Epoch 88, Step  1490] loss: 0.364\n",
            "[Epoch 88, Step  1500] loss: 0.194\n",
            "[Epoch 88, Step  1510] loss: 0.296\n",
            "[Epoch 88, Step  1520] loss: 0.098\n",
            "[Epoch 88, Step  1530] loss: 0.350\n",
            "[Epoch 88, Step  1540] loss: 0.245\n",
            "[Epoch 88, Step  1550] loss: 0.274\n",
            "[Epoch 88, Step  1560] loss: 0.427\n",
            "[Epoch 88, Step  1570] loss: 0.159\n",
            "[Epoch 88, Step  1580] loss: 0.159\n",
            "[Epoch 88, Step  1590] loss: 0.294\n",
            "[Epoch 88, Step  1600] loss: 0.217\n",
            "[Epoch 89, Step    10] loss: 0.307\n",
            "[Epoch 89, Step    20] loss: 0.171\n",
            "[Epoch 89, Step    30] loss: 0.088\n",
            "[Epoch 89, Step    40] loss: 0.017\n",
            "[Epoch 89, Step    50] loss: 0.226\n",
            "[Epoch 89, Step    60] loss: 0.295\n",
            "[Epoch 89, Step    70] loss: 0.247\n",
            "[Epoch 89, Step    80] loss: 0.150\n",
            "[Epoch 89, Step    90] loss: 0.195\n",
            "[Epoch 89, Step   100] loss: 0.339\n",
            "[Epoch 89, Step   110] loss: 0.155\n",
            "[Epoch 89, Step   120] loss: 0.241\n",
            "[Epoch 89, Step   130] loss: 0.182\n",
            "[Epoch 89, Step   140] loss: 0.705\n",
            "[Epoch 89, Step   150] loss: 0.175\n",
            "[Epoch 89, Step   160] loss: 0.224\n",
            "[Epoch 89, Step   170] loss: 0.297\n",
            "[Epoch 89, Step   180] loss: 0.268\n",
            "[Epoch 89, Step   190] loss: 0.096\n",
            "[Epoch 89, Step   200] loss: 0.023\n",
            "[Epoch 89, Step   210] loss: 0.062\n",
            "[Epoch 89, Step   220] loss: 0.231\n",
            "[Epoch 89, Step   230] loss: 0.353\n",
            "[Epoch 89, Step   240] loss: 0.092\n",
            "[Epoch 89, Step   250] loss: 0.557\n",
            "[Epoch 89, Step   260] loss: 0.129\n",
            "[Epoch 89, Step   270] loss: 0.097\n",
            "[Epoch 89, Step   280] loss: 0.103\n",
            "[Epoch 89, Step   290] loss: 0.164\n",
            "[Epoch 89, Step   300] loss: 0.238\n",
            "[Epoch 89, Step   310] loss: 0.117\n",
            "[Epoch 89, Step   320] loss: 0.446\n",
            "[Epoch 89, Step   330] loss: 0.476\n",
            "[Epoch 89, Step   340] loss: 0.199\n",
            "[Epoch 89, Step   350] loss: 0.226\n",
            "[Epoch 89, Step   360] loss: 0.173\n",
            "[Epoch 89, Step   370] loss: 0.033\n",
            "[Epoch 89, Step   380] loss: 0.247\n",
            "[Epoch 89, Step   390] loss: 0.182\n",
            "[Epoch 89, Step   400] loss: 0.108\n",
            "[Epoch 89, Step   410] loss: 0.021\n",
            "[Epoch 89, Step   420] loss: 0.165\n",
            "[Epoch 89, Step   430] loss: 0.119\n",
            "[Epoch 89, Step   440] loss: 0.155\n",
            "[Epoch 89, Step   450] loss: 0.187\n",
            "[Epoch 89, Step   460] loss: 0.308\n",
            "[Epoch 89, Step   470] loss: 0.096\n",
            "[Epoch 89, Step   480] loss: 0.209\n",
            "[Epoch 89, Step   490] loss: 0.155\n",
            "[Epoch 89, Step   500] loss: 0.075\n",
            "[Epoch 89, Step   510] loss: 0.213\n",
            "[Epoch 89, Step   520] loss: 0.096\n",
            "[Epoch 89, Step   530] loss: 0.232\n",
            "[Epoch 89, Step   540] loss: 0.653\n",
            "[Epoch 89, Step   550] loss: 0.158\n",
            "[Epoch 89, Step   560] loss: 0.172\n",
            "[Epoch 89, Step   570] loss: 0.196\n",
            "[Epoch 89, Step   580] loss: 0.159\n",
            "[Epoch 89, Step   590] loss: 0.124\n",
            "[Epoch 89, Step   600] loss: 0.153\n",
            "[Epoch 89, Step   610] loss: 0.057\n",
            "[Epoch 89, Step   620] loss: 0.281\n",
            "[Epoch 89, Step   630] loss: 0.055\n",
            "[Epoch 89, Step   640] loss: 0.365\n",
            "[Epoch 89, Step   650] loss: 0.402\n",
            "[Epoch 89, Step   660] loss: 0.429\n",
            "[Epoch 89, Step   670] loss: 0.141\n",
            "[Epoch 89, Step   680] loss: 0.090\n",
            "[Epoch 89, Step   690] loss: 0.137\n",
            "[Epoch 89, Step   700] loss: 0.146\n",
            "[Epoch 89, Step   710] loss: 0.240\n",
            "[Epoch 89, Step   720] loss: 0.219\n",
            "[Epoch 89, Step   730] loss: 0.487\n",
            "[Epoch 89, Step   740] loss: 0.240\n",
            "[Epoch 89, Step   750] loss: 0.565\n",
            "[Epoch 89, Step   760] loss: 0.213\n",
            "[Epoch 89, Step   770] loss: 0.251\n",
            "[Epoch 89, Step   780] loss: 0.095\n",
            "[Epoch 89, Step   790] loss: 0.194\n",
            "[Epoch 89, Step   800] loss: 0.130\n",
            "[Epoch 89, Step   810] loss: 0.617\n",
            "[Epoch 89, Step   820] loss: 0.279\n",
            "[Epoch 89, Step   830] loss: 0.086\n",
            "[Epoch 89, Step   840] loss: 0.317\n",
            "[Epoch 89, Step   850] loss: 0.199\n",
            "[Epoch 89, Step   860] loss: 0.060\n",
            "[Epoch 89, Step   870] loss: 0.054\n",
            "[Epoch 89, Step   880] loss: 0.211\n",
            "[Epoch 89, Step   890] loss: 0.244\n",
            "[Epoch 89, Step   900] loss: 0.215\n",
            "[Epoch 89, Step   910] loss: 0.022\n",
            "[Epoch 89, Step   920] loss: 0.211\n",
            "[Epoch 89, Step   930] loss: 0.346\n",
            "[Epoch 89, Step   940] loss: 0.237\n",
            "[Epoch 89, Step   950] loss: 0.056\n",
            "[Epoch 89, Step   960] loss: 0.197\n",
            "[Epoch 89, Step   970] loss: 0.306\n",
            "[Epoch 89, Step   980] loss: 0.326\n",
            "[Epoch 89, Step   990] loss: 0.427\n",
            "[Epoch 89, Step  1000] loss: 0.069\n",
            "[Epoch 89, Step  1010] loss: 0.257\n",
            "[Epoch 89, Step  1020] loss: 0.258\n",
            "[Epoch 89, Step  1030] loss: 0.469\n",
            "[Epoch 89, Step  1040] loss: 0.050\n",
            "[Epoch 89, Step  1050] loss: 0.075\n",
            "[Epoch 89, Step  1060] loss: 0.472\n",
            "[Epoch 89, Step  1070] loss: 0.317\n",
            "[Epoch 89, Step  1080] loss: 0.424\n",
            "[Epoch 89, Step  1090] loss: 0.112\n",
            "[Epoch 89, Step  1100] loss: 0.328\n",
            "[Epoch 89, Step  1110] loss: 0.047\n",
            "[Epoch 89, Step  1120] loss: 0.123\n",
            "[Epoch 89, Step  1130] loss: 0.071\n",
            "[Epoch 89, Step  1140] loss: 0.032\n",
            "[Epoch 89, Step  1150] loss: 0.276\n",
            "[Epoch 89, Step  1160] loss: 0.509\n",
            "[Epoch 89, Step  1170] loss: 0.130\n",
            "[Epoch 89, Step  1180] loss: 0.168\n",
            "[Epoch 89, Step  1190] loss: 0.046\n",
            "[Epoch 89, Step  1200] loss: 0.126\n",
            "[Epoch 89, Step  1210] loss: 0.260\n",
            "[Epoch 89, Step  1220] loss: 0.296\n",
            "[Epoch 89, Step  1230] loss: 0.595\n",
            "[Epoch 89, Step  1240] loss: 0.143\n",
            "[Epoch 89, Step  1250] loss: 0.070\n",
            "[Epoch 89, Step  1260] loss: 0.152\n",
            "[Epoch 89, Step  1270] loss: 0.561\n",
            "[Epoch 89, Step  1280] loss: 0.207\n",
            "[Epoch 89, Step  1290] loss: 0.139\n",
            "[Epoch 89, Step  1300] loss: 0.176\n",
            "[Epoch 89, Step  1310] loss: 0.275\n",
            "[Epoch 89, Step  1320] loss: 0.278\n",
            "[Epoch 89, Step  1330] loss: 0.277\n",
            "[Epoch 89, Step  1340] loss: 0.075\n",
            "[Epoch 89, Step  1350] loss: 0.143\n",
            "[Epoch 89, Step  1360] loss: 0.380\n",
            "[Epoch 89, Step  1370] loss: 0.150\n",
            "[Epoch 89, Step  1380] loss: 0.163\n",
            "[Epoch 89, Step  1390] loss: 0.086\n",
            "[Epoch 89, Step  1400] loss: 0.136\n",
            "[Epoch 89, Step  1410] loss: 0.201\n",
            "[Epoch 89, Step  1420] loss: 0.356\n",
            "[Epoch 89, Step  1430] loss: 0.059\n",
            "[Epoch 89, Step  1440] loss: 0.449\n",
            "[Epoch 89, Step  1450] loss: 0.428\n",
            "[Epoch 89, Step  1460] loss: 0.765\n",
            "[Epoch 89, Step  1470] loss: 0.091\n",
            "[Epoch 89, Step  1480] loss: 0.242\n",
            "[Epoch 89, Step  1490] loss: 0.279\n",
            "[Epoch 89, Step  1500] loss: 0.191\n",
            "[Epoch 89, Step  1510] loss: 0.098\n",
            "[Epoch 89, Step  1520] loss: 0.085\n",
            "[Epoch 89, Step  1530] loss: 0.175\n",
            "[Epoch 89, Step  1540] loss: 0.427\n",
            "[Epoch 89, Step  1550] loss: 0.438\n",
            "[Epoch 89, Step  1560] loss: 0.079\n",
            "[Epoch 89, Step  1570] loss: 0.116\n",
            "[Epoch 89, Step  1580] loss: 0.227\n",
            "[Epoch 89, Step  1590] loss: 0.425\n",
            "[Epoch 89, Step  1600] loss: 0.203\n",
            "[Epoch 90, Step    10] loss: 0.478\n",
            "[Epoch 90, Step    20] loss: 0.227\n",
            "[Epoch 90, Step    30] loss: 0.117\n",
            "[Epoch 90, Step    40] loss: 0.186\n",
            "[Epoch 90, Step    50] loss: 0.049\n",
            "[Epoch 90, Step    60] loss: 0.129\n",
            "[Epoch 90, Step    70] loss: 0.213\n",
            "[Epoch 90, Step    80] loss: 0.240\n",
            "[Epoch 90, Step    90] loss: 0.143\n",
            "[Epoch 90, Step   100] loss: 0.202\n",
            "[Epoch 90, Step   110] loss: 0.234\n",
            "[Epoch 90, Step   120] loss: 0.082\n",
            "[Epoch 90, Step   130] loss: 0.243\n",
            "[Epoch 90, Step   140] loss: 0.044\n",
            "[Epoch 90, Step   150] loss: 0.032\n",
            "[Epoch 90, Step   160] loss: 0.289\n",
            "[Epoch 90, Step   170] loss: 0.311\n",
            "[Epoch 90, Step   180] loss: 0.178\n",
            "[Epoch 90, Step   190] loss: 0.118\n",
            "[Epoch 90, Step   200] loss: 0.064\n",
            "[Epoch 90, Step   210] loss: 0.182\n",
            "[Epoch 90, Step   220] loss: 0.283\n",
            "[Epoch 90, Step   230] loss: 0.667\n",
            "[Epoch 90, Step   240] loss: 0.252\n",
            "[Epoch 90, Step   250] loss: 0.082\n",
            "[Epoch 90, Step   260] loss: 0.411\n",
            "[Epoch 90, Step   270] loss: 0.085\n",
            "[Epoch 90, Step   280] loss: 0.234\n",
            "[Epoch 90, Step   290] loss: 0.186\n",
            "[Epoch 90, Step   300] loss: 0.393\n",
            "[Epoch 90, Step   310] loss: 0.176\n",
            "[Epoch 90, Step   320] loss: 0.185\n",
            "[Epoch 90, Step   330] loss: 0.251\n",
            "[Epoch 90, Step   340] loss: 0.196\n",
            "[Epoch 90, Step   350] loss: 0.205\n",
            "[Epoch 90, Step   360] loss: 0.659\n",
            "[Epoch 90, Step   370] loss: 0.075\n",
            "[Epoch 90, Step   380] loss: 0.393\n",
            "[Epoch 90, Step   390] loss: 0.180\n",
            "[Epoch 90, Step   400] loss: 0.171\n",
            "[Epoch 90, Step   410] loss: 0.112\n",
            "[Epoch 90, Step   420] loss: 0.160\n",
            "[Epoch 90, Step   430] loss: 0.275\n",
            "[Epoch 90, Step   440] loss: 0.426\n",
            "[Epoch 90, Step   450] loss: 0.211\n",
            "[Epoch 90, Step   460] loss: 0.129\n",
            "[Epoch 90, Step   470] loss: 0.337\n",
            "[Epoch 90, Step   480] loss: 0.175\n",
            "[Epoch 90, Step   490] loss: 0.045\n",
            "[Epoch 90, Step   500] loss: 0.114\n",
            "[Epoch 90, Step   510] loss: 0.160\n",
            "[Epoch 90, Step   520] loss: 0.245\n",
            "[Epoch 90, Step   530] loss: 0.391\n",
            "[Epoch 90, Step   540] loss: 0.328\n",
            "[Epoch 90, Step   550] loss: 0.073\n",
            "[Epoch 90, Step   560] loss: 0.305\n",
            "[Epoch 90, Step   570] loss: 0.437\n",
            "[Epoch 90, Step   580] loss: 0.029\n",
            "[Epoch 90, Step   590] loss: 0.227\n",
            "[Epoch 90, Step   600] loss: 0.080\n",
            "[Epoch 90, Step   610] loss: 0.131\n",
            "[Epoch 90, Step   620] loss: 0.118\n",
            "[Epoch 90, Step   630] loss: 0.392\n",
            "[Epoch 90, Step   640] loss: 0.114\n",
            "[Epoch 90, Step   650] loss: 0.110\n",
            "[Epoch 90, Step   660] loss: 0.287\n",
            "[Epoch 90, Step   670] loss: 0.233\n",
            "[Epoch 90, Step   680] loss: 0.168\n",
            "[Epoch 90, Step   690] loss: 0.357\n",
            "[Epoch 90, Step   700] loss: 0.396\n",
            "[Epoch 90, Step   710] loss: 0.305\n",
            "[Epoch 90, Step   720] loss: 0.209\n",
            "[Epoch 90, Step   730] loss: 0.074\n",
            "[Epoch 90, Step   740] loss: 0.071\n",
            "[Epoch 90, Step   750] loss: 0.301\n",
            "[Epoch 90, Step   760] loss: 0.257\n",
            "[Epoch 90, Step   770] loss: 0.202\n",
            "[Epoch 90, Step   780] loss: 0.609\n",
            "[Epoch 90, Step   790] loss: 0.450\n",
            "[Epoch 90, Step   800] loss: 0.432\n",
            "[Epoch 90, Step   810] loss: 0.234\n",
            "[Epoch 90, Step   820] loss: 0.044\n",
            "[Epoch 90, Step   830] loss: 0.131\n",
            "[Epoch 90, Step   840] loss: 0.213\n",
            "[Epoch 90, Step   850] loss: 0.139\n",
            "[Epoch 90, Step   860] loss: 0.186\n",
            "[Epoch 90, Step   870] loss: 0.130\n",
            "[Epoch 90, Step   880] loss: 0.092\n",
            "[Epoch 90, Step   890] loss: 0.173\n",
            "[Epoch 90, Step   900] loss: 0.177\n",
            "[Epoch 90, Step   910] loss: 0.086\n",
            "[Epoch 90, Step   920] loss: 0.167\n",
            "[Epoch 90, Step   930] loss: 0.062\n",
            "[Epoch 90, Step   940] loss: 0.360\n",
            "[Epoch 90, Step   950] loss: 0.175\n",
            "[Epoch 90, Step   960] loss: 0.243\n",
            "[Epoch 90, Step   970] loss: 0.378\n",
            "[Epoch 90, Step   980] loss: 0.206\n",
            "[Epoch 90, Step   990] loss: 0.208\n",
            "[Epoch 90, Step  1000] loss: 0.212\n",
            "[Epoch 90, Step  1010] loss: 0.194\n",
            "[Epoch 90, Step  1020] loss: 0.175\n",
            "[Epoch 90, Step  1030] loss: 0.117\n",
            "[Epoch 90, Step  1040] loss: 0.292\n",
            "[Epoch 90, Step  1050] loss: 0.118\n",
            "[Epoch 90, Step  1060] loss: 0.161\n",
            "[Epoch 90, Step  1070] loss: 0.232\n",
            "[Epoch 90, Step  1080] loss: 0.379\n",
            "[Epoch 90, Step  1090] loss: 0.075\n",
            "[Epoch 90, Step  1100] loss: 0.271\n",
            "[Epoch 90, Step  1110] loss: 0.322\n",
            "[Epoch 90, Step  1120] loss: 0.341\n",
            "[Epoch 90, Step  1130] loss: 0.120\n",
            "[Epoch 90, Step  1140] loss: 0.453\n",
            "[Epoch 90, Step  1150] loss: 0.059\n",
            "[Epoch 90, Step  1160] loss: 0.118\n",
            "[Epoch 90, Step  1170] loss: 0.198\n",
            "[Epoch 90, Step  1180] loss: 0.147\n",
            "[Epoch 90, Step  1190] loss: 0.232\n",
            "[Epoch 90, Step  1200] loss: 0.182\n",
            "[Epoch 90, Step  1210] loss: 0.287\n",
            "[Epoch 90, Step  1220] loss: 0.042\n",
            "[Epoch 90, Step  1230] loss: 0.269\n",
            "[Epoch 90, Step  1240] loss: 0.394\n",
            "[Epoch 90, Step  1250] loss: 0.090\n",
            "[Epoch 90, Step  1260] loss: 0.079\n",
            "[Epoch 90, Step  1270] loss: 0.120\n",
            "[Epoch 90, Step  1280] loss: 0.276\n",
            "[Epoch 90, Step  1290] loss: 0.343\n",
            "[Epoch 90, Step  1300] loss: 0.414\n",
            "[Epoch 90, Step  1310] loss: 0.080\n",
            "[Epoch 90, Step  1320] loss: 0.299\n",
            "[Epoch 90, Step  1330] loss: 0.168\n",
            "[Epoch 90, Step  1340] loss: 0.268\n",
            "[Epoch 90, Step  1350] loss: 0.308\n",
            "[Epoch 90, Step  1360] loss: 0.560\n",
            "[Epoch 90, Step  1370] loss: 0.300\n",
            "[Epoch 90, Step  1380] loss: 0.123\n",
            "[Epoch 90, Step  1390] loss: 0.345\n",
            "[Epoch 90, Step  1400] loss: 0.274\n",
            "[Epoch 90, Step  1410] loss: 0.387\n",
            "[Epoch 90, Step  1420] loss: 0.095\n",
            "[Epoch 90, Step  1430] loss: 0.283\n",
            "[Epoch 90, Step  1440] loss: 0.214\n",
            "[Epoch 90, Step  1450] loss: 0.108\n",
            "[Epoch 90, Step  1460] loss: 0.186\n",
            "[Epoch 90, Step  1470] loss: 0.168\n",
            "[Epoch 90, Step  1480] loss: 0.237\n",
            "[Epoch 90, Step  1490] loss: 0.023\n",
            "[Epoch 90, Step  1500] loss: 0.268\n",
            "[Epoch 90, Step  1510] loss: 0.452\n",
            "[Epoch 90, Step  1520] loss: 0.134\n",
            "[Epoch 90, Step  1530] loss: 0.111\n",
            "[Epoch 90, Step  1540] loss: 0.248\n",
            "[Epoch 90, Step  1550] loss: 0.141\n",
            "[Epoch 90, Step  1560] loss: 0.315\n",
            "[Epoch 90, Step  1570] loss: 0.210\n",
            "[Epoch 90, Step  1580] loss: 0.408\n",
            "[Epoch 90, Step  1590] loss: 0.083\n",
            "[Epoch 90, Step  1600] loss: 0.193\n",
            "[Epoch 91, Step    10] loss: 0.141\n",
            "[Epoch 91, Step    20] loss: 0.360\n",
            "[Epoch 91, Step    30] loss: 0.036\n",
            "[Epoch 91, Step    40] loss: 0.151\n",
            "[Epoch 91, Step    50] loss: 0.360\n",
            "[Epoch 91, Step    60] loss: 0.230\n",
            "[Epoch 91, Step    70] loss: 0.080\n",
            "[Epoch 91, Step    80] loss: 0.236\n",
            "[Epoch 91, Step    90] loss: 0.337\n",
            "[Epoch 91, Step   100] loss: 0.257\n",
            "[Epoch 91, Step   110] loss: 0.157\n",
            "[Epoch 91, Step   120] loss: 0.148\n",
            "[Epoch 91, Step   130] loss: 0.102\n",
            "[Epoch 91, Step   140] loss: 0.344\n",
            "[Epoch 91, Step   150] loss: 0.384\n",
            "[Epoch 91, Step   160] loss: 0.364\n",
            "[Epoch 91, Step   170] loss: 0.275\n",
            "[Epoch 91, Step   180] loss: 0.178\n",
            "[Epoch 91, Step   190] loss: 0.286\n",
            "[Epoch 91, Step   200] loss: 0.154\n",
            "[Epoch 91, Step   210] loss: 0.091\n",
            "[Epoch 91, Step   220] loss: 0.051\n",
            "[Epoch 91, Step   230] loss: 0.214\n",
            "[Epoch 91, Step   240] loss: 0.373\n",
            "[Epoch 91, Step   250] loss: 0.244\n",
            "[Epoch 91, Step   260] loss: 0.508\n",
            "[Epoch 91, Step   270] loss: 0.327\n",
            "[Epoch 91, Step   280] loss: 0.118\n",
            "[Epoch 91, Step   290] loss: 0.201\n",
            "[Epoch 91, Step   300] loss: 0.584\n",
            "[Epoch 91, Step   310] loss: 0.093\n",
            "[Epoch 91, Step   320] loss: 0.126\n",
            "[Epoch 91, Step   330] loss: 0.215\n",
            "[Epoch 91, Step   340] loss: 0.157\n",
            "[Epoch 91, Step   350] loss: 0.235\n",
            "[Epoch 91, Step   360] loss: 0.126\n",
            "[Epoch 91, Step   370] loss: 0.087\n",
            "[Epoch 91, Step   380] loss: 0.062\n",
            "[Epoch 91, Step   390] loss: 0.385\n",
            "[Epoch 91, Step   400] loss: 0.302\n",
            "[Epoch 91, Step   410] loss: 0.221\n",
            "[Epoch 91, Step   420] loss: 0.426\n",
            "[Epoch 91, Step   430] loss: 0.161\n",
            "[Epoch 91, Step   440] loss: 0.171\n",
            "[Epoch 91, Step   450] loss: 0.136\n",
            "[Epoch 91, Step   460] loss: 0.093\n",
            "[Epoch 91, Step   470] loss: 0.137\n",
            "[Epoch 91, Step   480] loss: 0.255\n",
            "[Epoch 91, Step   490] loss: 0.594\n",
            "[Epoch 91, Step   500] loss: 0.197\n",
            "[Epoch 91, Step   510] loss: 0.209\n",
            "[Epoch 91, Step   520] loss: 0.204\n",
            "[Epoch 91, Step   530] loss: 0.120\n",
            "[Epoch 91, Step   540] loss: 0.149\n",
            "[Epoch 91, Step   550] loss: 0.345\n",
            "[Epoch 91, Step   560] loss: 0.237\n",
            "[Epoch 91, Step   570] loss: 0.363\n",
            "[Epoch 91, Step   580] loss: 0.685\n",
            "[Epoch 91, Step   590] loss: 0.044\n",
            "[Epoch 91, Step   600] loss: 0.202\n",
            "[Epoch 91, Step   610] loss: 0.089\n",
            "[Epoch 91, Step   620] loss: 0.243\n",
            "[Epoch 91, Step   630] loss: 0.221\n",
            "[Epoch 91, Step   640] loss: 0.197\n",
            "[Epoch 91, Step   650] loss: 0.085\n",
            "[Epoch 91, Step   660] loss: 0.157\n",
            "[Epoch 91, Step   670] loss: 0.116\n",
            "[Epoch 91, Step   680] loss: 0.104\n",
            "[Epoch 91, Step   690] loss: 0.103\n",
            "[Epoch 91, Step   700] loss: 0.242\n",
            "[Epoch 91, Step   710] loss: 0.022\n",
            "[Epoch 91, Step   720] loss: 0.344\n",
            "[Epoch 91, Step   730] loss: 0.169\n",
            "[Epoch 91, Step   740] loss: 0.442\n",
            "[Epoch 91, Step   750] loss: 0.071\n",
            "[Epoch 91, Step   760] loss: 0.052\n",
            "[Epoch 91, Step   770] loss: 0.258\n",
            "[Epoch 91, Step   780] loss: 0.338\n",
            "[Epoch 91, Step   790] loss: 0.098\n",
            "[Epoch 91, Step   800] loss: 0.436\n",
            "[Epoch 91, Step   810] loss: 0.132\n",
            "[Epoch 91, Step   820] loss: 0.206\n",
            "[Epoch 91, Step   830] loss: 0.573\n",
            "[Epoch 91, Step   840] loss: 0.238\n",
            "[Epoch 91, Step   850] loss: 0.065\n",
            "[Epoch 91, Step   860] loss: 0.266\n",
            "[Epoch 91, Step   870] loss: 0.399\n",
            "[Epoch 91, Step   880] loss: 0.014\n",
            "[Epoch 91, Step   890] loss: 0.097\n",
            "[Epoch 91, Step   900] loss: 0.169\n",
            "[Epoch 91, Step   910] loss: 0.325\n",
            "[Epoch 91, Step   920] loss: 0.119\n",
            "[Epoch 91, Step   930] loss: 0.069\n",
            "[Epoch 91, Step   940] loss: 0.069\n",
            "[Epoch 91, Step   950] loss: 0.157\n",
            "[Epoch 91, Step   960] loss: 0.247\n",
            "[Epoch 91, Step   970] loss: 0.079\n",
            "[Epoch 91, Step   980] loss: 0.071\n",
            "[Epoch 91, Step   990] loss: 0.196\n",
            "[Epoch 91, Step  1000] loss: 0.217\n",
            "[Epoch 91, Step  1010] loss: 0.489\n",
            "[Epoch 91, Step  1020] loss: 0.221\n",
            "[Epoch 91, Step  1030] loss: 0.694\n",
            "[Epoch 91, Step  1040] loss: 0.196\n",
            "[Epoch 91, Step  1050] loss: 0.193\n",
            "[Epoch 91, Step  1060] loss: 0.149\n",
            "[Epoch 91, Step  1070] loss: 0.282\n",
            "[Epoch 91, Step  1080] loss: 0.271\n",
            "[Epoch 91, Step  1090] loss: 0.048\n",
            "[Epoch 91, Step  1100] loss: 0.111\n",
            "[Epoch 91, Step  1110] loss: 0.254\n",
            "[Epoch 91, Step  1120] loss: 0.282\n",
            "[Epoch 91, Step  1130] loss: 0.158\n",
            "[Epoch 91, Step  1140] loss: 0.081\n",
            "[Epoch 91, Step  1150] loss: 0.066\n",
            "[Epoch 91, Step  1160] loss: 0.211\n",
            "[Epoch 91, Step  1170] loss: 0.517\n",
            "[Epoch 91, Step  1180] loss: 0.119\n",
            "[Epoch 91, Step  1190] loss: 0.201\n",
            "[Epoch 91, Step  1200] loss: 0.503\n",
            "[Epoch 91, Step  1210] loss: 0.131\n",
            "[Epoch 91, Step  1220] loss: 0.149\n",
            "[Epoch 91, Step  1230] loss: 0.103\n",
            "[Epoch 91, Step  1240] loss: 0.195\n",
            "[Epoch 91, Step  1250] loss: 0.323\n",
            "[Epoch 91, Step  1260] loss: 0.532\n",
            "[Epoch 91, Step  1270] loss: 0.301\n",
            "[Epoch 91, Step  1280] loss: 0.097\n",
            "[Epoch 91, Step  1290] loss: 0.312\n",
            "[Epoch 91, Step  1300] loss: 0.191\n",
            "[Epoch 91, Step  1310] loss: 0.295\n",
            "[Epoch 91, Step  1320] loss: 0.014\n",
            "[Epoch 91, Step  1330] loss: 0.517\n",
            "[Epoch 91, Step  1340] loss: 0.325\n",
            "[Epoch 91, Step  1350] loss: 0.172\n",
            "[Epoch 91, Step  1360] loss: 0.076\n",
            "[Epoch 91, Step  1370] loss: 0.280\n",
            "[Epoch 91, Step  1380] loss: 0.424\n",
            "[Epoch 91, Step  1390] loss: 0.313\n",
            "[Epoch 91, Step  1400] loss: 0.134\n",
            "[Epoch 91, Step  1410] loss: 0.223\n",
            "[Epoch 91, Step  1420] loss: 0.099\n",
            "[Epoch 91, Step  1430] loss: 0.281\n",
            "[Epoch 91, Step  1440] loss: 0.374\n",
            "[Epoch 91, Step  1450] loss: 0.186\n",
            "[Epoch 91, Step  1460] loss: 0.099\n",
            "[Epoch 91, Step  1470] loss: 0.103\n",
            "[Epoch 91, Step  1480] loss: 0.431\n",
            "[Epoch 91, Step  1490] loss: 0.042\n",
            "[Epoch 91, Step  1500] loss: 0.101\n",
            "[Epoch 91, Step  1510] loss: 0.143\n",
            "[Epoch 91, Step  1520] loss: 0.121\n",
            "[Epoch 91, Step  1530] loss: 0.365\n",
            "[Epoch 91, Step  1540] loss: 0.045\n",
            "[Epoch 91, Step  1550] loss: 0.193\n",
            "[Epoch 91, Step  1560] loss: 0.395\n",
            "[Epoch 91, Step  1570] loss: 0.114\n",
            "[Epoch 91, Step  1580] loss: 0.195\n",
            "[Epoch 91, Step  1590] loss: 0.136\n",
            "[Epoch 91, Step  1600] loss: 0.510\n",
            "[Epoch 92, Step    10] loss: 0.044\n",
            "[Epoch 92, Step    20] loss: 0.048\n",
            "[Epoch 92, Step    30] loss: 0.097\n",
            "[Epoch 92, Step    40] loss: 0.200\n",
            "[Epoch 92, Step    50] loss: 0.137\n",
            "[Epoch 92, Step    60] loss: 0.424\n",
            "[Epoch 92, Step    70] loss: 0.235\n",
            "[Epoch 92, Step    80] loss: 0.189\n",
            "[Epoch 92, Step    90] loss: 0.295\n",
            "[Epoch 92, Step   100] loss: 0.191\n",
            "[Epoch 92, Step   110] loss: 0.161\n",
            "[Epoch 92, Step   120] loss: 0.081\n",
            "[Epoch 92, Step   130] loss: 0.094\n",
            "[Epoch 92, Step   140] loss: 0.231\n",
            "[Epoch 92, Step   150] loss: 0.075\n",
            "[Epoch 92, Step   160] loss: 0.156\n",
            "[Epoch 92, Step   170] loss: 0.203\n",
            "[Epoch 92, Step   180] loss: 0.070\n",
            "[Epoch 92, Step   190] loss: 0.027\n",
            "[Epoch 92, Step   200] loss: 0.226\n",
            "[Epoch 92, Step   210] loss: 0.090\n",
            "[Epoch 92, Step   220] loss: 0.474\n",
            "[Epoch 92, Step   230] loss: 0.301\n",
            "[Epoch 92, Step   240] loss: 0.222\n",
            "[Epoch 92, Step   250] loss: 0.224\n",
            "[Epoch 92, Step   260] loss: 0.102\n",
            "[Epoch 92, Step   270] loss: 0.132\n",
            "[Epoch 92, Step   280] loss: 0.255\n",
            "[Epoch 92, Step   290] loss: 0.143\n",
            "[Epoch 92, Step   300] loss: 0.276\n",
            "[Epoch 92, Step   310] loss: 0.386\n",
            "[Epoch 92, Step   320] loss: 0.171\n",
            "[Epoch 92, Step   330] loss: 0.171\n",
            "[Epoch 92, Step   340] loss: 0.319\n",
            "[Epoch 92, Step   350] loss: 0.095\n",
            "[Epoch 92, Step   360] loss: 0.337\n",
            "[Epoch 92, Step   370] loss: 0.063\n",
            "[Epoch 92, Step   380] loss: 0.261\n",
            "[Epoch 92, Step   390] loss: 0.372\n",
            "[Epoch 92, Step   400] loss: 0.184\n",
            "[Epoch 92, Step   410] loss: 0.454\n",
            "[Epoch 92, Step   420] loss: 0.143\n",
            "[Epoch 92, Step   430] loss: 0.115\n",
            "[Epoch 92, Step   440] loss: 0.081\n",
            "[Epoch 92, Step   450] loss: 0.163\n",
            "[Epoch 92, Step   460] loss: 0.141\n",
            "[Epoch 92, Step   470] loss: 0.672\n",
            "[Epoch 92, Step   480] loss: 0.084\n",
            "[Epoch 92, Step   490] loss: 0.105\n",
            "[Epoch 92, Step   500] loss: 0.487\n",
            "[Epoch 92, Step   510] loss: 0.279\n",
            "[Epoch 92, Step   520] loss: 0.094\n",
            "[Epoch 92, Step   530] loss: 0.570\n",
            "[Epoch 92, Step   540] loss: 0.140\n",
            "[Epoch 92, Step   550] loss: 0.123\n",
            "[Epoch 92, Step   560] loss: 0.158\n",
            "[Epoch 92, Step   570] loss: 0.208\n",
            "[Epoch 92, Step   580] loss: 0.167\n",
            "[Epoch 92, Step   590] loss: 0.265\n",
            "[Epoch 92, Step   600] loss: 0.106\n",
            "[Epoch 92, Step   610] loss: 0.055\n",
            "[Epoch 92, Step   620] loss: 0.183\n",
            "[Epoch 92, Step   630] loss: 0.134\n",
            "[Epoch 92, Step   640] loss: 0.324\n",
            "[Epoch 92, Step   650] loss: 0.132\n",
            "[Epoch 92, Step   660] loss: 0.165\n",
            "[Epoch 92, Step   670] loss: 0.049\n",
            "[Epoch 92, Step   680] loss: 0.045\n",
            "[Epoch 92, Step   690] loss: 0.274\n",
            "[Epoch 92, Step   700] loss: 0.077\n",
            "[Epoch 92, Step   710] loss: 0.162\n",
            "[Epoch 92, Step   720] loss: 0.201\n",
            "[Epoch 92, Step   730] loss: 0.151\n",
            "[Epoch 92, Step   740] loss: 0.125\n",
            "[Epoch 92, Step   750] loss: 0.132\n",
            "[Epoch 92, Step   760] loss: 0.099\n",
            "[Epoch 92, Step   770] loss: 0.263\n",
            "[Epoch 92, Step   780] loss: 0.175\n",
            "[Epoch 92, Step   790] loss: 0.235\n",
            "[Epoch 92, Step   800] loss: 0.453\n",
            "[Epoch 92, Step   810] loss: 0.450\n",
            "[Epoch 92, Step   820] loss: 0.301\n",
            "[Epoch 92, Step   830] loss: 0.360\n",
            "[Epoch 92, Step   840] loss: 0.174\n",
            "[Epoch 92, Step   850] loss: 0.160\n",
            "[Epoch 92, Step   860] loss: 0.117\n",
            "[Epoch 92, Step   870] loss: 0.075\n",
            "[Epoch 92, Step   880] loss: 0.187\n",
            "[Epoch 92, Step   890] loss: 0.176\n",
            "[Epoch 92, Step   900] loss: 0.097\n",
            "[Epoch 92, Step   910] loss: 0.355\n",
            "[Epoch 92, Step   920] loss: 0.130\n",
            "[Epoch 92, Step   930] loss: 0.273\n",
            "[Epoch 92, Step   940] loss: 0.132\n",
            "[Epoch 92, Step   950] loss: 0.394\n",
            "[Epoch 92, Step   960] loss: 0.086\n",
            "[Epoch 92, Step   970] loss: 0.283\n",
            "[Epoch 92, Step   980] loss: 0.430\n",
            "[Epoch 92, Step   990] loss: 0.270\n",
            "[Epoch 92, Step  1000] loss: 0.299\n",
            "[Epoch 92, Step  1010] loss: 0.320\n",
            "[Epoch 92, Step  1020] loss: 0.080\n",
            "[Epoch 92, Step  1030] loss: 0.030\n",
            "[Epoch 92, Step  1040] loss: 0.538\n",
            "[Epoch 92, Step  1050] loss: 0.074\n",
            "[Epoch 92, Step  1060] loss: 0.301\n",
            "[Epoch 92, Step  1070] loss: 0.115\n",
            "[Epoch 92, Step  1080] loss: 0.627\n",
            "[Epoch 92, Step  1090] loss: 0.089\n",
            "[Epoch 92, Step  1100] loss: 0.107\n",
            "[Epoch 92, Step  1110] loss: 0.382\n",
            "[Epoch 92, Step  1120] loss: 0.153\n",
            "[Epoch 92, Step  1130] loss: 0.331\n",
            "[Epoch 92, Step  1140] loss: 0.057\n",
            "[Epoch 92, Step  1150] loss: 0.078\n",
            "[Epoch 92, Step  1160] loss: 0.473\n",
            "[Epoch 92, Step  1170] loss: 0.155\n",
            "[Epoch 92, Step  1180] loss: 0.204\n",
            "[Epoch 92, Step  1190] loss: 0.266\n",
            "[Epoch 92, Step  1200] loss: 0.248\n",
            "[Epoch 92, Step  1210] loss: 0.085\n",
            "[Epoch 92, Step  1220] loss: 0.435\n",
            "[Epoch 92, Step  1230] loss: 0.063\n",
            "[Epoch 92, Step  1240] loss: 0.793\n",
            "[Epoch 92, Step  1250] loss: 0.303\n",
            "[Epoch 92, Step  1260] loss: 0.195\n",
            "[Epoch 92, Step  1270] loss: 0.258\n",
            "[Epoch 92, Step  1280] loss: 0.308\n",
            "[Epoch 92, Step  1290] loss: 0.413\n",
            "[Epoch 92, Step  1300] loss: 0.469\n",
            "[Epoch 92, Step  1310] loss: 0.233\n",
            "[Epoch 92, Step  1320] loss: 0.210\n",
            "[Epoch 92, Step  1330] loss: 0.450\n",
            "[Epoch 92, Step  1340] loss: 0.296\n",
            "[Epoch 92, Step  1350] loss: 0.400\n",
            "[Epoch 92, Step  1360] loss: 0.208\n",
            "[Epoch 92, Step  1370] loss: 0.091\n",
            "[Epoch 92, Step  1380] loss: 0.622\n",
            "[Epoch 92, Step  1390] loss: 0.159\n",
            "[Epoch 92, Step  1400] loss: 0.171\n",
            "[Epoch 92, Step  1410] loss: 0.025\n",
            "[Epoch 92, Step  1420] loss: 0.037\n",
            "[Epoch 92, Step  1430] loss: 0.074\n",
            "[Epoch 92, Step  1440] loss: 0.281\n",
            "[Epoch 92, Step  1450] loss: 0.282\n",
            "[Epoch 92, Step  1460] loss: 0.100\n",
            "[Epoch 92, Step  1470] loss: 0.220\n",
            "[Epoch 92, Step  1480] loss: 0.198\n",
            "[Epoch 92, Step  1490] loss: 0.480\n",
            "[Epoch 92, Step  1500] loss: 0.155\n",
            "[Epoch 92, Step  1510] loss: 0.162\n",
            "[Epoch 92, Step  1520] loss: 0.544\n",
            "[Epoch 92, Step  1530] loss: 0.163\n",
            "[Epoch 92, Step  1540] loss: 0.310\n",
            "[Epoch 92, Step  1550] loss: 0.127\n",
            "[Epoch 92, Step  1560] loss: 0.323\n",
            "[Epoch 92, Step  1570] loss: 0.119\n",
            "[Epoch 92, Step  1580] loss: 0.165\n",
            "[Epoch 92, Step  1590] loss: 0.167\n",
            "[Epoch 92, Step  1600] loss: 0.231\n",
            "[Epoch 93, Step    10] loss: 0.296\n",
            "[Epoch 93, Step    20] loss: 0.212\n",
            "[Epoch 93, Step    30] loss: 0.073\n",
            "[Epoch 93, Step    40] loss: 0.123\n",
            "[Epoch 93, Step    50] loss: 0.051\n",
            "[Epoch 93, Step    60] loss: 0.457\n",
            "[Epoch 93, Step    70] loss: 0.213\n",
            "[Epoch 93, Step    80] loss: 0.267\n",
            "[Epoch 93, Step    90] loss: 0.489\n",
            "[Epoch 93, Step   100] loss: 0.041\n",
            "[Epoch 93, Step   110] loss: 0.454\n",
            "[Epoch 93, Step   120] loss: 0.131\n",
            "[Epoch 93, Step   130] loss: 0.242\n",
            "[Epoch 93, Step   140] loss: 0.266\n",
            "[Epoch 93, Step   150] loss: 0.167\n",
            "[Epoch 93, Step   160] loss: 0.152\n",
            "[Epoch 93, Step   170] loss: 0.046\n",
            "[Epoch 93, Step   180] loss: 0.219\n",
            "[Epoch 93, Step   190] loss: 0.248\n",
            "[Epoch 93, Step   200] loss: 0.006\n",
            "[Epoch 93, Step   210] loss: 0.134\n",
            "[Epoch 93, Step   220] loss: 0.048\n",
            "[Epoch 93, Step   230] loss: 0.141\n",
            "[Epoch 93, Step   240] loss: 0.315\n",
            "[Epoch 93, Step   250] loss: 0.125\n",
            "[Epoch 93, Step   260] loss: 0.210\n",
            "[Epoch 93, Step   270] loss: 0.038\n",
            "[Epoch 93, Step   280] loss: 0.166\n",
            "[Epoch 93, Step   290] loss: 0.178\n",
            "[Epoch 93, Step   300] loss: 0.071\n",
            "[Epoch 93, Step   310] loss: 0.169\n",
            "[Epoch 93, Step   320] loss: 0.084\n",
            "[Epoch 93, Step   330] loss: 0.195\n",
            "[Epoch 93, Step   340] loss: 0.246\n",
            "[Epoch 93, Step   350] loss: 0.267\n",
            "[Epoch 93, Step   360] loss: 0.266\n",
            "[Epoch 93, Step   370] loss: 0.253\n",
            "[Epoch 93, Step   380] loss: 0.257\n",
            "[Epoch 93, Step   390] loss: 0.485\n",
            "[Epoch 93, Step   400] loss: 0.041\n",
            "[Epoch 93, Step   410] loss: 0.554\n",
            "[Epoch 93, Step   420] loss: 0.203\n",
            "[Epoch 93, Step   430] loss: 0.267\n",
            "[Epoch 93, Step   440] loss: 0.699\n",
            "[Epoch 93, Step   450] loss: 0.473\n",
            "[Epoch 93, Step   460] loss: 0.092\n",
            "[Epoch 93, Step   470] loss: 0.175\n",
            "[Epoch 93, Step   480] loss: 0.216\n",
            "[Epoch 93, Step   490] loss: 0.217\n",
            "[Epoch 93, Step   500] loss: 0.534\n",
            "[Epoch 93, Step   510] loss: 0.081\n",
            "[Epoch 93, Step   520] loss: 0.202\n",
            "[Epoch 93, Step   530] loss: 0.115\n",
            "[Epoch 93, Step   540] loss: 0.031\n",
            "[Epoch 93, Step   550] loss: 0.082\n",
            "[Epoch 93, Step   560] loss: 0.385\n",
            "[Epoch 93, Step   570] loss: 0.166\n",
            "[Epoch 93, Step   580] loss: 0.137\n",
            "[Epoch 93, Step   590] loss: 0.104\n",
            "[Epoch 93, Step   600] loss: 0.176\n",
            "[Epoch 93, Step   610] loss: 0.255\n",
            "[Epoch 93, Step   620] loss: 0.087\n",
            "[Epoch 93, Step   630] loss: 0.120\n",
            "[Epoch 93, Step   640] loss: 0.147\n",
            "[Epoch 93, Step   650] loss: 0.156\n",
            "[Epoch 93, Step   660] loss: 0.231\n",
            "[Epoch 93, Step   670] loss: 0.427\n",
            "[Epoch 93, Step   680] loss: 0.220\n",
            "[Epoch 93, Step   690] loss: 0.198\n",
            "[Epoch 93, Step   700] loss: 0.017\n",
            "[Epoch 93, Step   710] loss: 0.184\n",
            "[Epoch 93, Step   720] loss: 0.200\n",
            "[Epoch 93, Step   730] loss: 0.346\n",
            "[Epoch 93, Step   740] loss: 0.174\n",
            "[Epoch 93, Step   750] loss: 0.108\n",
            "[Epoch 93, Step   760] loss: 0.389\n",
            "[Epoch 93, Step   770] loss: 0.363\n",
            "[Epoch 93, Step   780] loss: 0.185\n",
            "[Epoch 93, Step   790] loss: 0.195\n",
            "[Epoch 93, Step   800] loss: 0.092\n",
            "[Epoch 93, Step   810] loss: 0.433\n",
            "[Epoch 93, Step   820] loss: 0.264\n",
            "[Epoch 93, Step   830] loss: 0.117\n",
            "[Epoch 93, Step   840] loss: 0.117\n",
            "[Epoch 93, Step   850] loss: 0.365\n",
            "[Epoch 93, Step   860] loss: 0.086\n",
            "[Epoch 93, Step   870] loss: 0.120\n",
            "[Epoch 93, Step   880] loss: 0.042\n",
            "[Epoch 93, Step   890] loss: 0.364\n",
            "[Epoch 93, Step   900] loss: 0.383\n",
            "[Epoch 93, Step   910] loss: 0.362\n",
            "[Epoch 93, Step   920] loss: 0.377\n",
            "[Epoch 93, Step   930] loss: 0.335\n",
            "[Epoch 93, Step   940] loss: 0.213\n",
            "[Epoch 93, Step   950] loss: 0.369\n",
            "[Epoch 93, Step   960] loss: 0.297\n",
            "[Epoch 93, Step   970] loss: 0.156\n",
            "[Epoch 93, Step   980] loss: 0.485\n",
            "[Epoch 93, Step   990] loss: 0.098\n",
            "[Epoch 93, Step  1000] loss: 0.187\n",
            "[Epoch 93, Step  1010] loss: 0.429\n",
            "[Epoch 93, Step  1020] loss: 0.143\n",
            "[Epoch 93, Step  1030] loss: 0.112\n",
            "[Epoch 93, Step  1040] loss: 0.208\n",
            "[Epoch 93, Step  1050] loss: 0.401\n",
            "[Epoch 93, Step  1060] loss: 0.117\n",
            "[Epoch 93, Step  1070] loss: 0.467\n",
            "[Epoch 93, Step  1080] loss: 0.157\n",
            "[Epoch 93, Step  1090] loss: 0.389\n",
            "[Epoch 93, Step  1100] loss: 0.279\n",
            "[Epoch 93, Step  1110] loss: 0.018\n",
            "[Epoch 93, Step  1120] loss: 0.083\n",
            "[Epoch 93, Step  1130] loss: 0.135\n",
            "[Epoch 93, Step  1140] loss: 0.227\n",
            "[Epoch 93, Step  1150] loss: 0.192\n",
            "[Epoch 93, Step  1160] loss: 0.445\n",
            "[Epoch 93, Step  1170] loss: 0.184\n",
            "[Epoch 93, Step  1180] loss: 0.248\n",
            "[Epoch 93, Step  1190] loss: 0.260\n",
            "[Epoch 93, Step  1200] loss: 0.073\n",
            "[Epoch 93, Step  1210] loss: 0.618\n",
            "[Epoch 93, Step  1220] loss: 0.094\n",
            "[Epoch 93, Step  1230] loss: 0.442\n",
            "[Epoch 93, Step  1240] loss: 0.088\n",
            "[Epoch 93, Step  1250] loss: 0.139\n",
            "[Epoch 93, Step  1260] loss: 0.162\n",
            "[Epoch 93, Step  1270] loss: 0.570\n",
            "[Epoch 93, Step  1280] loss: 0.148\n",
            "[Epoch 93, Step  1290] loss: 0.268\n",
            "[Epoch 93, Step  1300] loss: 0.047\n",
            "[Epoch 93, Step  1310] loss: 0.278\n",
            "[Epoch 93, Step  1320] loss: 0.219\n",
            "[Epoch 93, Step  1330] loss: 0.128\n",
            "[Epoch 93, Step  1340] loss: 0.489\n",
            "[Epoch 93, Step  1350] loss: 0.286\n",
            "[Epoch 93, Step  1360] loss: 0.285\n",
            "[Epoch 93, Step  1370] loss: 0.266\n",
            "[Epoch 93, Step  1380] loss: 0.214\n",
            "[Epoch 93, Step  1390] loss: 0.056\n",
            "[Epoch 93, Step  1400] loss: 0.051\n",
            "[Epoch 93, Step  1410] loss: 0.312\n",
            "[Epoch 93, Step  1420] loss: 0.123\n",
            "[Epoch 93, Step  1430] loss: 0.186\n",
            "[Epoch 93, Step  1440] loss: 0.058\n",
            "[Epoch 93, Step  1450] loss: 0.212\n",
            "[Epoch 93, Step  1460] loss: 0.320\n",
            "[Epoch 93, Step  1470] loss: 0.078\n",
            "[Epoch 93, Step  1480] loss: 0.216\n",
            "[Epoch 93, Step  1490] loss: 0.238\n",
            "[Epoch 93, Step  1500] loss: 0.574\n",
            "[Epoch 93, Step  1510] loss: 0.058\n",
            "[Epoch 93, Step  1520] loss: 0.041\n",
            "[Epoch 93, Step  1530] loss: 0.060\n",
            "[Epoch 93, Step  1540] loss: 0.316\n",
            "[Epoch 93, Step  1550] loss: 0.058\n",
            "[Epoch 93, Step  1560] loss: 0.101\n",
            "[Epoch 93, Step  1570] loss: 0.212\n",
            "[Epoch 93, Step  1580] loss: 0.212\n",
            "[Epoch 93, Step  1590] loss: 0.208\n",
            "[Epoch 93, Step  1600] loss: 0.176\n",
            "[Epoch 94, Step    10] loss: 0.199\n",
            "[Epoch 94, Step    20] loss: 0.414\n",
            "[Epoch 94, Step    30] loss: 0.153\n",
            "[Epoch 94, Step    40] loss: 0.255\n",
            "[Epoch 94, Step    50] loss: 0.299\n",
            "[Epoch 94, Step    60] loss: 0.228\n",
            "[Epoch 94, Step    70] loss: 0.187\n",
            "[Epoch 94, Step    80] loss: 0.119\n",
            "[Epoch 94, Step    90] loss: 0.116\n",
            "[Epoch 94, Step   100] loss: 0.156\n",
            "[Epoch 94, Step   110] loss: 0.314\n",
            "[Epoch 94, Step   120] loss: 0.198\n",
            "[Epoch 94, Step   130] loss: 0.118\n",
            "[Epoch 94, Step   140] loss: 0.262\n",
            "[Epoch 94, Step   150] loss: 0.214\n",
            "[Epoch 94, Step   160] loss: 0.194\n",
            "[Epoch 94, Step   170] loss: 0.122\n",
            "[Epoch 94, Step   180] loss: 0.044\n",
            "[Epoch 94, Step   190] loss: 0.089\n",
            "[Epoch 94, Step   200] loss: 0.223\n",
            "[Epoch 94, Step   210] loss: 0.052\n",
            "[Epoch 94, Step   220] loss: 0.373\n",
            "[Epoch 94, Step   230] loss: 0.216\n",
            "[Epoch 94, Step   240] loss: 0.289\n",
            "[Epoch 94, Step   250] loss: 0.235\n",
            "[Epoch 94, Step   260] loss: 0.202\n",
            "[Epoch 94, Step   270] loss: 0.153\n",
            "[Epoch 94, Step   280] loss: 0.050\n",
            "[Epoch 94, Step   290] loss: 0.115\n",
            "[Epoch 94, Step   300] loss: 0.042\n",
            "[Epoch 94, Step   310] loss: 0.388\n",
            "[Epoch 94, Step   320] loss: 0.151\n",
            "[Epoch 94, Step   330] loss: 0.283\n",
            "[Epoch 94, Step   340] loss: 0.223\n",
            "[Epoch 94, Step   350] loss: 0.131\n",
            "[Epoch 94, Step   360] loss: 0.157\n",
            "[Epoch 94, Step   370] loss: 0.242\n",
            "[Epoch 94, Step   380] loss: 0.472\n",
            "[Epoch 94, Step   390] loss: 0.576\n",
            "[Epoch 94, Step   400] loss: 0.143\n",
            "[Epoch 94, Step   410] loss: 0.093\n",
            "[Epoch 94, Step   420] loss: 0.395\n",
            "[Epoch 94, Step   430] loss: 0.155\n",
            "[Epoch 94, Step   440] loss: 0.352\n",
            "[Epoch 94, Step   450] loss: 0.085\n",
            "[Epoch 94, Step   460] loss: 0.374\n",
            "[Epoch 94, Step   470] loss: 0.066\n",
            "[Epoch 94, Step   480] loss: 0.338\n",
            "[Epoch 94, Step   490] loss: 0.226\n",
            "[Epoch 94, Step   500] loss: 0.048\n",
            "[Epoch 94, Step   510] loss: 0.159\n",
            "[Epoch 94, Step   520] loss: 0.370\n",
            "[Epoch 94, Step   530] loss: 0.184\n",
            "[Epoch 94, Step   540] loss: 0.304\n",
            "[Epoch 94, Step   550] loss: 0.253\n",
            "[Epoch 94, Step   560] loss: 0.465\n",
            "[Epoch 94, Step   570] loss: 0.324\n",
            "[Epoch 94, Step   580] loss: 0.166\n",
            "[Epoch 94, Step   590] loss: 0.064\n",
            "[Epoch 94, Step   600] loss: 0.295\n",
            "[Epoch 94, Step   610] loss: 0.080\n",
            "[Epoch 94, Step   620] loss: 0.429\n",
            "[Epoch 94, Step   630] loss: 0.056\n",
            "[Epoch 94, Step   640] loss: 0.107\n",
            "[Epoch 94, Step   650] loss: 0.190\n",
            "[Epoch 94, Step   660] loss: 0.270\n",
            "[Epoch 94, Step   670] loss: 0.329\n",
            "[Epoch 94, Step   680] loss: 0.272\n",
            "[Epoch 94, Step   690] loss: 0.082\n",
            "[Epoch 94, Step   700] loss: 0.168\n",
            "[Epoch 94, Step   710] loss: 0.194\n",
            "[Epoch 94, Step   720] loss: 0.486\n",
            "[Epoch 94, Step   730] loss: 0.351\n",
            "[Epoch 94, Step   740] loss: 0.276\n",
            "[Epoch 94, Step   750] loss: 0.195\n",
            "[Epoch 94, Step   760] loss: 0.055\n",
            "[Epoch 94, Step   770] loss: 0.198\n",
            "[Epoch 94, Step   780] loss: 0.202\n",
            "[Epoch 94, Step   790] loss: 0.174\n",
            "[Epoch 94, Step   800] loss: 0.237\n",
            "[Epoch 94, Step   810] loss: 0.216\n",
            "[Epoch 94, Step   820] loss: 0.114\n",
            "[Epoch 94, Step   830] loss: 0.094\n",
            "[Epoch 94, Step   840] loss: 0.336\n",
            "[Epoch 94, Step   850] loss: 0.060\n",
            "[Epoch 94, Step   860] loss: 0.088\n",
            "[Epoch 94, Step   870] loss: 0.113\n",
            "[Epoch 94, Step   880] loss: 0.357\n",
            "[Epoch 94, Step   890] loss: 0.086\n",
            "[Epoch 94, Step   900] loss: 0.384\n",
            "[Epoch 94, Step   910] loss: 0.244\n",
            "[Epoch 94, Step   920] loss: 0.485\n",
            "[Epoch 94, Step   930] loss: 0.373\n",
            "[Epoch 94, Step   940] loss: 0.082\n",
            "[Epoch 94, Step   950] loss: 0.134\n",
            "[Epoch 94, Step   960] loss: 0.204\n",
            "[Epoch 94, Step   970] loss: 0.254\n",
            "[Epoch 94, Step   980] loss: 0.113\n",
            "[Epoch 94, Step   990] loss: 0.087\n",
            "[Epoch 94, Step  1000] loss: 0.168\n",
            "[Epoch 94, Step  1010] loss: 0.118\n",
            "[Epoch 94, Step  1020] loss: 0.339\n",
            "[Epoch 94, Step  1030] loss: 0.305\n",
            "[Epoch 94, Step  1040] loss: 0.105\n",
            "[Epoch 94, Step  1050] loss: 0.185\n",
            "[Epoch 94, Step  1060] loss: 0.269\n",
            "[Epoch 94, Step  1070] loss: 0.069\n",
            "[Epoch 94, Step  1080] loss: 0.151\n",
            "[Epoch 94, Step  1090] loss: 0.576\n",
            "[Epoch 94, Step  1100] loss: 0.547\n",
            "[Epoch 94, Step  1110] loss: 0.153\n",
            "[Epoch 94, Step  1120] loss: 0.074\n",
            "[Epoch 94, Step  1130] loss: 0.236\n",
            "[Epoch 94, Step  1140] loss: 0.130\n",
            "[Epoch 94, Step  1150] loss: 0.191\n",
            "[Epoch 94, Step  1160] loss: 0.018\n",
            "[Epoch 94, Step  1170] loss: 0.505\n",
            "[Epoch 94, Step  1180] loss: 0.091\n",
            "[Epoch 94, Step  1190] loss: 0.250\n",
            "[Epoch 94, Step  1200] loss: 0.261\n",
            "[Epoch 94, Step  1210] loss: 0.166\n",
            "[Epoch 94, Step  1220] loss: 0.095\n",
            "[Epoch 94, Step  1230] loss: 0.199\n",
            "[Epoch 94, Step  1240] loss: 0.036\n",
            "[Epoch 94, Step  1250] loss: 0.461\n",
            "[Epoch 94, Step  1260] loss: 0.658\n",
            "[Epoch 94, Step  1270] loss: 0.163\n",
            "[Epoch 94, Step  1280] loss: 0.396\n",
            "[Epoch 94, Step  1290] loss: 0.205\n",
            "[Epoch 94, Step  1300] loss: 0.183\n",
            "[Epoch 94, Step  1310] loss: 0.281\n",
            "[Epoch 94, Step  1320] loss: 0.205\n",
            "[Epoch 94, Step  1330] loss: 0.136\n",
            "[Epoch 94, Step  1340] loss: 0.031\n",
            "[Epoch 94, Step  1350] loss: 0.286\n",
            "[Epoch 94, Step  1360] loss: 0.181\n",
            "[Epoch 94, Step  1370] loss: 0.056\n",
            "[Epoch 94, Step  1380] loss: 0.522\n",
            "[Epoch 94, Step  1390] loss: 0.219\n",
            "[Epoch 94, Step  1400] loss: 0.537\n",
            "[Epoch 94, Step  1410] loss: 0.119\n",
            "[Epoch 94, Step  1420] loss: 0.161\n",
            "[Epoch 94, Step  1430] loss: 0.051\n",
            "[Epoch 94, Step  1440] loss: 0.349\n",
            "[Epoch 94, Step  1450] loss: 0.128\n",
            "[Epoch 94, Step  1460] loss: 0.085\n",
            "[Epoch 94, Step  1470] loss: 0.287\n",
            "[Epoch 94, Step  1480] loss: 0.150\n",
            "[Epoch 94, Step  1490] loss: 0.046\n",
            "[Epoch 94, Step  1500] loss: 0.128\n",
            "[Epoch 94, Step  1510] loss: 0.180\n",
            "[Epoch 94, Step  1520] loss: 0.113\n",
            "[Epoch 94, Step  1530] loss: 0.030\n",
            "[Epoch 94, Step  1540] loss: 0.251\n",
            "[Epoch 94, Step  1550] loss: 0.440\n",
            "[Epoch 94, Step  1560] loss: 0.136\n",
            "[Epoch 94, Step  1570] loss: 0.361\n",
            "[Epoch 94, Step  1580] loss: 0.600\n",
            "[Epoch 94, Step  1590] loss: 0.070\n",
            "[Epoch 94, Step  1600] loss: 0.284\n",
            "[Epoch 95, Step    10] loss: 0.048\n",
            "[Epoch 95, Step    20] loss: 0.149\n",
            "[Epoch 95, Step    30] loss: 0.352\n",
            "[Epoch 95, Step    40] loss: 0.454\n",
            "[Epoch 95, Step    50] loss: 0.200\n",
            "[Epoch 95, Step    60] loss: 0.293\n",
            "[Epoch 95, Step    70] loss: 0.340\n",
            "[Epoch 95, Step    80] loss: 0.337\n",
            "[Epoch 95, Step    90] loss: 0.235\n",
            "[Epoch 95, Step   100] loss: 0.247\n",
            "[Epoch 95, Step   110] loss: 0.029\n",
            "[Epoch 95, Step   120] loss: 0.467\n",
            "[Epoch 95, Step   130] loss: 0.090\n",
            "[Epoch 95, Step   140] loss: 0.104\n",
            "[Epoch 95, Step   150] loss: 0.301\n",
            "[Epoch 95, Step   160] loss: 0.065\n",
            "[Epoch 95, Step   170] loss: 0.209\n",
            "[Epoch 95, Step   180] loss: 0.136\n",
            "[Epoch 95, Step   190] loss: 0.170\n",
            "[Epoch 95, Step   200] loss: 0.049\n",
            "[Epoch 95, Step   210] loss: 0.194\n",
            "[Epoch 95, Step   220] loss: 0.201\n",
            "[Epoch 95, Step   230] loss: 0.367\n",
            "[Epoch 95, Step   240] loss: 0.210\n",
            "[Epoch 95, Step   250] loss: 0.329\n",
            "[Epoch 95, Step   260] loss: 0.264\n",
            "[Epoch 95, Step   270] loss: 0.431\n",
            "[Epoch 95, Step   280] loss: 0.244\n",
            "[Epoch 95, Step   290] loss: 0.091\n",
            "[Epoch 95, Step   300] loss: 0.311\n",
            "[Epoch 95, Step   310] loss: 0.094\n",
            "[Epoch 95, Step   320] loss: 0.184\n",
            "[Epoch 95, Step   330] loss: 0.199\n",
            "[Epoch 95, Step   340] loss: 0.042\n",
            "[Epoch 95, Step   350] loss: 0.136\n",
            "[Epoch 95, Step   360] loss: 0.070\n",
            "[Epoch 95, Step   370] loss: 0.008\n",
            "[Epoch 95, Step   380] loss: 0.087\n",
            "[Epoch 95, Step   390] loss: 0.238\n",
            "[Epoch 95, Step   400] loss: 0.237\n",
            "[Epoch 95, Step   410] loss: 0.362\n",
            "[Epoch 95, Step   420] loss: 0.189\n",
            "[Epoch 95, Step   430] loss: 0.439\n",
            "[Epoch 95, Step   440] loss: 0.206\n",
            "[Epoch 95, Step   450] loss: 0.521\n",
            "[Epoch 95, Step   460] loss: 0.385\n",
            "[Epoch 95, Step   470] loss: 0.207\n",
            "[Epoch 95, Step   480] loss: 0.597\n",
            "[Epoch 95, Step   490] loss: 0.150\n",
            "[Epoch 95, Step   500] loss: 0.056\n",
            "[Epoch 95, Step   510] loss: 0.282\n",
            "[Epoch 95, Step   520] loss: 0.263\n",
            "[Epoch 95, Step   530] loss: 0.279\n",
            "[Epoch 95, Step   540] loss: 0.161\n",
            "[Epoch 95, Step   550] loss: 0.405\n",
            "[Epoch 95, Step   560] loss: 0.160\n",
            "[Epoch 95, Step   570] loss: 0.154\n",
            "[Epoch 95, Step   580] loss: 0.271\n",
            "[Epoch 95, Step   590] loss: 0.096\n",
            "[Epoch 95, Step   600] loss: 0.235\n",
            "[Epoch 95, Step   610] loss: 0.080\n",
            "[Epoch 95, Step   620] loss: 0.137\n",
            "[Epoch 95, Step   630] loss: 0.258\n",
            "[Epoch 95, Step   640] loss: 0.155\n",
            "[Epoch 95, Step   650] loss: 0.054\n",
            "[Epoch 95, Step   660] loss: 0.334\n",
            "[Epoch 95, Step   670] loss: 0.075\n",
            "[Epoch 95, Step   680] loss: 0.214\n",
            "[Epoch 95, Step   690] loss: 0.139\n",
            "[Epoch 95, Step   700] loss: 0.259\n",
            "[Epoch 95, Step   710] loss: 0.212\n",
            "[Epoch 95, Step   720] loss: 0.068\n",
            "[Epoch 95, Step   730] loss: 0.088\n",
            "[Epoch 95, Step   740] loss: 0.202\n",
            "[Epoch 95, Step   750] loss: 0.144\n",
            "[Epoch 95, Step   760] loss: 0.134\n",
            "[Epoch 95, Step   770] loss: 0.267\n",
            "[Epoch 95, Step   780] loss: 0.318\n",
            "[Epoch 95, Step   790] loss: 0.247\n",
            "[Epoch 95, Step   800] loss: 0.110\n",
            "[Epoch 95, Step   810] loss: 0.381\n",
            "[Epoch 95, Step   820] loss: 0.241\n",
            "[Epoch 95, Step   830] loss: 0.205\n",
            "[Epoch 95, Step   840] loss: 0.299\n",
            "[Epoch 95, Step   850] loss: 0.189\n",
            "[Epoch 95, Step   860] loss: 0.196\n",
            "[Epoch 95, Step   870] loss: 0.195\n",
            "[Epoch 95, Step   880] loss: 0.065\n",
            "[Epoch 95, Step   890] loss: 0.064\n",
            "[Epoch 95, Step   900] loss: 0.044\n",
            "[Epoch 95, Step   910] loss: 0.370\n",
            "[Epoch 95, Step   920] loss: 0.308\n",
            "[Epoch 95, Step   930] loss: 0.269\n",
            "[Epoch 95, Step   940] loss: 0.238\n",
            "[Epoch 95, Step   950] loss: 0.176\n",
            "[Epoch 95, Step   960] loss: 0.522\n",
            "[Epoch 95, Step   970] loss: 0.100\n",
            "[Epoch 95, Step   980] loss: 0.244\n",
            "[Epoch 95, Step   990] loss: 0.216\n",
            "[Epoch 95, Step  1000] loss: 0.227\n",
            "[Epoch 95, Step  1010] loss: 0.213\n",
            "[Epoch 95, Step  1020] loss: 0.272\n",
            "[Epoch 95, Step  1030] loss: 0.045\n",
            "[Epoch 95, Step  1040] loss: 0.167\n",
            "[Epoch 95, Step  1050] loss: 0.058\n",
            "[Epoch 95, Step  1060] loss: 0.465\n",
            "[Epoch 95, Step  1070] loss: 0.028\n",
            "[Epoch 95, Step  1080] loss: 0.111\n",
            "[Epoch 95, Step  1090] loss: 0.022\n",
            "[Epoch 95, Step  1100] loss: 0.252\n",
            "[Epoch 95, Step  1110] loss: 0.335\n",
            "[Epoch 95, Step  1120] loss: 0.051\n",
            "[Epoch 95, Step  1130] loss: 0.387\n",
            "[Epoch 95, Step  1140] loss: 0.240\n",
            "[Epoch 95, Step  1150] loss: 0.099\n",
            "[Epoch 95, Step  1160] loss: 0.324\n",
            "[Epoch 95, Step  1170] loss: 0.149\n",
            "[Epoch 95, Step  1180] loss: 0.419\n",
            "[Epoch 95, Step  1190] loss: 0.132\n",
            "[Epoch 95, Step  1200] loss: 0.627\n",
            "[Epoch 95, Step  1210] loss: 0.349\n",
            "[Epoch 95, Step  1220] loss: 0.047\n",
            "[Epoch 95, Step  1230] loss: 0.022\n",
            "[Epoch 95, Step  1240] loss: 0.100\n",
            "[Epoch 95, Step  1250] loss: 0.189\n",
            "[Epoch 95, Step  1260] loss: 0.085\n",
            "[Epoch 95, Step  1270] loss: 0.252\n",
            "[Epoch 95, Step  1280] loss: 0.261\n",
            "[Epoch 95, Step  1290] loss: 0.413\n",
            "[Epoch 95, Step  1300] loss: 0.241\n",
            "[Epoch 95, Step  1310] loss: 0.225\n",
            "[Epoch 95, Step  1320] loss: 0.118\n",
            "[Epoch 95, Step  1330] loss: 0.101\n",
            "[Epoch 95, Step  1340] loss: 0.413\n",
            "[Epoch 95, Step  1350] loss: 0.251\n",
            "[Epoch 95, Step  1360] loss: 0.109\n",
            "[Epoch 95, Step  1370] loss: 0.372\n",
            "[Epoch 95, Step  1380] loss: 0.515\n",
            "[Epoch 95, Step  1390] loss: 0.099\n",
            "[Epoch 95, Step  1400] loss: 0.619\n",
            "[Epoch 95, Step  1410] loss: 0.229\n",
            "[Epoch 95, Step  1420] loss: 0.170\n",
            "[Epoch 95, Step  1430] loss: 0.757\n",
            "[Epoch 95, Step  1440] loss: 0.122\n",
            "[Epoch 95, Step  1450] loss: 0.140\n",
            "[Epoch 95, Step  1460] loss: 0.296\n",
            "[Epoch 95, Step  1470] loss: 0.277\n",
            "[Epoch 95, Step  1480] loss: 0.163\n",
            "[Epoch 95, Step  1490] loss: 0.115\n",
            "[Epoch 95, Step  1500] loss: 0.313\n",
            "[Epoch 95, Step  1510] loss: 0.048\n",
            "[Epoch 95, Step  1520] loss: 0.241\n",
            "[Epoch 95, Step  1530] loss: 0.172\n",
            "[Epoch 95, Step  1540] loss: 0.170\n",
            "[Epoch 95, Step  1550] loss: 0.116\n",
            "[Epoch 95, Step  1560] loss: 0.156\n",
            "[Epoch 95, Step  1570] loss: 0.104\n",
            "[Epoch 95, Step  1580] loss: 0.166\n",
            "[Epoch 95, Step  1590] loss: 0.099\n",
            "[Epoch 95, Step  1600] loss: 0.313\n",
            "[Epoch 96, Step    10] loss: 0.290\n",
            "[Epoch 96, Step    20] loss: 0.153\n",
            "[Epoch 96, Step    30] loss: 0.275\n",
            "[Epoch 96, Step    40] loss: 0.027\n",
            "[Epoch 96, Step    50] loss: 0.098\n",
            "[Epoch 96, Step    60] loss: 0.038\n",
            "[Epoch 96, Step    70] loss: 0.156\n",
            "[Epoch 96, Step    80] loss: 0.175\n",
            "[Epoch 96, Step    90] loss: 0.012\n",
            "[Epoch 96, Step   100] loss: 0.401\n",
            "[Epoch 96, Step   110] loss: 0.315\n",
            "[Epoch 96, Step   120] loss: 0.064\n",
            "[Epoch 96, Step   130] loss: 0.329\n",
            "[Epoch 96, Step   140] loss: 0.731\n",
            "[Epoch 96, Step   150] loss: 0.134\n",
            "[Epoch 96, Step   160] loss: 0.072\n",
            "[Epoch 96, Step   170] loss: 0.124\n",
            "[Epoch 96, Step   180] loss: 0.099\n",
            "[Epoch 96, Step   190] loss: 0.328\n",
            "[Epoch 96, Step   200] loss: 0.119\n",
            "[Epoch 96, Step   210] loss: 0.263\n",
            "[Epoch 96, Step   220] loss: 0.160\n",
            "[Epoch 96, Step   230] loss: 0.067\n",
            "[Epoch 96, Step   240] loss: 0.263\n",
            "[Epoch 96, Step   250] loss: 0.065\n",
            "[Epoch 96, Step   260] loss: 0.259\n",
            "[Epoch 96, Step   270] loss: 0.275\n",
            "[Epoch 96, Step   280] loss: 0.471\n",
            "[Epoch 96, Step   290] loss: 0.227\n",
            "[Epoch 96, Step   300] loss: 0.184\n",
            "[Epoch 96, Step   310] loss: 0.057\n",
            "[Epoch 96, Step   320] loss: 0.216\n",
            "[Epoch 96, Step   330] loss: 0.163\n",
            "[Epoch 96, Step   340] loss: 0.060\n",
            "[Epoch 96, Step   350] loss: 0.426\n",
            "[Epoch 96, Step   360] loss: 0.074\n",
            "[Epoch 96, Step   370] loss: 0.204\n",
            "[Epoch 96, Step   380] loss: 0.056\n",
            "[Epoch 96, Step   390] loss: 0.197\n",
            "[Epoch 96, Step   400] loss: 0.376\n",
            "[Epoch 96, Step   410] loss: 0.388\n",
            "[Epoch 96, Step   420] loss: 0.378\n",
            "[Epoch 96, Step   430] loss: 0.208\n",
            "[Epoch 96, Step   440] loss: 0.159\n",
            "[Epoch 96, Step   450] loss: 0.380\n",
            "[Epoch 96, Step   460] loss: 0.146\n",
            "[Epoch 96, Step   470] loss: 0.068\n",
            "[Epoch 96, Step   480] loss: 0.206\n",
            "[Epoch 96, Step   490] loss: 0.323\n",
            "[Epoch 96, Step   500] loss: 0.084\n",
            "[Epoch 96, Step   510] loss: 0.411\n",
            "[Epoch 96, Step   520] loss: 0.295\n",
            "[Epoch 96, Step   530] loss: 0.102\n",
            "[Epoch 96, Step   540] loss: 0.185\n",
            "[Epoch 96, Step   550] loss: 0.208\n",
            "[Epoch 96, Step   560] loss: 0.138\n",
            "[Epoch 96, Step   570] loss: 0.094\n",
            "[Epoch 96, Step   580] loss: 0.395\n",
            "[Epoch 96, Step   590] loss: 0.064\n",
            "[Epoch 96, Step   600] loss: 0.134\n",
            "[Epoch 96, Step   610] loss: 0.365\n",
            "[Epoch 96, Step   620] loss: 0.387\n",
            "[Epoch 96, Step   630] loss: 0.080\n",
            "[Epoch 96, Step   640] loss: 0.197\n",
            "[Epoch 96, Step   650] loss: 0.087\n",
            "[Epoch 96, Step   660] loss: 0.270\n",
            "[Epoch 96, Step   670] loss: 0.336\n",
            "[Epoch 96, Step   680] loss: 0.070\n",
            "[Epoch 96, Step   690] loss: 0.352\n",
            "[Epoch 96, Step   700] loss: 0.339\n",
            "[Epoch 96, Step   710] loss: 0.105\n",
            "[Epoch 96, Step   720] loss: 0.183\n",
            "[Epoch 96, Step   730] loss: 0.162\n",
            "[Epoch 96, Step   740] loss: 0.220\n",
            "[Epoch 96, Step   750] loss: 0.149\n",
            "[Epoch 96, Step   760] loss: 0.346\n",
            "[Epoch 96, Step   770] loss: 0.197\n",
            "[Epoch 96, Step   780] loss: 0.487\n",
            "[Epoch 96, Step   790] loss: 0.259\n",
            "[Epoch 96, Step   800] loss: 0.026\n",
            "[Epoch 96, Step   810] loss: 0.523\n",
            "[Epoch 96, Step   820] loss: 0.603\n",
            "[Epoch 96, Step   830] loss: 0.207\n",
            "[Epoch 96, Step   840] loss: 0.101\n",
            "[Epoch 96, Step   850] loss: 0.153\n",
            "[Epoch 96, Step   860] loss: 0.508\n",
            "[Epoch 96, Step   870] loss: 0.178\n",
            "[Epoch 96, Step   880] loss: 0.272\n",
            "[Epoch 96, Step   890] loss: 0.280\n",
            "[Epoch 96, Step   900] loss: 0.083\n",
            "[Epoch 96, Step   910] loss: 0.107\n",
            "[Epoch 96, Step   920] loss: 0.053\n",
            "[Epoch 96, Step   930] loss: 0.110\n",
            "[Epoch 96, Step   940] loss: 0.135\n",
            "[Epoch 96, Step   950] loss: 0.116\n",
            "[Epoch 96, Step   960] loss: 0.225\n",
            "[Epoch 96, Step   970] loss: 0.099\n",
            "[Epoch 96, Step   980] loss: 0.123\n",
            "[Epoch 96, Step   990] loss: 0.579\n",
            "[Epoch 96, Step  1000] loss: 0.326\n",
            "[Epoch 96, Step  1010] loss: 0.372\n",
            "[Epoch 96, Step  1020] loss: 0.062\n",
            "[Epoch 96, Step  1030] loss: 0.169\n",
            "[Epoch 96, Step  1040] loss: 0.228\n",
            "[Epoch 96, Step  1050] loss: 0.044\n",
            "[Epoch 96, Step  1060] loss: 0.103\n",
            "[Epoch 96, Step  1070] loss: 0.227\n",
            "[Epoch 96, Step  1080] loss: 0.094\n",
            "[Epoch 96, Step  1090] loss: 0.186\n",
            "[Epoch 96, Step  1100] loss: 0.256\n",
            "[Epoch 96, Step  1110] loss: 0.294\n",
            "[Epoch 96, Step  1120] loss: 0.071\n",
            "[Epoch 96, Step  1130] loss: 0.289\n",
            "[Epoch 96, Step  1140] loss: 0.125\n",
            "[Epoch 96, Step  1150] loss: 0.154\n",
            "[Epoch 96, Step  1160] loss: 0.327\n",
            "[Epoch 96, Step  1170] loss: 0.486\n",
            "[Epoch 96, Step  1180] loss: 0.256\n",
            "[Epoch 96, Step  1190] loss: 0.414\n",
            "[Epoch 96, Step  1200] loss: 0.339\n",
            "[Epoch 96, Step  1210] loss: 0.182\n",
            "[Epoch 96, Step  1220] loss: 0.150\n",
            "[Epoch 96, Step  1230] loss: 0.268\n",
            "[Epoch 96, Step  1240] loss: 0.232\n",
            "[Epoch 96, Step  1250] loss: 0.201\n",
            "[Epoch 96, Step  1260] loss: 0.148\n",
            "[Epoch 96, Step  1270] loss: 0.220\n",
            "[Epoch 96, Step  1280] loss: 0.145\n",
            "[Epoch 96, Step  1290] loss: 0.063\n",
            "[Epoch 96, Step  1300] loss: 0.244\n",
            "[Epoch 96, Step  1310] loss: 0.190\n",
            "[Epoch 96, Step  1320] loss: 0.091\n",
            "[Epoch 96, Step  1330] loss: 0.133\n",
            "[Epoch 96, Step  1340] loss: 0.347\n",
            "[Epoch 96, Step  1350] loss: 0.308\n",
            "[Epoch 96, Step  1360] loss: 0.149\n",
            "[Epoch 96, Step  1370] loss: 0.043\n",
            "[Epoch 96, Step  1380] loss: 0.653\n",
            "[Epoch 96, Step  1390] loss: 0.039\n",
            "[Epoch 96, Step  1400] loss: 0.208\n",
            "[Epoch 96, Step  1410] loss: 0.138\n",
            "[Epoch 96, Step  1420] loss: 0.323\n",
            "[Epoch 96, Step  1430] loss: 0.128\n",
            "[Epoch 96, Step  1440] loss: 0.367\n",
            "[Epoch 96, Step  1450] loss: 0.166\n",
            "[Epoch 96, Step  1460] loss: 0.043\n",
            "[Epoch 96, Step  1470] loss: 0.433\n",
            "[Epoch 96, Step  1480] loss: 0.358\n",
            "[Epoch 96, Step  1490] loss: 0.205\n",
            "[Epoch 96, Step  1500] loss: 0.015\n",
            "[Epoch 96, Step  1510] loss: 0.028\n",
            "[Epoch 96, Step  1520] loss: 0.049\n",
            "[Epoch 96, Step  1530] loss: 0.218\n",
            "[Epoch 96, Step  1540] loss: 0.084\n",
            "[Epoch 96, Step  1550] loss: 0.375\n",
            "[Epoch 96, Step  1560] loss: 0.468\n",
            "[Epoch 96, Step  1570] loss: 0.511\n",
            "[Epoch 96, Step  1580] loss: 0.126\n",
            "[Epoch 96, Step  1590] loss: 0.071\n",
            "[Epoch 96, Step  1600] loss: 0.249\n",
            "[Epoch 97, Step    10] loss: 0.457\n",
            "[Epoch 97, Step    20] loss: 0.129\n",
            "[Epoch 97, Step    30] loss: 0.147\n",
            "[Epoch 97, Step    40] loss: 0.078\n",
            "[Epoch 97, Step    50] loss: 0.326\n",
            "[Epoch 97, Step    60] loss: 0.364\n",
            "[Epoch 97, Step    70] loss: 0.054\n",
            "[Epoch 97, Step    80] loss: 0.082\n",
            "[Epoch 97, Step    90] loss: 0.198\n",
            "[Epoch 97, Step   100] loss: 0.233\n",
            "[Epoch 97, Step   110] loss: 0.193\n",
            "[Epoch 97, Step   120] loss: 0.147\n",
            "[Epoch 97, Step   130] loss: 0.230\n",
            "[Epoch 97, Step   140] loss: 0.499\n",
            "[Epoch 97, Step   150] loss: 0.379\n",
            "[Epoch 97, Step   160] loss: 0.239\n",
            "[Epoch 97, Step   170] loss: 0.150\n",
            "[Epoch 97, Step   180] loss: 0.157\n",
            "[Epoch 97, Step   190] loss: 0.067\n",
            "[Epoch 97, Step   200] loss: 0.125\n",
            "[Epoch 97, Step   210] loss: 0.325\n",
            "[Epoch 97, Step   220] loss: 0.519\n",
            "[Epoch 97, Step   230] loss: 0.108\n",
            "[Epoch 97, Step   240] loss: 0.146\n",
            "[Epoch 97, Step   250] loss: 0.122\n",
            "[Epoch 97, Step   260] loss: 0.400\n",
            "[Epoch 97, Step   270] loss: 0.111\n",
            "[Epoch 97, Step   280] loss: 0.042\n",
            "[Epoch 97, Step   290] loss: 0.094\n",
            "[Epoch 97, Step   300] loss: 0.309\n",
            "[Epoch 97, Step   310] loss: 0.249\n",
            "[Epoch 97, Step   320] loss: 0.096\n",
            "[Epoch 97, Step   330] loss: 0.303\n",
            "[Epoch 97, Step   340] loss: 0.536\n",
            "[Epoch 97, Step   350] loss: 0.059\n",
            "[Epoch 97, Step   360] loss: 0.032\n",
            "[Epoch 97, Step   370] loss: 0.280\n",
            "[Epoch 97, Step   380] loss: 0.261\n",
            "[Epoch 97, Step   390] loss: 0.020\n",
            "[Epoch 97, Step   400] loss: 0.472\n",
            "[Epoch 97, Step   410] loss: 0.298\n",
            "[Epoch 97, Step   420] loss: 0.423\n",
            "[Epoch 97, Step   430] loss: 0.091\n",
            "[Epoch 97, Step   440] loss: 0.129\n",
            "[Epoch 97, Step   450] loss: 0.161\n",
            "[Epoch 97, Step   460] loss: 0.121\n",
            "[Epoch 97, Step   470] loss: 0.156\n",
            "[Epoch 97, Step   480] loss: 0.444\n",
            "[Epoch 97, Step   490] loss: 0.256\n",
            "[Epoch 97, Step   500] loss: 0.764\n",
            "[Epoch 97, Step   510] loss: 0.419\n",
            "[Epoch 97, Step   520] loss: 0.094\n",
            "[Epoch 97, Step   530] loss: 0.296\n",
            "[Epoch 97, Step   540] loss: 0.201\n",
            "[Epoch 97, Step   550] loss: 0.134\n",
            "[Epoch 97, Step   560] loss: 0.176\n",
            "[Epoch 97, Step   570] loss: 0.062\n",
            "[Epoch 97, Step   580] loss: 0.055\n",
            "[Epoch 97, Step   590] loss: 0.306\n",
            "[Epoch 97, Step   600] loss: 0.263\n",
            "[Epoch 97, Step   610] loss: 0.203\n",
            "[Epoch 97, Step   620] loss: 0.114\n",
            "[Epoch 97, Step   630] loss: 0.104\n",
            "[Epoch 97, Step   640] loss: 0.084\n",
            "[Epoch 97, Step   650] loss: 0.192\n",
            "[Epoch 97, Step   660] loss: 0.319\n",
            "[Epoch 97, Step   670] loss: 0.461\n",
            "[Epoch 97, Step   680] loss: 0.144\n",
            "[Epoch 97, Step   690] loss: 0.312\n",
            "[Epoch 97, Step   700] loss: 0.223\n",
            "[Epoch 97, Step   710] loss: 0.190\n",
            "[Epoch 97, Step   720] loss: 0.078\n",
            "[Epoch 97, Step   730] loss: 0.284\n",
            "[Epoch 97, Step   740] loss: 0.434\n",
            "[Epoch 97, Step   750] loss: 0.145\n",
            "[Epoch 97, Step   760] loss: 0.168\n",
            "[Epoch 97, Step   770] loss: 0.212\n",
            "[Epoch 97, Step   780] loss: 0.284\n",
            "[Epoch 97, Step   790] loss: 0.155\n",
            "[Epoch 97, Step   800] loss: 0.066\n",
            "[Epoch 97, Step   810] loss: 0.320\n",
            "[Epoch 97, Step   820] loss: 0.246\n",
            "[Epoch 97, Step   830] loss: 0.061\n",
            "[Epoch 97, Step   840] loss: 0.499\n",
            "[Epoch 97, Step   850] loss: 0.125\n",
            "[Epoch 97, Step   860] loss: 0.287\n",
            "[Epoch 97, Step   870] loss: 0.261\n",
            "[Epoch 97, Step   880] loss: 0.247\n",
            "[Epoch 97, Step   890] loss: 0.046\n",
            "[Epoch 97, Step   900] loss: 0.655\n",
            "[Epoch 97, Step   910] loss: 0.571\n",
            "[Epoch 97, Step   920] loss: 0.121\n",
            "[Epoch 97, Step   930] loss: 0.179\n",
            "[Epoch 97, Step   940] loss: 0.462\n",
            "[Epoch 97, Step   950] loss: 0.140\n",
            "[Epoch 97, Step   960] loss: 0.202\n",
            "[Epoch 97, Step   970] loss: 0.065\n",
            "[Epoch 97, Step   980] loss: 0.035\n",
            "[Epoch 97, Step   990] loss: 0.185\n",
            "[Epoch 97, Step  1000] loss: 0.101\n",
            "[Epoch 97, Step  1010] loss: 0.130\n",
            "[Epoch 97, Step  1020] loss: 0.092\n",
            "[Epoch 97, Step  1030] loss: 0.147\n",
            "[Epoch 97, Step  1040] loss: 0.245\n",
            "[Epoch 97, Step  1050] loss: 0.136\n",
            "[Epoch 97, Step  1060] loss: 0.194\n",
            "[Epoch 97, Step  1070] loss: 0.223\n",
            "[Epoch 97, Step  1080] loss: 0.246\n",
            "[Epoch 97, Step  1090] loss: 0.032\n",
            "[Epoch 97, Step  1100] loss: 0.170\n",
            "[Epoch 97, Step  1110] loss: 0.331\n",
            "[Epoch 97, Step  1120] loss: 0.391\n",
            "[Epoch 97, Step  1130] loss: 0.430\n",
            "[Epoch 97, Step  1140] loss: 0.318\n",
            "[Epoch 97, Step  1150] loss: 0.065\n",
            "[Epoch 97, Step  1160] loss: 0.133\n",
            "[Epoch 97, Step  1170] loss: 0.088\n",
            "[Epoch 97, Step  1180] loss: 0.306\n",
            "[Epoch 97, Step  1190] loss: 0.160\n",
            "[Epoch 97, Step  1200] loss: 0.390\n",
            "[Epoch 97, Step  1210] loss: 0.063\n",
            "[Epoch 97, Step  1220] loss: 0.108\n",
            "[Epoch 97, Step  1230] loss: 0.165\n",
            "[Epoch 97, Step  1240] loss: 0.336\n",
            "[Epoch 97, Step  1250] loss: 0.115\n",
            "[Epoch 97, Step  1260] loss: 0.022\n",
            "[Epoch 97, Step  1270] loss: 0.108\n",
            "[Epoch 97, Step  1280] loss: 0.137\n",
            "[Epoch 97, Step  1290] loss: 0.074\n",
            "[Epoch 97, Step  1300] loss: 0.606\n",
            "[Epoch 97, Step  1310] loss: 0.122\n",
            "[Epoch 97, Step  1320] loss: 0.202\n",
            "[Epoch 97, Step  1330] loss: 0.106\n",
            "[Epoch 97, Step  1340] loss: 0.196\n",
            "[Epoch 97, Step  1350] loss: 0.200\n",
            "[Epoch 97, Step  1360] loss: 0.081\n",
            "[Epoch 97, Step  1370] loss: 0.156\n",
            "[Epoch 97, Step  1380] loss: 0.361\n",
            "[Epoch 97, Step  1390] loss: 0.242\n",
            "[Epoch 97, Step  1400] loss: 0.129\n",
            "[Epoch 97, Step  1410] loss: 0.235\n",
            "[Epoch 97, Step  1420] loss: 0.152\n",
            "[Epoch 97, Step  1430] loss: 0.071\n",
            "[Epoch 97, Step  1440] loss: 0.046\n",
            "[Epoch 97, Step  1450] loss: 0.130\n",
            "[Epoch 97, Step  1460] loss: 0.282\n",
            "[Epoch 97, Step  1470] loss: 0.048\n",
            "[Epoch 97, Step  1480] loss: 0.303\n",
            "[Epoch 97, Step  1490] loss: 0.075\n",
            "[Epoch 97, Step  1500] loss: 0.450\n",
            "[Epoch 97, Step  1510] loss: 0.125\n",
            "[Epoch 97, Step  1520] loss: 0.522\n",
            "[Epoch 97, Step  1530] loss: 0.267\n",
            "[Epoch 97, Step  1540] loss: 0.293\n",
            "[Epoch 97, Step  1550] loss: 0.072\n",
            "[Epoch 97, Step  1560] loss: 0.207\n",
            "[Epoch 97, Step  1570] loss: 0.232\n",
            "[Epoch 97, Step  1580] loss: 0.215\n",
            "[Epoch 97, Step  1590] loss: 0.240\n",
            "[Epoch 97, Step  1600] loss: 0.407\n",
            "[Epoch 98, Step    10] loss: 0.262\n",
            "[Epoch 98, Step    20] loss: 0.447\n",
            "[Epoch 98, Step    30] loss: 0.239\n",
            "[Epoch 98, Step    40] loss: 0.101\n",
            "[Epoch 98, Step    50] loss: 0.193\n",
            "[Epoch 98, Step    60] loss: 0.113\n",
            "[Epoch 98, Step    70] loss: 0.201\n",
            "[Epoch 98, Step    80] loss: 0.553\n",
            "[Epoch 98, Step    90] loss: 0.188\n",
            "[Epoch 98, Step   100] loss: 0.090\n",
            "[Epoch 98, Step   110] loss: 0.201\n",
            "[Epoch 98, Step   120] loss: 0.146\n",
            "[Epoch 98, Step   130] loss: 0.367\n",
            "[Epoch 98, Step   140] loss: 0.067\n",
            "[Epoch 98, Step   150] loss: 0.028\n",
            "[Epoch 98, Step   160] loss: 0.255\n",
            "[Epoch 98, Step   170] loss: 0.658\n",
            "[Epoch 98, Step   180] loss: 0.234\n",
            "[Epoch 98, Step   190] loss: 0.172\n",
            "[Epoch 98, Step   200] loss: 0.365\n",
            "[Epoch 98, Step   210] loss: 0.166\n",
            "[Epoch 98, Step   220] loss: 0.223\n",
            "[Epoch 98, Step   230] loss: 0.093\n",
            "[Epoch 98, Step   240] loss: 0.261\n",
            "[Epoch 98, Step   250] loss: 0.100\n",
            "[Epoch 98, Step   260] loss: 0.012\n",
            "[Epoch 98, Step   270] loss: 0.164\n",
            "[Epoch 98, Step   280] loss: 0.037\n",
            "[Epoch 98, Step   290] loss: 0.181\n",
            "[Epoch 98, Step   300] loss: 0.046\n",
            "[Epoch 98, Step   310] loss: 0.287\n",
            "[Epoch 98, Step   320] loss: 0.200\n",
            "[Epoch 98, Step   330] loss: 0.250\n",
            "[Epoch 98, Step   340] loss: 0.328\n",
            "[Epoch 98, Step   350] loss: 0.186\n",
            "[Epoch 98, Step   360] loss: 0.225\n",
            "[Epoch 98, Step   370] loss: 0.197\n",
            "[Epoch 98, Step   380] loss: 0.473\n",
            "[Epoch 98, Step   390] loss: 0.401\n",
            "[Epoch 98, Step   400] loss: 0.019\n",
            "[Epoch 98, Step   410] loss: 0.086\n",
            "[Epoch 98, Step   420] loss: 0.497\n",
            "[Epoch 98, Step   430] loss: 0.215\n",
            "[Epoch 98, Step   440] loss: 0.128\n",
            "[Epoch 98, Step   450] loss: 0.123\n",
            "[Epoch 98, Step   460] loss: 0.503\n",
            "[Epoch 98, Step   470] loss: 0.075\n",
            "[Epoch 98, Step   480] loss: 0.288\n",
            "[Epoch 98, Step   490] loss: 0.255\n",
            "[Epoch 98, Step   500] loss: 0.469\n",
            "[Epoch 98, Step   510] loss: 0.149\n",
            "[Epoch 98, Step   520] loss: 0.287\n",
            "[Epoch 98, Step   530] loss: 0.155\n",
            "[Epoch 98, Step   540] loss: 0.298\n",
            "[Epoch 98, Step   550] loss: 0.358\n",
            "[Epoch 98, Step   560] loss: 0.103\n",
            "[Epoch 98, Step   570] loss: 0.052\n",
            "[Epoch 98, Step   580] loss: 0.041\n",
            "[Epoch 98, Step   590] loss: 0.302\n",
            "[Epoch 98, Step   600] loss: 0.126\n",
            "[Epoch 98, Step   610] loss: 0.063\n",
            "[Epoch 98, Step   620] loss: 0.106\n",
            "[Epoch 98, Step   630] loss: 0.483\n",
            "[Epoch 98, Step   640] loss: 0.215\n",
            "[Epoch 98, Step   650] loss: 0.315\n",
            "[Epoch 98, Step   660] loss: 0.232\n",
            "[Epoch 98, Step   670] loss: 0.155\n",
            "[Epoch 98, Step   680] loss: 0.097\n",
            "[Epoch 98, Step   690] loss: 0.136\n",
            "[Epoch 98, Step   700] loss: 0.206\n",
            "[Epoch 98, Step   710] loss: 0.182\n",
            "[Epoch 98, Step   720] loss: 0.055\n",
            "[Epoch 98, Step   730] loss: 0.415\n",
            "[Epoch 98, Step   740] loss: 0.035\n",
            "[Epoch 98, Step   750] loss: 0.216\n",
            "[Epoch 98, Step   760] loss: 0.198\n",
            "[Epoch 98, Step   770] loss: 0.140\n",
            "[Epoch 98, Step   780] loss: 0.216\n",
            "[Epoch 98, Step   790] loss: 0.230\n",
            "[Epoch 98, Step   800] loss: 0.568\n",
            "[Epoch 98, Step   810] loss: 0.058\n",
            "[Epoch 98, Step   820] loss: 0.270\n",
            "[Epoch 98, Step   830] loss: 0.082\n",
            "[Epoch 98, Step   840] loss: 0.092\n",
            "[Epoch 98, Step   850] loss: 0.107\n",
            "[Epoch 98, Step   860] loss: 0.206\n",
            "[Epoch 98, Step   870] loss: 0.183\n",
            "[Epoch 98, Step   880] loss: 0.128\n",
            "[Epoch 98, Step   890] loss: 0.147\n",
            "[Epoch 98, Step   900] loss: 0.096\n",
            "[Epoch 98, Step   910] loss: 0.275\n",
            "[Epoch 98, Step   920] loss: 0.700\n",
            "[Epoch 98, Step   930] loss: 0.364\n",
            "[Epoch 98, Step   940] loss: 0.450\n",
            "[Epoch 98, Step   950] loss: 0.283\n",
            "[Epoch 98, Step   960] loss: 0.307\n",
            "[Epoch 98, Step   970] loss: 0.032\n",
            "[Epoch 98, Step   980] loss: 0.335\n",
            "[Epoch 98, Step   990] loss: 0.052\n",
            "[Epoch 98, Step  1000] loss: 0.535\n",
            "[Epoch 98, Step  1010] loss: 0.264\n",
            "[Epoch 98, Step  1020] loss: 0.144\n",
            "[Epoch 98, Step  1030] loss: 0.229\n",
            "[Epoch 98, Step  1040] loss: 0.047\n",
            "[Epoch 98, Step  1050] loss: 0.130\n",
            "[Epoch 98, Step  1060] loss: 0.229\n",
            "[Epoch 98, Step  1070] loss: 0.111\n",
            "[Epoch 98, Step  1080] loss: 0.177\n",
            "[Epoch 98, Step  1090] loss: 0.047\n",
            "[Epoch 98, Step  1100] loss: 0.509\n",
            "[Epoch 98, Step  1110] loss: 0.322\n",
            "[Epoch 98, Step  1120] loss: 0.225\n",
            "[Epoch 98, Step  1130] loss: 0.265\n",
            "[Epoch 98, Step  1140] loss: 0.114\n",
            "[Epoch 98, Step  1150] loss: 0.070\n",
            "[Epoch 98, Step  1160] loss: 0.102\n",
            "[Epoch 98, Step  1170] loss: 0.181\n",
            "[Epoch 98, Step  1180] loss: 0.122\n",
            "[Epoch 98, Step  1190] loss: 0.202\n",
            "[Epoch 98, Step  1200] loss: 0.096\n",
            "[Epoch 98, Step  1210] loss: 0.203\n",
            "[Epoch 98, Step  1220] loss: 0.193\n",
            "[Epoch 98, Step  1230] loss: 0.047\n",
            "[Epoch 98, Step  1240] loss: 0.049\n",
            "[Epoch 98, Step  1250] loss: 0.172\n",
            "[Epoch 98, Step  1260] loss: 0.145\n",
            "[Epoch 98, Step  1270] loss: 0.185\n",
            "[Epoch 98, Step  1280] loss: 0.112\n",
            "[Epoch 98, Step  1290] loss: 0.185\n",
            "[Epoch 98, Step  1300] loss: 0.434\n",
            "[Epoch 98, Step  1310] loss: 0.213\n",
            "[Epoch 98, Step  1320] loss: 0.145\n",
            "[Epoch 98, Step  1330] loss: 0.109\n",
            "[Epoch 98, Step  1340] loss: 0.173\n",
            "[Epoch 98, Step  1350] loss: 0.322\n",
            "[Epoch 98, Step  1360] loss: 0.627\n",
            "[Epoch 98, Step  1370] loss: 0.012\n",
            "[Epoch 98, Step  1380] loss: 0.598\n",
            "[Epoch 98, Step  1390] loss: 0.379\n",
            "[Epoch 98, Step  1400] loss: 0.313\n",
            "[Epoch 98, Step  1410] loss: 0.107\n",
            "[Epoch 98, Step  1420] loss: 0.217\n",
            "[Epoch 98, Step  1430] loss: 0.128\n",
            "[Epoch 98, Step  1440] loss: 0.175\n",
            "[Epoch 98, Step  1450] loss: 0.258\n",
            "[Epoch 98, Step  1460] loss: 0.132\n",
            "[Epoch 98, Step  1470] loss: 0.181\n",
            "[Epoch 98, Step  1480] loss: 0.527\n",
            "[Epoch 98, Step  1490] loss: 0.097\n",
            "[Epoch 98, Step  1500] loss: 0.188\n",
            "[Epoch 98, Step  1510] loss: 0.288\n",
            "[Epoch 98, Step  1520] loss: 0.274\n",
            "[Epoch 98, Step  1530] loss: 0.088\n",
            "[Epoch 98, Step  1540] loss: 0.220\n",
            "[Epoch 98, Step  1550] loss: 0.141\n",
            "[Epoch 98, Step  1560] loss: 0.263\n",
            "[Epoch 98, Step  1570] loss: 0.164\n",
            "[Epoch 98, Step  1580] loss: 0.252\n",
            "[Epoch 98, Step  1590] loss: 0.136\n",
            "[Epoch 98, Step  1600] loss: 0.482\n",
            "[Epoch 99, Step    10] loss: 0.221\n",
            "[Epoch 99, Step    20] loss: 0.284\n",
            "[Epoch 99, Step    30] loss: 0.091\n",
            "[Epoch 99, Step    40] loss: 0.105\n",
            "[Epoch 99, Step    50] loss: 0.029\n",
            "[Epoch 99, Step    60] loss: 0.065\n",
            "[Epoch 99, Step    70] loss: 0.283\n",
            "[Epoch 99, Step    80] loss: 0.118\n",
            "[Epoch 99, Step    90] loss: 0.280\n",
            "[Epoch 99, Step   100] loss: 0.069\n",
            "[Epoch 99, Step   110] loss: 0.286\n",
            "[Epoch 99, Step   120] loss: 0.247\n",
            "[Epoch 99, Step   130] loss: 0.105\n",
            "[Epoch 99, Step   140] loss: 0.134\n",
            "[Epoch 99, Step   150] loss: 0.185\n",
            "[Epoch 99, Step   160] loss: 0.216\n",
            "[Epoch 99, Step   170] loss: 0.135\n",
            "[Epoch 99, Step   180] loss: 0.311\n",
            "[Epoch 99, Step   190] loss: 0.132\n",
            "[Epoch 99, Step   200] loss: 0.243\n",
            "[Epoch 99, Step   210] loss: 0.165\n",
            "[Epoch 99, Step   220] loss: 0.065\n",
            "[Epoch 99, Step   230] loss: 0.114\n",
            "[Epoch 99, Step   240] loss: 0.125\n",
            "[Epoch 99, Step   250] loss: 0.129\n",
            "[Epoch 99, Step   260] loss: 0.278\n",
            "[Epoch 99, Step   270] loss: 0.494\n",
            "[Epoch 99, Step   280] loss: 0.013\n",
            "[Epoch 99, Step   290] loss: 0.239\n",
            "[Epoch 99, Step   300] loss: 0.155\n",
            "[Epoch 99, Step   310] loss: 0.227\n",
            "[Epoch 99, Step   320] loss: 0.157\n",
            "[Epoch 99, Step   330] loss: 0.090\n",
            "[Epoch 99, Step   340] loss: 0.049\n",
            "[Epoch 99, Step   350] loss: 0.276\n",
            "[Epoch 99, Step   360] loss: 0.100\n",
            "[Epoch 99, Step   370] loss: 0.306\n",
            "[Epoch 99, Step   380] loss: 0.163\n",
            "[Epoch 99, Step   390] loss: 0.287\n",
            "[Epoch 99, Step   400] loss: 0.164\n",
            "[Epoch 99, Step   410] loss: 0.409\n",
            "[Epoch 99, Step   420] loss: 0.216\n",
            "[Epoch 99, Step   430] loss: 0.377\n",
            "[Epoch 99, Step   440] loss: 0.472\n",
            "[Epoch 99, Step   450] loss: 0.104\n",
            "[Epoch 99, Step   460] loss: 0.124\n",
            "[Epoch 99, Step   470] loss: 0.038\n",
            "[Epoch 99, Step   480] loss: 0.263\n",
            "[Epoch 99, Step   490] loss: 0.138\n",
            "[Epoch 99, Step   500] loss: 0.096\n",
            "[Epoch 99, Step   510] loss: 0.200\n",
            "[Epoch 99, Step   520] loss: 0.542\n",
            "[Epoch 99, Step   530] loss: 0.183\n",
            "[Epoch 99, Step   540] loss: 0.182\n",
            "[Epoch 99, Step   550] loss: 0.360\n",
            "[Epoch 99, Step   560] loss: 0.137\n",
            "[Epoch 99, Step   570] loss: 0.047\n",
            "[Epoch 99, Step   580] loss: 0.450\n",
            "[Epoch 99, Step   590] loss: 0.349\n",
            "[Epoch 99, Step   600] loss: 0.357\n",
            "[Epoch 99, Step   610] loss: 0.169\n",
            "[Epoch 99, Step   620] loss: 0.522\n",
            "[Epoch 99, Step   630] loss: 0.160\n",
            "[Epoch 99, Step   640] loss: 0.259\n",
            "[Epoch 99, Step   650] loss: 0.540\n",
            "[Epoch 99, Step   660] loss: 0.095\n",
            "[Epoch 99, Step   670] loss: 0.106\n",
            "[Epoch 99, Step   680] loss: 0.087\n",
            "[Epoch 99, Step   690] loss: 0.294\n",
            "[Epoch 99, Step   700] loss: 0.049\n",
            "[Epoch 99, Step   710] loss: 0.119\n",
            "[Epoch 99, Step   720] loss: 0.118\n",
            "[Epoch 99, Step   730] loss: 0.251\n",
            "[Epoch 99, Step   740] loss: 0.085\n",
            "[Epoch 99, Step   750] loss: 0.210\n",
            "[Epoch 99, Step   760] loss: 0.108\n",
            "[Epoch 99, Step   770] loss: 0.051\n",
            "[Epoch 99, Step   780] loss: 0.084\n",
            "[Epoch 99, Step   790] loss: 0.138\n",
            "[Epoch 99, Step   800] loss: 0.343\n",
            "[Epoch 99, Step   810] loss: 0.189\n",
            "[Epoch 99, Step   820] loss: 0.144\n",
            "[Epoch 99, Step   830] loss: 0.071\n",
            "[Epoch 99, Step   840] loss: 0.485\n",
            "[Epoch 99, Step   850] loss: 0.392\n",
            "[Epoch 99, Step   860] loss: 0.030\n",
            "[Epoch 99, Step   870] loss: 0.213\n",
            "[Epoch 99, Step   880] loss: 0.154\n",
            "[Epoch 99, Step   890] loss: 0.053\n",
            "[Epoch 99, Step   900] loss: 0.305\n",
            "[Epoch 99, Step   910] loss: 0.113\n",
            "[Epoch 99, Step   920] loss: 0.354\n",
            "[Epoch 99, Step   930] loss: 0.117\n",
            "[Epoch 99, Step   940] loss: 0.028\n",
            "[Epoch 99, Step   950] loss: 0.212\n",
            "[Epoch 99, Step   960] loss: 0.161\n",
            "[Epoch 99, Step   970] loss: 0.305\n",
            "[Epoch 99, Step   980] loss: 0.100\n",
            "[Epoch 99, Step   990] loss: 0.158\n",
            "[Epoch 99, Step  1000] loss: 0.239\n",
            "[Epoch 99, Step  1010] loss: 0.277\n",
            "[Epoch 99, Step  1020] loss: 0.094\n",
            "[Epoch 99, Step  1030] loss: 0.367\n",
            "[Epoch 99, Step  1040] loss: 0.633\n",
            "[Epoch 99, Step  1050] loss: 0.148\n",
            "[Epoch 99, Step  1060] loss: 0.162\n",
            "[Epoch 99, Step  1070] loss: 0.084\n",
            "[Epoch 99, Step  1080] loss: 0.124\n",
            "[Epoch 99, Step  1090] loss: 0.279\n",
            "[Epoch 99, Step  1100] loss: 0.312\n",
            "[Epoch 99, Step  1110] loss: 0.013\n",
            "[Epoch 99, Step  1120] loss: 0.120\n",
            "[Epoch 99, Step  1130] loss: 0.281\n",
            "[Epoch 99, Step  1140] loss: 0.203\n",
            "[Epoch 99, Step  1150] loss: 0.361\n",
            "[Epoch 99, Step  1160] loss: 0.089\n",
            "[Epoch 99, Step  1170] loss: 0.348\n",
            "[Epoch 99, Step  1180] loss: 0.209\n",
            "[Epoch 99, Step  1190] loss: 0.099\n",
            "[Epoch 99, Step  1200] loss: 0.158\n",
            "[Epoch 99, Step  1210] loss: 0.131\n",
            "[Epoch 99, Step  1220] loss: 0.435\n",
            "[Epoch 99, Step  1230] loss: 0.294\n",
            "[Epoch 99, Step  1240] loss: 0.170\n",
            "[Epoch 99, Step  1250] loss: 0.286\n",
            "[Epoch 99, Step  1260] loss: 0.394\n",
            "[Epoch 99, Step  1270] loss: 0.048\n",
            "[Epoch 99, Step  1280] loss: 0.409\n",
            "[Epoch 99, Step  1290] loss: 0.233\n",
            "[Epoch 99, Step  1300] loss: 0.047\n",
            "[Epoch 99, Step  1310] loss: 0.372\n",
            "[Epoch 99, Step  1320] loss: 0.046\n",
            "[Epoch 99, Step  1330] loss: 0.071\n",
            "[Epoch 99, Step  1340] loss: 0.075\n",
            "[Epoch 99, Step  1350] loss: 0.164\n",
            "[Epoch 99, Step  1360] loss: 0.612\n",
            "[Epoch 99, Step  1370] loss: 0.161\n",
            "[Epoch 99, Step  1380] loss: 0.180\n",
            "[Epoch 99, Step  1390] loss: 0.329\n",
            "[Epoch 99, Step  1400] loss: 0.217\n",
            "[Epoch 99, Step  1410] loss: 0.051\n",
            "[Epoch 99, Step  1420] loss: 0.447\n",
            "[Epoch 99, Step  1430] loss: 0.259\n",
            "[Epoch 99, Step  1440] loss: 0.251\n",
            "[Epoch 99, Step  1450] loss: 0.276\n",
            "[Epoch 99, Step  1460] loss: 0.347\n",
            "[Epoch 99, Step  1470] loss: 0.323\n",
            "[Epoch 99, Step  1480] loss: 0.435\n",
            "[Epoch 99, Step  1490] loss: 0.049\n",
            "[Epoch 99, Step  1500] loss: 0.157\n",
            "[Epoch 99, Step  1510] loss: 0.081\n",
            "[Epoch 99, Step  1520] loss: 0.467\n",
            "[Epoch 99, Step  1530] loss: 0.547\n",
            "[Epoch 99, Step  1540] loss: 0.113\n",
            "[Epoch 99, Step  1550] loss: 0.484\n",
            "[Epoch 99, Step  1560] loss: 0.510\n",
            "[Epoch 99, Step  1570] loss: 0.201\n",
            "[Epoch 99, Step  1580] loss: 0.174\n",
            "[Epoch 99, Step  1590] loss: 0.204\n",
            "[Epoch 99, Step  1600] loss: 0.219\n",
            "[Epoch 100, Step    10] loss: 0.038\n",
            "[Epoch 100, Step    20] loss: 0.023\n",
            "[Epoch 100, Step    30] loss: 0.338\n",
            "[Epoch 100, Step    40] loss: 0.409\n",
            "[Epoch 100, Step    50] loss: 0.035\n",
            "[Epoch 100, Step    60] loss: 0.043\n",
            "[Epoch 100, Step    70] loss: 0.040\n",
            "[Epoch 100, Step    80] loss: 0.060\n",
            "[Epoch 100, Step    90] loss: 0.078\n",
            "[Epoch 100, Step   100] loss: 0.187\n",
            "[Epoch 100, Step   110] loss: 0.051\n",
            "[Epoch 100, Step   120] loss: 0.037\n",
            "[Epoch 100, Step   130] loss: 0.436\n",
            "[Epoch 100, Step   140] loss: 0.223\n",
            "[Epoch 100, Step   150] loss: 0.082\n",
            "[Epoch 100, Step   160] loss: 0.281\n",
            "[Epoch 100, Step   170] loss: 0.214\n",
            "[Epoch 100, Step   180] loss: 0.428\n",
            "[Epoch 100, Step   190] loss: 0.246\n",
            "[Epoch 100, Step   200] loss: 0.105\n",
            "[Epoch 100, Step   210] loss: 0.350\n",
            "[Epoch 100, Step   220] loss: 0.347\n",
            "[Epoch 100, Step   230] loss: 0.245\n",
            "[Epoch 100, Step   240] loss: 0.428\n",
            "[Epoch 100, Step   250] loss: 0.032\n",
            "[Epoch 100, Step   260] loss: 0.032\n",
            "[Epoch 100, Step   270] loss: 0.280\n",
            "[Epoch 100, Step   280] loss: 0.150\n",
            "[Epoch 100, Step   290] loss: 0.230\n",
            "[Epoch 100, Step   300] loss: 0.267\n",
            "[Epoch 100, Step   310] loss: 0.342\n",
            "[Epoch 100, Step   320] loss: 0.051\n",
            "[Epoch 100, Step   330] loss: 0.293\n",
            "[Epoch 100, Step   340] loss: 0.397\n",
            "[Epoch 100, Step   350] loss: 0.565\n",
            "[Epoch 100, Step   360] loss: 0.179\n",
            "[Epoch 100, Step   370] loss: 0.348\n",
            "[Epoch 100, Step   380] loss: 0.176\n",
            "[Epoch 100, Step   390] loss: 0.175\n",
            "[Epoch 100, Step   400] loss: 0.074\n",
            "[Epoch 100, Step   410] loss: 0.064\n",
            "[Epoch 100, Step   420] loss: 0.329\n",
            "[Epoch 100, Step   430] loss: 0.375\n",
            "[Epoch 100, Step   440] loss: 0.508\n",
            "[Epoch 100, Step   450] loss: 0.237\n",
            "[Epoch 100, Step   460] loss: 0.392\n",
            "[Epoch 100, Step   470] loss: 0.056\n",
            "[Epoch 100, Step   480] loss: 0.567\n",
            "[Epoch 100, Step   490] loss: 0.087\n",
            "[Epoch 100, Step   500] loss: 0.147\n",
            "[Epoch 100, Step   510] loss: 0.046\n",
            "[Epoch 100, Step   520] loss: 0.434\n",
            "[Epoch 100, Step   530] loss: 0.156\n",
            "[Epoch 100, Step   540] loss: 0.519\n",
            "[Epoch 100, Step   550] loss: 0.165\n",
            "[Epoch 100, Step   560] loss: 0.249\n",
            "[Epoch 100, Step   570] loss: 0.122\n",
            "[Epoch 100, Step   580] loss: 0.129\n",
            "[Epoch 100, Step   590] loss: 0.164\n",
            "[Epoch 100, Step   600] loss: 0.120\n",
            "[Epoch 100, Step   610] loss: 0.130\n",
            "[Epoch 100, Step   620] loss: 0.104\n",
            "[Epoch 100, Step   630] loss: 0.196\n",
            "[Epoch 100, Step   640] loss: 0.136\n",
            "[Epoch 100, Step   650] loss: 0.090\n",
            "[Epoch 100, Step   660] loss: 0.207\n",
            "[Epoch 100, Step   670] loss: 0.164\n",
            "[Epoch 100, Step   680] loss: 0.221\n",
            "[Epoch 100, Step   690] loss: 0.149\n",
            "[Epoch 100, Step   700] loss: 0.053\n",
            "[Epoch 100, Step   710] loss: 0.404\n",
            "[Epoch 100, Step   720] loss: 0.079\n",
            "[Epoch 100, Step   730] loss: 0.160\n",
            "[Epoch 100, Step   740] loss: 0.292\n",
            "[Epoch 100, Step   750] loss: 0.349\n",
            "[Epoch 100, Step   760] loss: 0.099\n",
            "[Epoch 100, Step   770] loss: 0.091\n",
            "[Epoch 100, Step   780] loss: 0.094\n",
            "[Epoch 100, Step   790] loss: 0.180\n",
            "[Epoch 100, Step   800] loss: 0.363\n",
            "[Epoch 100, Step   810] loss: 0.225\n",
            "[Epoch 100, Step   820] loss: 0.192\n",
            "[Epoch 100, Step   830] loss: 0.249\n",
            "[Epoch 100, Step   840] loss: 0.125\n",
            "[Epoch 100, Step   850] loss: 0.238\n",
            "[Epoch 100, Step   860] loss: 0.329\n",
            "[Epoch 100, Step   870] loss: 0.255\n",
            "[Epoch 100, Step   880] loss: 0.278\n",
            "[Epoch 100, Step   890] loss: 0.183\n",
            "[Epoch 100, Step   900] loss: 0.057\n",
            "[Epoch 100, Step   910] loss: 0.574\n",
            "[Epoch 100, Step   920] loss: 0.116\n",
            "[Epoch 100, Step   930] loss: 0.199\n",
            "[Epoch 100, Step   940] loss: 0.204\n",
            "[Epoch 100, Step   950] loss: 0.411\n",
            "[Epoch 100, Step   960] loss: 0.498\n",
            "[Epoch 100, Step   970] loss: 0.038\n",
            "[Epoch 100, Step   980] loss: 0.308\n",
            "[Epoch 100, Step   990] loss: 0.255\n",
            "[Epoch 100, Step  1000] loss: 0.253\n",
            "[Epoch 100, Step  1010] loss: 0.208\n",
            "[Epoch 100, Step  1020] loss: 0.181\n",
            "[Epoch 100, Step  1030] loss: 0.293\n",
            "[Epoch 100, Step  1040] loss: 0.051\n",
            "[Epoch 100, Step  1050] loss: 0.247\n",
            "[Epoch 100, Step  1060] loss: 0.156\n",
            "[Epoch 100, Step  1070] loss: 0.103\n",
            "[Epoch 100, Step  1080] loss: 0.136\n",
            "[Epoch 100, Step  1090] loss: 0.099\n",
            "[Epoch 100, Step  1100] loss: 0.118\n",
            "[Epoch 100, Step  1110] loss: 0.112\n",
            "[Epoch 100, Step  1120] loss: 0.106\n",
            "[Epoch 100, Step  1130] loss: 0.443\n",
            "[Epoch 100, Step  1140] loss: 0.125\n",
            "[Epoch 100, Step  1150] loss: 0.078\n",
            "[Epoch 100, Step  1160] loss: 0.074\n",
            "[Epoch 100, Step  1170] loss: 0.321\n",
            "[Epoch 100, Step  1180] loss: 0.473\n",
            "[Epoch 100, Step  1190] loss: 0.210\n",
            "[Epoch 100, Step  1200] loss: 0.452\n",
            "[Epoch 100, Step  1210] loss: 0.171\n",
            "[Epoch 100, Step  1220] loss: 0.365\n",
            "[Epoch 100, Step  1230] loss: 0.228\n",
            "[Epoch 100, Step  1240] loss: 0.032\n",
            "[Epoch 100, Step  1250] loss: 0.059\n",
            "[Epoch 100, Step  1260] loss: 0.109\n",
            "[Epoch 100, Step  1270] loss: 0.089\n",
            "[Epoch 100, Step  1280] loss: 0.270\n",
            "[Epoch 100, Step  1290] loss: 0.193\n",
            "[Epoch 100, Step  1300] loss: 0.239\n",
            "[Epoch 100, Step  1310] loss: 0.199\n",
            "[Epoch 100, Step  1320] loss: 0.513\n",
            "[Epoch 100, Step  1330] loss: 0.256\n",
            "[Epoch 100, Step  1340] loss: 0.158\n",
            "[Epoch 100, Step  1350] loss: 0.059\n",
            "[Epoch 100, Step  1360] loss: 0.570\n",
            "[Epoch 100, Step  1370] loss: 0.151\n",
            "[Epoch 100, Step  1380] loss: 0.078\n",
            "[Epoch 100, Step  1390] loss: 0.341\n",
            "[Epoch 100, Step  1400] loss: 0.237\n",
            "[Epoch 100, Step  1410] loss: 0.169\n",
            "[Epoch 100, Step  1420] loss: 0.467\n",
            "[Epoch 100, Step  1430] loss: 0.572\n",
            "[Epoch 100, Step  1440] loss: 0.150\n",
            "[Epoch 100, Step  1450] loss: 0.120\n",
            "[Epoch 100, Step  1460] loss: 0.089\n",
            "[Epoch 100, Step  1470] loss: 0.343\n",
            "[Epoch 100, Step  1480] loss: 0.242\n",
            "[Epoch 100, Step  1490] loss: 0.130\n",
            "[Epoch 100, Step  1500] loss: 0.222\n",
            "[Epoch 100, Step  1510] loss: 0.153\n",
            "[Epoch 100, Step  1520] loss: 0.094\n",
            "[Epoch 100, Step  1530] loss: 0.089\n",
            "[Epoch 100, Step  1540] loss: 0.143\n",
            "[Epoch 100, Step  1550] loss: 0.466\n",
            "[Epoch 100, Step  1560] loss: 0.187\n",
            "[Epoch 100, Step  1570] loss: 0.157\n",
            "[Epoch 100, Step  1580] loss: 0.177\n",
            "[Epoch 100, Step  1590] loss: 0.194\n",
            "[Epoch 100, Step  1600] loss: 0.198\n",
            "Finished Training\n",
            "F1 Score: 0.91\n",
            "Classification Report:\n",
            "               precision    recall  f1-score   support\n",
            "\n",
            "         0.0       0.94      0.92      0.93       255\n",
            "         1.0       0.86      0.90      0.88       147\n",
            "\n",
            "    accuracy                           0.91       402\n",
            "   macro avg       0.90      0.91      0.90       402\n",
            "weighted avg       0.91      0.91      0.91       402\n",
            "\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 800x600 with 2 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ]
    }
  ]
}
